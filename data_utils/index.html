<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Aymeric Damien">
  
  <title>Data Utils - TFLearn</title>
  

  <link rel="shortcut icon" href="../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../css/extra.css" rel="stylesheet">

  
  <script>
    // Current page data
    var mkdocs_page_name = "Data Utils";
    var mkdocs_page_input_path = "data_utils.md";
    var mkdocs_page_url = "/data_utils/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script>
  <script src="../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> TFLearn</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Home</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../doc_index/">Index</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../installation/">Installation</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../getting_started/">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../examples/">Examples</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Models</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../models/dnn/">Deep Neural Network</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../models/generator/">Generative Neural Network</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Layers</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/core/">Core Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/conv/">Convolutional Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/recurrent/">Recurrent Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/normalization/">Normalization Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/embedding_ops/">Embedding Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/merge_ops/">Merge Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../layers/estimator/">Estimator Layers</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Built-in Ops</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../activations/">Activations</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../objectives/">Objectives</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../optimizers/">Optimizers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../metrics/">Metrics</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../initializations/">Initializations</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../losses/">Losses</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../summaries/">Summaries</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../variables/">Variables</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Data Management</span></li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">Data Utils</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#vocabulary-processor">Vocabulary Processor</a></li>
                
            
                <li class="toctree-l3"><a href="#to_categorical">to_categorical</a></li>
                
            
                <li class="toctree-l3"><a href="#pad_sequences">pad_sequences</a></li>
                
            
                <li class="toctree-l3"><a href="#string_to_semi_redundant_sequences">string_to_semi_redundant_sequences</a></li>
                
            
                <li class="toctree-l3"><a href="#build-hdf5-image-dataset">Build HDF5 Image Dataset</a></li>
                
            
                <li class="toctree-l3"><a href="#image-preloader">Image PreLoader</a></li>
                
            
                <li class="toctree-l3"><a href="#shuffle">shuffle</a></li>
                
            
                <li class="toctree-l3"><a href="#samplewise_zero_center">samplewise_zero_center</a></li>
                
            
                <li class="toctree-l3"><a href="#samplewise_std_normalization">samplewise_std_normalization</a></li>
                
            
                <li class="toctree-l3"><a href="#featurewise_zero_center">featurewise_zero_center</a></li>
                
            
                <li class="toctree-l3"><a href="#featurewise_std_normalization">featurewise_std_normalization</a></li>
                
            
                <li class="toctree-l3"><a href="#load_csv">load_csv</a></li>
                
            
            </ul>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../data_preprocessing/">Data Preprocessing</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../data_augmentation/">Data Augmentation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../data_flow/">Data Flow</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Others</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../config/">Graph Config</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Helpers for Extending Tensorflow</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../helpers/trainer/">Trainer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../helpers/evaluator/">Evaluator</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../helpers/summarizer/">Summarizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../helpers/regularizer/">Regularizer</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../contributions/">Contributions</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../license/">License</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">TFLearn</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Data Management &raquo;</li>
        
      
    
    <li>Data Utils</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/tflearn/tflearn" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="vocabulary-processor">Vocabulary Processor</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.VocabularyProcessor</b></span>  (max_document_length,  min_frequency=0,  vocabulary=None,  tokenizer_fn=None)</span></p>
<p>Maps documents to sequences of word ids.</p>
<h3>Arguments</h3>

<ul>
<li><strong>max_document_length</strong>: Maximum length of documents.
if documents are longer, they will be trimmed, if shorter - padded.</li>
<li><strong>min_frequency</strong>: Minimum frequency of words in the vocabulary.</li>
<li><strong>vocabulary</strong>: CategoricalVocabulary object.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>vocabulary_</strong>: CategoricalVocabulary object.</li>
</ul>
<h2>Methods</h2>

<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>fit</b></span>  (raw_documents,  unused_y=None)</span></p>
<p>Learn a vocabulary dictionary of all tokens in the raw documents.</p>
<h5>Arguments</h5>

<ul>
<li><strong>raw_documents</strong>: An iterable which yield either str or unicode.</li>
<li><strong>unused_y</strong>: to match fit format signature of estimators.</li>
</ul>
<h5>Returns</h5>

<p>self</p>
<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>fit_transform</b></span>  (raw_documents,  unused_y=None)</span></p>
<p>Learn the vocabulary dictionary and return indexies of words.</p>
<h5>Arguments</h5>

<ul>
<li><strong>raw_documents</strong>: An iterable which yield either str or unicode.</li>
<li><strong>unused_y</strong>: to match fit_transform signature of estimators.</li>
</ul>
<h5>Returns</h5>

<p>X: iterable, [n_samples, max_document_length] Word-id matrix.</p>
<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>restore</b></span>  (cls,  filename)</span></p>
<p>Restores vocabulary processor from given file.</p>
<h5>Arguments</h5>

<ul>
<li><strong>filename</strong>: Path to file to load from.</li>
</ul>
<h5>Returns</h5>

<p>VocabularyProcessor object.</p>
<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>reverse</b></span>  (documents)</span></p>
<p>Reverses output of vocabulary mapping to words.</p>
<h5>Arguments</h5>

<ul>
<li><strong>documents</strong>: iterable, list of class ids.</li>
</ul>
<h5>Returns</h5>

<p>Iterator over mapped in words documents.</p>
<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>save</b></span>  (filename)</span></p>
<p>Saves vocabulary processor into given file.</p>
<h5>Arguments</h5>

<ul>
<li><strong>filename</strong>: Path to output file.</li>
</ul>
<p><span class="hr_large"></span> </p>
<p><span class="extra_h2"><span style="color:black"><b>transform</b></span>  (raw_documents)</span></p>
<p>Transform documents to word-id matrix.</p>
<p>Convert words to ids with vocabulary fitted with fit or the one
provided in the constructor.</p>
<h5>Arguments</h5>

<ul>
<li><strong>raw_documents</strong>: An iterable which yield either str or unicode.</li>
</ul>
<hr />
<h1 id="to_categorical">to_categorical</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.to_categorical</b></span>  (y,  nb_classes)</span></p>
<p>Convert class vector (integers from 0 to nb_classes)
to binary class matrix, for use with categorical_crossentropy.</p>
<h3>Arguments</h3>

<ul>
<li><strong>y</strong>: <code>array</code>. Class vector to convert.</li>
<li><strong>nb_classes</strong>: <code>int</code>. Total number of classes.</li>
</ul>
<hr />
<h1 id="pad_sequences">pad_sequences</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.pad_sequences</b></span>  (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0)</span></p>
<p>Pad each sequence to the same length: the length of the longest sequence.
If maxlen is provided, any sequence longer than maxlen is truncated to
maxlen. Truncation happens off either the beginning or the end (default) 
of the sequence. Supports pre-padding and post-padding (default).</p>
<h3>Arguments</h3>

<ul>
<li><strong>sequences</strong>: list of lists where each element is a sequence.</li>
<li><strong>maxlen</strong>: int, maximum length.</li>
<li><strong>dtype</strong>: type to cast the resulting sequence.</li>
<li><strong>padding</strong>: 'pre' or 'post', pad either before or after each sequence.</li>
<li><strong>truncating</strong>: 'pre' or 'post', remove values from sequences larger than
maxlen either in the beginning or in the end of the sequence</li>
<li><strong>value</strong>: float, value to pad the sequences to the desired value.</li>
</ul>
<h3>Returns</h3>

<p>x: <code>numpy array</code> with dimensions (number_of_sequences, maxlen)</p>
<hr />
<h1 id="string_to_semi_redundant_sequences">string_to_semi_redundant_sequences</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.string_to_semi_redundant_sequences</b></span>  (string,  seq_maxlen=25,  redun_step=3)</span></p>
<p>Vectorize a string and returns parsed sequences and targets, along with
the associated dictionary.</p>
<h3>Arguments</h3>

<ul>
<li><strong>string</strong>: <code>str</code>. Lower-case text from input text file.</li>
<li><strong>seq_maxlen</strong>: <code>int</code>. Maximum length of a sequence. Default: 25.</li>
<li><strong>redun_step</strong>: <code>int</code>. Redundancy step. Default: 3.</li>
</ul>
<h3>Returns</h3>

<p>A tuple: (inputs, targets, dictionary)</p>
<hr />
<h1 id="build-hdf5-image-dataset">Build HDF5 Image Dataset</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.build_hdf5_image_dataset</b></span>  (target_path,  image_shape,  output_path='dataset.h5',  mode='file',  categorical_labels=True,  normalize=True,  grayscale=False,  files_extension=None,  chunks=True)</span></p>
<p>Build an HDF5 dataset by providing either a root folder or a plain text
file with images path and class id.</p>
<p>'folder' mode: Root folder should be arranged as follow:</p>
<pre><code>ROOT_FOLDER -&gt; SUBFOLDER_0 (CLASS 0) -&gt; CLASS0_IMG1.jpg -&gt; CLASS0_IMG2.jpg -&gt; ...-&gt; SUBFOLDER_1 (CLASS 1) -&gt; CLASS1_IMG1.jpg -&gt; ...-&gt; ...
</code></pre>

<p>Note that if sub-folders are not integers from 0 to n_classes, an id will
be assigned to each sub-folder following alphabetical order.</p>
<p>'file' mode: Plain text file should be formatted as follow:</p>
<pre><code>/path/to/img1 class_id
/path/to/img2 class_id
/path/to/img3 class_id
</code></pre>

<h3>Examples</h3>

<pre><code># Load path/class_id image file:
dataset_file = 'my_dataset.txt'

# Build a HDF5 dataset (only required once)
from tflearn.data_utils import build_hdf5_image_dataset
build_hdf5_image_dataset(dataset_file, image_shape=(128, 128), mode='file', output_path='dataset.h5', categorical_labels=True, normalize=True)

# Load HDF5 dataset
import h5py
h5f = h5py.File('dataset.h5', 'w')
X = h5f['X']
Y = h5f['Y']

# Build neural network and train
network = ...
model = DNN(network, ...)
model.fit(X, Y)
</code></pre>

<h3>Arguments</h3>

<ul>
<li><strong>target_path</strong>: <code>str</code>. Path of root folder or images plain text file.</li>
<li><strong>image_shape</strong>: <code>tuple (height, width)</code>. The images shape. Images that
doesn't match that shape will be resized.</li>
<li><strong>output_path</strong>: <code>str</code>. The output path for the hdf5 dataset. Default:
'dataset.h5'</li>
<li><strong>mode</strong>: <code>str</code> in ['file', 'folder']. The data source mode. 'folder'
accepts a root folder with each of his sub-folder representing a
class containing the images to classify.
'file' accepts a single plain text file that contains every
image path with their class id.
Default: 'folder'.</li>
<li><strong>categorical_labels</strong>: <code>bool</code>. If True, labels are converted to binary
vectors.</li>
<li><strong>normalize</strong>: <code>bool</code>. If True, normalize all pictures by dividing
every image array by 255.</li>
<li><strong>grayscale</strong>: <code>bool</code>. If true, images are converted to grayscale.</li>
<li><strong>files_extension</strong>: <code>list of str</code>. A list of allowed image file
extension, for example ['.jpg', '.jpeg', '.png']. If None,
all files are allowed.</li>
<li><strong>chunks</strong>: <code>bool</code> or <code>list of int</code>. Whether to chunks the dataset or not.
Additionaly, a specific shape for each chunk can be provided.</li>
</ul>
<hr />
<h1 id="image-preloader">Image PreLoader</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.image_preloader</b></span>  (target_path,  image_shape,  mode='file',  normalize=True,  grayscale=False,  categorical_labels=True,  files_extension=None)</span></p>
<p>Create a python array (<code>Preloader</code>) that loads images on the fly (from
disk or url). There is two ways to provide image samples 'folder' or
'file', see the specifications below.</p>
<p>'folder' mode: Load images from disk, given a root folder. This folder
should be arranged as follow:</p>
<pre><code>ROOT_FOLDER -&gt; SUBFOLDER_0 (CLASS 0) -&gt; CLASS0_IMG1.jpg -&gt; CLASS0_IMG2.jpg -&gt; ...-&gt; SUBFOLDER_1 (CLASS 1) -&gt; CLASS1_IMG1.jpg -&gt; ...-&gt; ...
</code></pre>

<p>Note that if sub-folders are not integers from 0 to n_classes, an id will
be assigned to each sub-folder following alphabetical order.</p>
<p>'file' mode: A plain text file listing every image path and class id.
This file should be formatted as follow:</p>
<pre><code>/path/to/img1 class_id
/path/to/img2 class_id
/path/to/img3 class_id
</code></pre>

<p>Note that load images on the fly and convert is time inefficient,
so you can instead use <code>build_hdf5_image_dataset</code> to build a HDF5 dataset
that enable fast retrieval (this function takes similar arguments).</p>
<h3>Examples</h3>

<pre><code># Load path/class_id image file:
dataset_file = 'my_dataset.txt'

# Build the preloader array, resize images to 128x128
from tflearn.data_utils import image_preloader
X, Y = image_preloader(dataset_file, image_shape=(128, 128),   mode='file', categorical_labels=True,   normalize=True)

# Build neural network and train
network = ...
model = DNN(network, ...)
model.fit(X, Y)
</code></pre>

<h3>Arguments</h3>

<ul>
<li><strong>target_path</strong>: <code>str</code>. Path of root folder or images plain text file.</li>
<li><strong>image_shape</strong>: <code>tuple (height, width)</code>. The images shape. Images that
doesn't match that shape will be resized.</li>
<li><strong>mode</strong>: <code>str</code> in ['file', 'folder']. The data source mode. 'folder'
accepts a root folder with each of his sub-folder representing a
class containing the images to classify.
'file' accepts a single plain text file that contains every
image path with their class id.
Default: 'folder'.</li>
<li><strong>categorical_labels</strong>: <code>bool</code>. If True, labels are converted to binary
vectors.</li>
<li><strong>normalize</strong>: <code>bool</code>. If True, normalize all pictures by dividing
every image array by 255.</li>
<li><strong>grayscale</strong>: <code>bool</code>. If true, images are converted to grayscale.</li>
<li><strong>files_extension</strong>: <code>list of str</code>. A list of allowed image file
extension, for example ['.jpg', '.jpeg', '.png']. If None,
all files are allowed.</li>
</ul>
<h3>Returns</h3>

<p>(X, Y): with X the images array and Y the labels array.</p>
<hr />
<h1 id="shuffle">shuffle</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.shuffle</b></span>  (*arrs)</span></p>
<p>Shuffle given arrays at unison, along first axis.</p>
<h3>Arguments</h3>

<ul>
<li>*arrs: Each array to shuffle at unison.</li>
</ul>
<h3>Returns</h3>

<p>Tuple of shuffled arrays.</p>
<hr />
<h1 id="samplewise_zero_center">samplewise_zero_center</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.samplewise_zero_center</b></span>  (X)</span></p>
<p>Zero center each sample by subtracting it by its mean.</p>
<h3>Arguments</h3>

<ul>
<li><strong>X</strong>: <code>array</code>. The batch of samples to center.</li>
</ul>
<h3>Returns</h3>

<p>A numpy array with same shape as input.</p>
<hr />
<h1 id="samplewise_std_normalization">samplewise_std_normalization</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.samplewise_std_normalization</b></span>  (X)</span></p>
<p>Scale each sample with its standard deviation.</p>
<h3>Arguments</h3>

<ul>
<li><strong>X</strong>: <code>array</code>. The batch of samples to scale.</li>
</ul>
<h3>Returns</h3>

<p>A numpy array with same shape as input.</p>
<hr />
<h1 id="featurewise_zero_center">featurewise_zero_center</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.featurewise_zero_center</b></span>  (X,  mean=None)</span></p>
<p>Zero center every sample with specified mean. If not specified, the mean
is evaluated over all samples.</p>
<h3>Arguments</h3>

<ul>
<li><strong>X</strong>: <code>array</code>. The batch of samples to center.</li>
<li><strong>mean</strong>: <code>float</code>. The mean to use for zero centering. If not specified, it
will be evaluated on provided data.</li>
</ul>
<h3>Returns</h3>

<p>A numpy array with same shape as input. Or a tuple (array, mean) if no
mean value was specified.</p>
<hr />
<h1 id="featurewise_std_normalization">featurewise_std_normalization</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.featurewise_std_normalization</b></span>  (X,  std=None)</span></p>
<p>Scale each sample by the specified standard deviation. If no std
specified, std is evaluated over all samples data.</p>
<h3>Arguments</h3>

<ul>
<li><strong>X</strong>: <code>array</code>. The batch of samples to scale.</li>
<li><strong>std</strong>: <code>float</code>. The std to use for scaling data. If not specified, it
will be evaluated over the provided data.</li>
</ul>
<h3>Returns</h3>

<p>A numpy array with same shape as input. Or a tuple (array, std) if no
std value was specified.</p>
<hr />
<h1 id="load_csv">load_csv</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.data_utils.load_csv</b></span>  (filepath,  target_column=-1,  categorical_labels=False,  columns_to_ignore=None,  has_header=True,  dtype=<type  'numpy.float32'>,  target_type=<type  'numpy.int64'>)</span></p>
<p>Load data from a CSV file. By default the labels are considered to be the
last column, but it can be changed by filling 'target_column' parameter.</p>
<h3>Arguments</h3>

<ul>
<li><strong>filepath</strong>: <code>str</code>. The csv file path.</li>
<li><strong>target_column</strong>: The id of the column representing the labels.
Default: -1 (The last column).</li>
<li><strong>categorical_labels</strong>: <code>bool</code>. If True, labels are returned as binary
vectors (to be used with 'categorical_crossentropy').</li>
<li><strong>columns_to_ignore</strong>: <code>list of int</code>. A list of columns index to ignore.</li>
<li><strong>has_header</strong>: <code>bool</code>. Whether the csv file has a header or not.</li>
<li><strong>dtype</strong>: The data type. Default: float32.</li>
<li><strong>target_type</strong>: The target type. Default: int64.</li>
</ul>
<h3>Returns</h3>

<p>A tuple (data, target).</p>
<hr />
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../data_preprocessing/" class="btn btn-neutral float-right" title="Data Preprocessing">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../variables/" class="btn btn-neutral" title="Variables"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/tflearn/tflearn" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../variables/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../data_preprocessing/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
