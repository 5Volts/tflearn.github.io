<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Aymeric Damien">
  
  <title>Convolutional Layers - TFLearn</title>
  

  <link rel="shortcut icon" href="../../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  <link href="../../css/extra.css" rel="stylesheet">

  
  <script>
    // Current page data
    var mkdocs_page_name = "Convolutional Layers";
    var mkdocs_page_input_path = "layers/conv.md";
    var mkdocs_page_url = "/layers/conv/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script>
  <script src="../../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> TFLearn</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../..">Home</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../doc_index/">Index</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../installation/">Installation</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../getting_started/">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../examples/">Examples</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Models</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/dnn/">Deep Neural Network</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../models/generator/">Generative Neural Network</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Layers</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../core/">Core Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">Convolutional Layers</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#convolution-3d">Convolution 3D</a></li>
                
            
                <li class="toctree-l3"><a href="#convolution-2d">Convolution 2D</a></li>
                
            
                <li class="toctree-l3"><a href="#convolution-2d-transpose">Convolution 2D Transpose</a></li>
                
            
                <li class="toctree-l3"><a href="#max-pooling-2d">Max Pooling 2D</a></li>
                
            
                <li class="toctree-l3"><a href="#max-pooling-3d">Max Pooling 3D</a></li>
                
            
                <li class="toctree-l3"><a href="#average-pooling-3d">Average Pooling 3D</a></li>
                
            
                <li class="toctree-l3"><a href="#average-pooling-2d">Average Pooling 2D</a></li>
                
            
                <li class="toctree-l3"><a href="#upsample-2d">UpSample 2D</a></li>
                
            
                <li class="toctree-l3"><a href="#upscore">Upscore</a></li>
                
            
                <li class="toctree-l3"><a href="#convolution-1d">Convolution 1D</a></li>
                
            
                <li class="toctree-l3"><a href="#max-pooling-1d">Max Pooling 1D</a></li>
                
            
                <li class="toctree-l3"><a href="#average-pooling-1d">Average Pooling 1D</a></li>
                
            
                <li class="toctree-l3"><a href="#global-average-pooling">Global Average Pooling</a></li>
                
            
                <li class="toctree-l3"><a href="#residual-block">Residual Block</a></li>
                
            
                <li class="toctree-l3"><a href="#residual-bottleneck">Residual Bottleneck</a></li>
                
            
                <li class="toctree-l3"><a href="#highway-convolution-2d">Highway Convolution 2D</a></li>
                
            
                <li class="toctree-l3"><a href="#highway-convolution-1d">Highway Convolution 1D</a></li>
                
            
            </ul>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../recurrent/">Recurrent Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../normalization/">Normalization Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../embedding_ops/">Embedding Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../merge_ops/">Merge Layers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../estimator/">Estimator Layers</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Built-in Ops</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../activations/">Activations</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../objectives/">Objectives</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../optimizers/">Optimizers</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../metrics/">Metrics</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../initializations/">Initializations</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../losses/">Losses</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../summaries/">Summaries</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../variables/">Variables</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Data Management</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../data_utils/">Data Utils</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../data_preprocessing/">Data Preprocessing</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../data_augmentation/">Data Augmentation</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../data_flow/">Data Flow</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Others</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../config/">Graph Config</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Helpers for Extending Tensorflow</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../helpers/trainer/">Trainer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../helpers/evaluator/">Evaluator</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../helpers/summarizer/">Summarizer</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../helpers/regularizer/">Regularizer</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../contributions/">Contributions</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../license/">License</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">TFLearn</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Layers &raquo;</li>
        
      
    
    <li>Convolutional Layers</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/tflearn/tflearn" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="convolution-3d">Convolution 3D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.conv_3d</b></span>  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='Conv3D')</span></p>
<h3>Input</h3>

<p>5-D Tensor [batch, in_depth, in_height, in_width, in_channels].</p>
<h3>Output</h3>

<p>5-D Tensor [filter_depth, filter_height, filter_width, in_channels, out_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 5-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: <code>int</code> or <code>list of int</code>. Size of filters.</li>
<li><strong>strides</strong>: 'int<code>or list of</code>int`. Strides of conv operation.
Default: [1 1 1 1 1]. Must have strides[0] = strides[4] = 1.</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Conv3D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
</ul>
<hr />
<h1 id="convolution-2d">Convolution 2D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.conv_2d</b></span>  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='Conv2D')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, new height, new width, nb_filter].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: <code>int</code> or <code>list of int</code>. Size of filters.</li>
<li><strong>strides</strong>: 'int<code>or list of</code>int`. Strides of conv operation.
Default: [1 1 1 1].</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Conv2D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
</ul>
<hr />
<h1 id="convolution-2d-transpose">Convolution 2D Transpose</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.conv_2d_transpose</b></span>  (incoming,  nb_filter,  filter_size,  output_shape,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='Conv2DTranspose')</span></p>
<p>This operation is sometimes called "deconvolution" after (Deconvolutional
Networks)[http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf], but is
actually the transpose (gradient) of <code>conv_2d</code> rather than an actual
deconvolution.</p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, new height, new width, nb_filter].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: <code>int</code> or <code>list of int</code>. Size of filters.</li>
<li><strong>output_shape</strong>: <code>list of int</code>. Dimensions of the output tensor.
Can optionally include the number of conv filters.
[new height, new width, nb_filter] or [new height, new width].</li>
<li><strong>strides</strong>: <code>int</code> or list of <code>int</code>. Strides of conv operation.
Default: [1 1 1 1].</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Conv2DTranspose'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
</ul>
<hr />
<h1 id="max-pooling-2d">Max Pooling 2D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.max_pool_2d</b></span>  (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool2D')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, pooled height, pooled width, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Pooling kernel size.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: same as kernel_size.</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'MaxPool2D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="max-pooling-3d">Max Pooling 3D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.max_pool_3d</b></span>  (incoming,  kernel_size,  strides=1,  padding='same',  name='MaxPool3D')</span></p>
<h3>Input</h3>

<p>5-D Tensor [batch, depth, rows, cols, channels].</p>
<h3>Output</h3>

<p>5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 5-D Layer.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Pooling kernel size.Must have kernel_size[0] = kernel_size[1] = 1</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.Must have strides[0] = strides[4] = 1.
Default: [1 1 1 1 1]</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'MaxPool3D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="average-pooling-3d">Average Pooling 3D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.avg_pool_3d</b></span>  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool3D')</span></p>
<h3>Input</h3>

<p>5-D Tensor [batch, depth, rows, cols, channels].</p>
<h3>Output</h3>

<p>5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 5-D Layer.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Pooling kernel size.Must have kernel_size[0] = kernel_size[1] = 1</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.Must have strides[0] = strides[4] = 1.
Default: [1 1 1 1 1]</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'AvgPool3D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="average-pooling-2d">Average Pooling 2D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.avg_pool_2d</b></span>  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool2D')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, pooled height, pooled width, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Pooling kernel size.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: same as kernel_size.</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'AvgPool2D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="upsample-2d">UpSample 2D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.upsample_2d</b></span>  (incoming,  kernel_size,  name='UpSample2D')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, pooled height, pooled width, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer to upsample.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Upsampling kernel size.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'UpSample2D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="upscore">Upscore</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.upscore_layer</b></span>  (incoming,  num_classes,  shape=None,  kernel_size=4,  strides=2,  name='Upscore')</span></p>
<p>This implements the upscore layer as used in
(Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038].
The upscore layer is initialized as bilinear upsampling filter.</p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, pooled height, pooled width, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer to upsample.</li>
<li><strong>num_classes</strong>: <code>int</code>. Number of output feature maps.</li>
<li><strong>shape</strong>: <code>list of int</code>. Dimension of the output map
[batch_size, new height, new width]. For convinience four values
 are allows [batch_size, new height, new width, X], where X
 is ignored.</li>
<li><strong>kernel_size</strong>: 'int<code>or</code>list of int`. Upsampling kernel size.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: [1 2 2 1].</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Upscore'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<h3>Links</h3>

<p>(Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038]</p>
<hr />
<h1 id="convolution-1d">Convolution 1D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.conv_1d</b></span>  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='Conv1D')</span></p>
<h3>Input</h3>

<p>3-D Tensor [batch, steps, in_channels].</p>
<h3>Output</h3>

<p>3-D Tensor [batch, new steps, nb_filters].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 3-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: 'int<code>or</code>list of int`. Size of filters.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: [1 1 1 1].</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Conv1D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
</ul>
<hr />
<h1 id="max-pooling-1d">Max Pooling 1D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.max_pool_1d</b></span>  (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool1D')</span></p>
<h3>Input</h3>

<p>3-D Tensor [batch, steps, in_channels].</p>
<h3>Output</h3>

<p>3-D Tensor [batch, pooled steps, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 3-D Layer.</li>
<li><strong>kernel_size</strong>: <code>int</code> or <code>list of int</code>. Pooling kernel size.</li>
<li><strong>strides</strong>: <code>int</code> or <code>list of int</code>. Strides of conv operation.
Default: same as kernel_size.</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'MaxPool1D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="average-pooling-1d">Average Pooling 1D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.avg_pool_1d</b></span>  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool1D')</span></p>
<h3>Input</h3>

<p>3-D Tensor [batch, steps, in_channels].</p>
<h3>Output</h3>

<p>3-D Tensor [batch, pooled steps, in_channels].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 3-D Layer.</li>
<li><strong>kernel_size</strong>: <code>int</code> or <code>list of int</code>. Pooling kernel size.</li>
<li><strong>strides</strong>: <code>int</code> or <code>list of int</code>. Strides of conv operation.
Default: same as kernel_size.</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'AvgPool1D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
</ul>
<hr />
<h1 id="global-average-pooling">Global Average Pooling</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.global_avg_pool</b></span>  (incoming,  name='GlobalAvgPool')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>2-D Tensor [batch, pooled dim]</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Tensor.</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'GlobalAvgPool'.</li>
</ul>
<hr />
<h1 id="residual-block">Residual Block</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.residual_block</b></span>  (incoming,  nb_blocks,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  name='ResidualBlock')</span></p>
<p>A residual block as described in MSRA's Deep Residual Network paper.
Full pre-activation architecture is used here.</p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, new height, new width, nb_filter].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer.</li>
<li><strong>nb_blocks</strong>: <code>int</code>. Number of layer blocks.</li>
<li><strong>out_channels</strong>: <code>int</code>. The number of convolutional filters of the
convolution layers.</li>
<li><strong>downsample</strong>: <code>bool</code>. If True, apply downsampling using
'downsample_strides' for strides.</li>
<li><strong>downsample_strides</strong>: <code>int</code>. The strides to use when downsampling.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>batch_norm</strong>: <code>bool</code>. If True, apply batch normalization.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'uniform_scaling'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>tf.Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'ShallowBottleneck'.</li>
</ul>
<h3>References</h3>

<ul>
<li>Deep Residual Learning for Image Recognition. Kaiming He, Xiangyu
Zhang, Shaoqing Ren, Jian Sun. 2015.</li>
<li>Identity Mappings in Deep Residual Networks. Kaiming He, Xiangyu
Zhang, Shaoqing Ren, Jian Sun. 2015.</li>
</ul>
<h3>Links</h3>

<ul>
<li><a href="http://arxiv.org/pdf/1512.03385v1.pdf">http://arxiv.org/pdf/1512.03385v1.pdf</a></li>
<li><a href="https://arxiv.org/pdf/1603.05027v2.pdf">Identity Mappings in Deep Residual Networks</a></li>
</ul>
<hr />
<h1 id="residual-bottleneck">Residual Bottleneck</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.residual_bottleneck</b></span>  (incoming,  nb_blocks,  bottleneck_size,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  name='ResidualBottleneck')</span></p>
<p>A residual bottleneck block as described in MSRA's Deep Residual Network
paper. Full pre-activation architecture is used here.</p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, new height, new width, nb_filter].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Layer.</li>
<li><strong>nb_blocks</strong>: <code>int</code>. Number of layer blocks.</li>
<li><strong>bottleneck_size</strong>: <code>int</code>. The number of convolutional filter of the
bottleneck convolutional layer.</li>
<li><strong>out_channels</strong>: <code>int</code>. The number of convolutional filters of the
layers surrounding the bottleneck layer.</li>
<li><strong>downsample</strong>: <code>bool</code>. If True, apply downsampling using
'downsample_strides' for strides.</li>
<li><strong>downsample_strides</strong>: <code>int</code>. The strides to use when downsampling.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>batch_norm</strong>: <code>bool</code>. If True, apply batch normalization.</li>
<li><strong>bias</strong>: <code>bool</code>. If True, a bias is used.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'uniform_scaling'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>tf.Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'DeepBottleneck'.</li>
</ul>
<h3>References</h3>

<ul>
<li>Deep Residual Learning for Image Recognition. Kaiming He, Xiangyu
Zhang, Shaoqing Ren, Jian Sun. 2015.</li>
<li>Identity Mappings in Deep Residual Networks. Kaiming He, Xiangyu
Zhang, Shaoqing Ren, Jian Sun. 2015.</li>
</ul>
<h3>Links</h3>

<ul>
<li><a href="http://arxiv.org/pdf/1512.03385v1.pdf">http://arxiv.org/pdf/1512.03385v1.pdf</a></li>
<li><a href="https://arxiv.org/pdf/1603.05027v2.pdf">Identity Mappings in Deep Residual Networks</a></li>
</ul>
<hr />
<h1 id="highway-convolution-2d">Highway Convolution 2D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.highway_conv_2d</b></span>  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='HighwayConv2D')</span></p>
<h3>Input</h3>

<p>4-D Tensor [batch, height, width, in_channels].</p>
<h3>Output</h3>

<p>4-D Tensor [batch, new height, new width, nb_filter].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 4-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: 'int<code>or</code>list of int`. Size of filters.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: [1 1 1 1].</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'Conv2D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>W_T</strong>: <code>Variable</code>. Variable representing gate weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
<li><strong>b_T</strong>: <code>Variable</code>. Variable representing gate biases.</li>
</ul>
<hr />
<h1 id="highway-convolution-1d">Highway Convolution 1D</h1>
<p><span class="extra_h1"><span style="color:black;"><b>tflearn.layers.conv.highway_conv_1d</b></span>  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  name='HighwayConv1D')</span></p>
<h3>Input</h3>

<p>3-D Tensor [batch, steps, in_channels].</p>
<h3>Output</h3>

<p>3-D Tensor [batch, new steps, nb_filters].</p>
<h3>Arguments</h3>

<ul>
<li><strong>incoming</strong>: <code>Tensor</code>. Incoming 3-D Tensor.</li>
<li><strong>nb_filter</strong>: <code>int</code>. The number of convolutional filters.</li>
<li><strong>filter_size</strong>: 'int<code>or</code>list of int`. Size of filters.</li>
<li><strong>strides</strong>: 'int<code>or</code>list of int`. Strides of conv operation.
Default: [1 1 1 1].</li>
<li><strong>padding</strong>: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
Default: 'same'.</li>
<li><strong>activation</strong>: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).
Activation applied to this layer (see tflearn.activations).
Default: 'linear'.</li>
<li><strong>weights_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.
(see tflearn.initializations) Default: 'truncated_normal'.</li>
<li><strong>bias_init</strong>: <code>str</code> (name) or <code>Tensor</code>. Bias initialization.
(see tflearn.initializations) Default: 'zeros'.</li>
<li><strong>regularizer</strong>: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this
layer weights (see tflearn.regularizers). Default: None.</li>
<li><strong>weight_decay</strong>: <code>float</code>. Regularizer decay parameter. Default: 0.001.</li>
<li><strong>trainable</strong>: <code>bool</code>. If True, weights will be trainable.</li>
<li><strong>restore</strong>: <code>bool</code>. If True, this layer weights will be restored when
loading a model</li>
<li><strong>name</strong>: A name for this layer (optional). Default: 'HighwayConv1D'.</li>
</ul>
<h3>Attributes</h3>

<ul>
<li><strong>scope</strong>: <code>Scope</code>. This layer scope.</li>
<li><strong>W</strong>: <code>Variable</code>. Variable representing filter weights.</li>
<li><strong>W_T</strong>: <code>Variable</code>. Variable representing gate weights.</li>
<li><strong>b</strong>: <code>Variable</code>. Variable representing biases.</li>
<li><strong>b_T</strong>: <code>Variable</code>. Variable representing gate biases.</li>
</ul>
<hr />
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../recurrent/" class="btn btn-neutral float-right" title="Recurrent Layers">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../core/" class="btn btn-neutral" title="Core Layers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/tflearn/tflearn" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../core/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../recurrent/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
