{
    "docs": [
        {
            "location": "/", 
            "text": "TFLearn: Deep learning library featuring a higher-level API for TensorFlow.\n\n\nTFlearn is a modular and transparent deep learning library built on top of Tensorflow.  It was designed to provide a higher-level API to TensorFlow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it.\n\n\nTFLearn features include:\n\n\n\n\nEasy-to-use and understand high-level API for implementing deep neural networks, with tutorial and examples.\n\n\nFast prototyping through highly modular built-in neural network layers, regularizers, optimizers, metrics...\n\n\nFull transparency over Tensorflow. All functions are built over tensors and can be used independently of TFLearn.\n\n\nPowerful helper functions to train any TensorFlow graph, with support of multiple inputs, outputs and optimizers.\n\n\nEasy and beautiful graph visualization, with details about weights, gradients, activations and more...\n\n\nEffortless device placement for using multiple CPU/GPU.\n\n\n\n\nThe high-level API currently supports most of recent deep learning models, such as Convolutions, LSTM, BiRNN, BatchNorm, PReLU, Residual networks, Generative networks... In the future, TFLearn is also intended to stay up-to-date with latest deep learning techniques.\n\n\nNote: This is the first release of TFLearn. Contributions are more than welcome!\n\n\nQuick overview\n\n\nCode Example\n\n\n# Classification\ntflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)\n\nnet = tflearn.input_data(shape=[None, 784])\nnet = tflearn.fully_connected(net, 64)\nnet = tflearn.dropout(net, 0.5)\nnet = tflearn.fully_connected(net, 10, activation='softmax')\nnet = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n\nmodel = tflearn.DNN(net)\nmodel.fit(X, Y)\n\n\n\n\n# Sequence Generation\nnet = tflearn.input_data(shape=[None, 100, 5000])\nnet = tflearn.lstm(net, 64)\nnet = tflearn.dropout(net, 0.5)\nnet = tflearn.fully_connected(net, 5000, activation='softmax')\nnet = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n\nmodel = tflearn.SequenceGenerator(net, dictionary=idx, seq_maxlen=100)\nmodel.fit(X, Y)\nmodel.generate(50, temperature=1.0)\n\n\n\n\nThere are many more examples available \nhere\n.\n\n\nWhere to Start?\n\n\nTo install TFLearn, see: \nInstallation Guide\n.\n\n\nIf your version of Tensorflow is under 0.7: \nUpgrade Tensorflow\n.\n\n\nFor a tutorial: \nGetting Started with TFLearn\n.\n\n\nFor more examples: \nExamples List\n.\n\n\nTo browse the API, check the \nAPI Documentation\n.\n\n\nModel Visualization\n\n\nGraph\n\n\n\n\nLoss \n Accuracy (multiple runs)\n\n\n\n\nLayers\n\n\n\n\nSources\n\n\nGitHub: \nhttps://github.com/tflearn/tflearn\n.\n\n\nContributions\n\n\nThis is the first release of TFLearn, if you find any bug, please report it in the GitHub issues section.\n\n\nImprovements and requests for new features are more than welcome! Do not hesitate to twist and tweak TFLearn, and send pull-requests.\n\n\nFor more info: \nContribute to TFLearn\n.\n\n\nLicense\n\n\nMIT License", 
            "title": "Home"
        }, 
        {
            "location": "/#tflearn-deep-learning-library-featuring-a-higher-level-api-for-tensorflow", 
            "text": "TFlearn is a modular and transparent deep learning library built on top of Tensorflow.  It was designed to provide a higher-level API to TensorFlow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it.  TFLearn features include:   Easy-to-use and understand high-level API for implementing deep neural networks, with tutorial and examples.  Fast prototyping through highly modular built-in neural network layers, regularizers, optimizers, metrics...  Full transparency over Tensorflow. All functions are built over tensors and can be used independently of TFLearn.  Powerful helper functions to train any TensorFlow graph, with support of multiple inputs, outputs and optimizers.  Easy and beautiful graph visualization, with details about weights, gradients, activations and more...  Effortless device placement for using multiple CPU/GPU.   The high-level API currently supports most of recent deep learning models, such as Convolutions, LSTM, BiRNN, BatchNorm, PReLU, Residual networks, Generative networks... In the future, TFLearn is also intended to stay up-to-date with latest deep learning techniques.  Note: This is the first release of TFLearn. Contributions are more than welcome!", 
            "title": "TFLearn: Deep learning library featuring a higher-level API for TensorFlow."
        }, 
        {
            "location": "/#quick-overview", 
            "text": "Code Example  # Classification\ntflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)\n\nnet = tflearn.input_data(shape=[None, 784])\nnet = tflearn.fully_connected(net, 64)\nnet = tflearn.dropout(net, 0.5)\nnet = tflearn.fully_connected(net, 10, activation='softmax')\nnet = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n\nmodel = tflearn.DNN(net)\nmodel.fit(X, Y)  # Sequence Generation\nnet = tflearn.input_data(shape=[None, 100, 5000])\nnet = tflearn.lstm(net, 64)\nnet = tflearn.dropout(net, 0.5)\nnet = tflearn.fully_connected(net, 5000, activation='softmax')\nnet = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n\nmodel = tflearn.SequenceGenerator(net, dictionary=idx, seq_maxlen=100)\nmodel.fit(X, Y)\nmodel.generate(50, temperature=1.0)  There are many more examples available  here .", 
            "title": "Quick overview"
        }, 
        {
            "location": "/#where-to-start", 
            "text": "To install TFLearn, see:  Installation Guide .  If your version of Tensorflow is under 0.7:  Upgrade Tensorflow .  For a tutorial:  Getting Started with TFLearn .  For more examples:  Examples List .  To browse the API, check the  API Documentation .", 
            "title": "Where to Start?"
        }, 
        {
            "location": "/#model-visualization", 
            "text": "Graph   Loss   Accuracy (multiple runs)   Layers", 
            "title": "Model Visualization"
        }, 
        {
            "location": "/#sources", 
            "text": "GitHub:  https://github.com/tflearn/tflearn .", 
            "title": "Sources"
        }, 
        {
            "location": "/#contributions", 
            "text": "This is the first release of TFLearn, if you find any bug, please report it in the GitHub issues section.  Improvements and requests for new features are more than welcome! Do not hesitate to twist and tweak TFLearn, and send pull-requests.  For more info:  Contribute to TFLearn .", 
            "title": "Contributions"
        }, 
        {
            "location": "/#license", 
            "text": "MIT License", 
            "title": "License"
        }, 
        {
            "location": "/doc_index/", 
            "text": "Documentation index\n\n\nBase\n\n\n\n\nIntroduction\n\n\nDocumentation Index\n\n\nTFLearn Installation\n\n\nGetting Started with TFLearn\n\n\nTFLearn Examples\n\n\n\n\nAPI\n\n\n\n\nModels\n\n\nDeep Neural Network\n\n\nGenerative Neural Network\n\n\n\n\n\n\nLayers\n\n\nCore Layers\n\n\nConvolutional Layers\n\n\nRecurrent Layers\n\n\nNormalization Layers\n\n\nEmbedding Layers\n\n\nMerge Layers\n\n\n\n\n\n\nBuilt-in Ops\n\n\nActivations\n\n\nObjectives\n\n\nOptimizers\n\n\nMetrics\n\n\nInitializations\n  \n\n\nLosses\n\n\nSummaries\n\n\n\n\n\n\nHelpers for extending Tensorflow\n\n\nTrainer\n\n\nEvaluator\n\n\nSummarizer\n\n\nRegularizer\n\n\n\n\n\n\nOthers\n\n\nGraph Configuration\n\n\nData Utilities\n\n\n\n\n\n\n\n\nOthers\n\n\n\n\nContributions\n\n\nLicense", 
            "title": "Index"
        }, 
        {
            "location": "/doc_index/#documentation-index", 
            "text": "", 
            "title": "Documentation index"
        }, 
        {
            "location": "/doc_index/#base", 
            "text": "Introduction  Documentation Index  TFLearn Installation  Getting Started with TFLearn  TFLearn Examples", 
            "title": "Base"
        }, 
        {
            "location": "/doc_index/#api", 
            "text": "Models  Deep Neural Network  Generative Neural Network    Layers  Core Layers  Convolutional Layers  Recurrent Layers  Normalization Layers  Embedding Layers  Merge Layers    Built-in Ops  Activations  Objectives  Optimizers  Metrics  Initializations     Losses  Summaries    Helpers for extending Tensorflow  Trainer  Evaluator  Summarizer  Regularizer    Others  Graph Configuration  Data Utilities", 
            "title": "API"
        }, 
        {
            "location": "/doc_index/#others", 
            "text": "Contributions  License", 
            "title": "Others"
        }, 
        {
            "location": "/installation/", 
            "text": "Installation\n\n\nTensorflow Installation\n\n\nTFLearn requires Tensorflow (version \n= 0.7.0) to be installed.\n\n\n# Ubuntu/Linux 64-bit, CPU only:\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled:\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only:\neasy_install --upgrade six\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl\n\n\n\n\n\n\nFor more details: \nTensorflow installation instructions\n.\n\n\n\n\nTFLearn Installation\n\n\nTo install TFLearn, the easiest way is to run\n\n\nFor the bleeding edge version:\n\n\npip install git+https://github.com/tflearn/tflearn.git\n\n\n\n\nFor the latest stable version:\n\n\npip install tflearn\n\n\n\n\nOtherwise, you can also install from source by running (from source folder):\n\n\npython setup.py install\n\n\n\n\nUpgrade Tensorflow\n\n\nIf you version for Tensorflow is too old (under 0.8.0), you may upgrade Tensorflow to avoid some incompatibilities with TFLearn.\nTo upgrade Tensorflow, you first need to uninstall Tensorflow and Protobuf:\n\n\npip uninstall protobuf\npip uninstall tensorflow\n\n\n\n\nThen you can re-install Tensorflow:\n\n\n# Ubuntu/Linux 64-bit, CPU only, Python 2.7:\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7. Requires CUDA toolkit 7.5 and cuDNN v4.\n# For other versions, see \nInstall from sources\n below.\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only:\n$ sudo easy_install --upgrade six\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl\n\n\n\n\nUsing Latest Tensorflow\n\n\nTFLearn is compatible with \nmaster version\n of Tensorflow, but some warnings may appear.", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#tensorflow-installation", 
            "text": "TFLearn requires Tensorflow (version  = 0.7.0) to be installed.  # Ubuntu/Linux 64-bit, CPU only:\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled:\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only:\neasy_install --upgrade six\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl   For more details:  Tensorflow installation instructions .", 
            "title": "Tensorflow Installation"
        }, 
        {
            "location": "/installation/#tflearn-installation", 
            "text": "To install TFLearn, the easiest way is to run  For the bleeding edge version:  pip install git+https://github.com/tflearn/tflearn.git  For the latest stable version:  pip install tflearn  Otherwise, you can also install from source by running (from source folder):  python setup.py install", 
            "title": "TFLearn Installation"
        }, 
        {
            "location": "/installation/#upgrade-tensorflow", 
            "text": "If you version for Tensorflow is too old (under 0.8.0), you may upgrade Tensorflow to avoid some incompatibilities with TFLearn.\nTo upgrade Tensorflow, you first need to uninstall Tensorflow and Protobuf:  pip uninstall protobuf\npip uninstall tensorflow  Then you can re-install Tensorflow:  # Ubuntu/Linux 64-bit, CPU only, Python 2.7:\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7. Requires CUDA toolkit 7.5 and cuDNN v4.\n# For other versions, see  Install from sources  below.\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only:\n$ sudo easy_install --upgrade six\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl", 
            "title": "Upgrade Tensorflow"
        }, 
        {
            "location": "/installation/#using-latest-tensorflow", 
            "text": "TFLearn is compatible with  master version  of Tensorflow, but some warnings may appear.", 
            "title": "Using Latest Tensorflow"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting started with TFLearn\n\n\nHere is a basic guide that introduces TFLearn and its functionalities. First, highlighting TFLearn high-level API for fast neural network building and training, and then showing how TFLearn layers, built-in ops and helpers can directly benefit any model implementation with Tensorflow.\n\n\nHigh-Level API usage\n\n\nTFLearn introduces a High-Level API that makes neural network building and training fast and easy. This API is intuitive and fully compatible with Tensorflow.\n\n\nLayers\n\n\nLayers are a core feature of TFLearn. While completely defining a model using Tensorflow ops can be time consuming and repetitive, TFLearn brings \"layers\" that represent an abstract set of operations to make building neural networks more convenient. For example, a convolutional layer will:\n\n\n\n\nCreate and initialize weights and biases variables\n\n\nApply convolution over incoming tensor\n\n\nAdd an activation function after the convolution\n\n\netc...\n\n\n\n\nIn Tensorflow, writing these kinds of operations can be quite tedious:\n\n\nwith tf.name_scope('conv1'):\n    W = tf.Variable(tf.random_normal([5, 5, 1, 32]), dtype=tf.float32, name='Weights')\n    b = tf.Variable(tf.random_normal([32]), dtype=tf.float32, name='biases')\n    x = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n    x = tf.add_bias(W, b)\n    x = tf.nn.relu(x)\n\n\n\n\nWhile in TFLearn, it only takes a line:\n\n\ntflearn.conv_2d(x, 32, 5, activation='relu', name='conv1')\n\n\n\n\nHere is a list of all currently available layers:\n\n\n\n\n\n\n\n\nFile\n\n\nLayers\n\n\n\n\n\n\n\n\n\n\ncore\n\n\ninput_data, fully_connected, dropout, custom_layer, reshape, flatten, activation, single_unit, highway, one_hot_encoding\n\n\n\n\n\n\nconv\n\n\nconv_2d, conv_2d_transpose, max_pool_2d, avg_pool_2d, upsample_2d, conv_1d, max_pool_1d, avg_pool_1d, residual_block, residual_bottleneck, conv_3d, max_pool_3d, avg_pool_3d, highway_conv_2d\n\n\n\n\n\n\nrecurrent\n\n\nsimple_rnn, lstm, gru, bidirectionnal_rnn, dynamic_rnn\n\n\n\n\n\n\nembedding\n\n\nembedding\n\n\n\n\n\n\nnormalization\n\n\nbatch_normalization, local_response_normalization\n\n\n\n\n\n\nmerge\n\n\nmerge, merge_outputs\n\n\n\n\n\n\nestimator\n\n\nregression\n\n\n\n\n\n\n\n\nBuilt-in Operations\n\n\nBesides layers concept, TFLearn also provides many different ops to be used when building a neural network. These ops are firstly mean to be be part of the above 'layers' arguments, but they can also be used independently in any other Tensorflow graph for convenience. In practice, just providing the op name as argument is enough (such as activation='relu' or regularizer='L2' for conv_2d), but a function can also be provided for further customization.\n\n\n\n\n\n\n\n\nFile\n\n\nOps\n\n\n\n\n\n\n\n\n\n\nactivations\n\n\nlinear, tanh, sigmoid, softmax, softplus, softsign, relu, relu6, leaky_relu, prelu, elu\n\n\n\n\n\n\nobjectives\n\n\nsoftmax_categorical_crossentropy, categorical_crossentropy, binary_crossentropy, mean_square, hinge_loss\n\n\n\n\n\n\noptimizers\n\n\nSGD, RMSProp, Adam, Momentum, AdaGrad, Ftrl, AdaDelta\n\n\n\n\n\n\nmetrics\n\n\nAccuracy, Top_k, R2\n\n\n\n\n\n\ninitializations\n\n\nzeros, uniform, uniform_scaling, normal, truncated_normal\n\n\n\n\n\n\nlosses\n\n\nl1, l2\n\n\n\n\n\n\n\n\nBelow are some quick examples:\n\n\n# Activation and Regularization inside a layer:\nfc2 = tflearn.fully_connected(fc1, 32, activation='tanh', regularizer='L2')\n# Equivalent to:\nfc2 = tflearn.fully_connected(fc1, 32)\ntflearn.add_weights_regularization(fc2, loss='L2')\nfc2 = tflearn.tanh(fc2)\n\n# Optimizer, Objective and Metric:\nreg = tflearn.regression(fc4, optimizer='rmsprop', metric='accuracy', loss='categorical_crossentropy')\n# Ops can also be defined outside, for deeper customization:\nmomentum = tflearn.optimizers.Momentum(learning_rate=0.1, weight_decay=0.96, decay_step=200)\ntop5 = tflearn.metrics.Top_k(k=5)\nreg = tflearn.regression(fc4, optimizer=momentum, metric=top5, loss='categorical_crossentropy')\n\n\n\n\nTraining, Evaluating \n Predicting\n\n\nTraining functions are another core feature of TFLearn. In Tensorflow, there are no pre-built API to train a network, so TFLearn integrates a set of functions that can easily handle any neural network training, whatever the number of inputs, outputs and optimizers.\n\n\nWhile using TFlearn layers, many parameters are already self managed, so it is very easy to train a model, using \nDNN\n model class:\n\n\nnetwork = ... (some layers) ...\nnetwork = regression(network, optimizer='sgd', loss='categorical_crossentropy')\n\nmodel = DNN(network)\nmodel.fit(X, Y)\n\n\n\n\nIt can also directly be called for prediction, or evaluation:\n\n\nnetwork = ...\n\nmodel = DNN(network)\nmodel.load('model.tflearn')\nmodel.predict(X)\n\n\n\n\n\n\nTo learn more about these wrappers, see: \ndnn\n and \nestimator\n.\n\n\n\n\nVisualization\n\n\nWhile writing a Tensorflow model and adding tensorboard summaries isn't very practical, TFLearn has the ability to self managed a lot of useful logs. Currently, TFLearn supports a verbose level to automatically manage summaries:\n\n\n\n\n0: Loss \n Metric (Best speed).\n\n\n1: Loss, Metric \n Gradients.\n\n\n2: Loss, Metric, Gradients \n Weights.\n\n\n3: Loss, Metric, Gradients, Weights, Activations \n Sparsity (Best Visualization).\n\n\n\n\nUsing \nDNN\n model class, it just requires to specify the verbose argument:\n\n\nmodel = DNN(network, tensorboard_verbose=3)\n\n\n\n\nThen, Tensorboard can be run to visualize network and performance:\n\n\n$ tensorboard --logdir='/tmp/tflearn_logs'\n\n\n\n\nGraph\n\n\n\n\nLoss \n Accuracy (multiple runs)\n\n\n\n\nLayers\n\n\n\n\nWeights persistence\n\n\nTo save or restore a model, simply invoke 'save' or 'load' method of \nDNN\n model class.\n\n\n# Save a model\nmodel.save('my_model.tflearn')\n# Load a model\nmodel.load('my_model.tflearn')\n\n\n\n\nRetrieving a layer variables can either be done using the layer name, or directly by using 'W' or 'b' attributes that are supercharged to the layer's returned Tensor.\n\n\n# Let's create a layer\nfc1 = fully_connected(input_layer, 64, name=\nfc_layer_1\n)\n# Using Tensor attributes (Layer will supercharge the returned Tensor with weights attributes)\nfc1_weights_var = fc1.W\nfc1_biases_var = fc1.b\n# Using Tensor name\nfc1_vars = tflearn.get_layer_variables_by_name(\nfc_layer_1\n)\nfc1_weights_var = fc1_vars[0]\nfc1_biases_var = fc1_vars[1]\n\n\n\n\nTo get or set the value of these variables, TFLearn models class implement \nget_weights\n and \nset_weights\n methods:\n\n\ninput_data = tflearn.input_data(shape=[None, 784])\nfc1 = tflearn.fully_connected(input_data, 64)\nfc2 = tflearn.fully_connected(input_data, 10, activation='softmax')\nnet = tflearn.regression(fc1)\nmodel = DNN(net)\n# Get weights values of fc1\nmodel.get_weights(fc1.W)\n# Assign new random weights to fc1\nmodel.set_weights(fc1.W, numpy.random.rand(64, 10))\n\n\n\n\nNote that you can also directly use TensorFlow \neval\n or \nassign\n ops to get or set the value of these variables.\n\n\n\n\nFor an example, see: \nweights_persistence.py\n.\n\n\n\n\nFine-tuning\n\n\nFine-tune a pre-trained model on a new task might be useful in many cases. So, when defining a model in TFLearn, you can specify which layer's weights you want to be restored or not (when loading pre-trained model). This can be handle with the 'restore' argument of layer functions (only available for layers with weights).\n\n\n# Weights will be restored by default.\nfc_layer = tflearn.fully_connected(input_layer, 32)\n# Weights will not be restored, if specified so.\nfc_layer = tflearn.fully_connected(input_layer, 32, restore='False')\n\n\n\n\nAll weights that doesn't need to be restored will be added to tf.GraphKeys.EXCL_RESTORE_VARS collection, and when loading a pre-trained model, these variables restoration will simply be ignored.\nThe following example shows how to fine-tune a network on a new task by restoring all weights except the last fully connected layer, and then train the new model on a new dataset:\n\n\n\n\nFine-tuning example: \nfinetuning.py\n.\n\n\n\n\nData management\n\n\nTFLearn supports numpy array data. Additionally, it also supports HDF5 for handling large datasets. HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data (\nmore info\n). TFLearn can directly use HDF5 formatted data:\n\n\n# Load hdf5 dataset\nh5f = h5py.File('data.h5', 'r')\nX, Y = h5f['MyLargeData']\n\n... define network ...\n\n# Use HDF5 data model to train model\nmodel = DNN(network)\nmodel.fit(X, Y)\n\n\n\n\nFor an example, see: \nhdf5.py\n.\n\n\nData Preprocessing and Data Augmentation\n\n\nIt is common to perform data pre-processing and data augmentation while training a model, so TFLearn provides wrappers to easily handle it. Note also that TFLearn data stream is designed with computing pipelines in order to speed-up training (by pre-processing data on CPU while GPU is performing model training).\n\n\n# Real-time image preprocessing\nimg_prep = tflearn.ImagePreprocessing()\n# Zero Center (With mean computed over the whole dataset)\nimg_prep.add_featurewise_zero_center()\n# STD Normalization (With std computed over the whole dataset)\nimg_prep.add_featurewise_stdnorm()\n\n# Real-time data augmentation\nimg_aug = tflearn.ImageAugmentation()\n# Random flip an image\nimg_aug.add_random_flip_leftright()\n\n# Add these methods into an 'input_data' layer\nnetwork = input_data(shape=[None, 32, 32, 3],\n                     data_preprocessing=img_prep,\n                     data_augmentation=img_aug)\n\n\n\n\nFor more details, see \nData Preprocessing\n and \nData Augmentation\n\n\nScopes \n Weights sharing\n\n\nAll layers are built over 'variable_op_scope', that make it easy to share variables among multiple layers and make TFLearn suitable for distributed training. All layers with inner  variables support a 'scope' argument to place variables under; layers with same scope name will then share the same weights.\n\n\n# Define a model builder\ndef my_model(x):\n    x = tflearn.fully_connected(x, 32, scope='fc1')\n    x = tflearn.fully_connected(x, 32, scope='fc2')\n    x = tflearn.fully_connected(x, 2, scope='out')\n\n# 2 different computation graph but sharing the same weights\nwith tf.device('/gpu:0')\n    # Force all Variables to reside on the CPU.\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model1 = my_model(placeholder_X)\n# Reuse Variables for the next model\ntf.get_variable_scope().reuse_variables()\nwith tf.device('/gpu:1')\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model2 = my_model(placeholder_X)\n\n# Model can now be trained by multiple GPUs (see gradient averaging)\n...\n\n\n\n\nGraph Initialization\n\n\nIt might be useful to limit resources, or assigns more or less GPU RAM memory while training. To do so, a graph initializer can be used to configure a graph before run:\n\n\ntflearn.init_graph(set_seed=8888, num_cores=16, gpu_memory_fraction=0.5)\n\n\n\n\n\n\nSee: \nconfig\n.\n\n\n\n\nExtending Tensorflow\n\n\nTFLearn is a very flexible library designed to let you use any of its component independently. A model can be succinctly built using any combination of Tensorflow operations and TFLearn built-in layers and operations. The following instructions will show you the basics for extending Tensorflow with TFLearn.\n\n\nLayers\n\n\nAny layer can be used with any other Tensor from Tensorflow, this means that you can directly use TFLearn wrappers into your own Tensorflow graph.\n\n\n# Some operations using Tensorflow.\nX = tf.placeholder(shape=(None, 784), dtype=tf.float32)\nnet = tf.reshape(X, [-1, 28, 28, 1])\n\n# Using TFLearn convolution layer.\nnet = tflearn.conv_2d(net, 32, 3, activation='relu')\n\n# Using Tensorflow's max pooling op.\nnet = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n...\n\n\n\n\n\n\nFor an example, see: \nlayers.py\n.\n\n\n\n\nBuilt-in Operations\n\n\nTFLearn built-in ops makes Tensorflow graphs writing faster and more readable. So, similar to layers, built-in ops are fully compatible with any TensorFlow expression. The following code example shows how to use them along with pure Tensorflow API.\n\n\n\n\nSee: \nbuiltin_ops.py\n.\n\n\n\n\nHere is a list of available ops, click on the file for more details:\n\n\n\n\n\n\n\n\nFile\n\n\nOps\n\n\n\n\n\n\n\n\n\n\nactivations\n\n\nlinear, tanh, sigmoid, softmax, softplus, softsign, relu, relu6, leaky_relu, prelu, elu\n\n\n\n\n\n\nobjectives\n\n\nsoftmax_categorical_crossentropy, categorical_crossentropy, binary_crossentropy, mean_square, hinge_loss\n\n\n\n\n\n\noptimizers\n\n\nSGD, RMSProp, Adam, Momentum, AdaGrad, Ftrl, AdaDelta\n\n\n\n\n\n\nmetrics\n\n\nAccuracy, Top_k, R2\n\n\n\n\n\n\ninitializations\n\n\nzeros, uniform, uniform_scaling, normal, truncated_normal\n\n\n\n\n\n\nlosses\n\n\nl1, l2\n\n\n\n\n\n\n\n\nNote:\n- Optimizers are designed as class and not function, for usage outside of TFlearn models, check: \noptimizers\n.\n\n\nTrainer / Evaluator / Predictor\n\n\nIf you are using you own Tensorflow model, TFLearn also provides some 'helpers' functions that can train any Tensorflow graph. It is suitable to make training more convenient, by introducing realtime monitoring, batch sampling, moving averages, tensorboard logs, data feeding, etc... It supports any number of inputs, outputs and optimization ops.\n\n\nTFLearn implements a \nTrainOp\n class to represent an optimization process (i.e. backprop). It is defined as follow:\n\n\ntrainop = TrainOp(net=my_network, loss=loss, metric=accuracy)\n\n\n\n\nThen, all TrainOp can be feeded into a \nTrainer\n class, that will handle the whole training process, considering all TrainOp together as a whole model.\n\n\nmodel = Trainer(trainops=trainop, tensorboard_dir='/tmp/tflearn')\nmodel.fit(feed_dict={input_placeholder: X, target_placeholder: Y})\n\n\n\n\nWhile most models will only have a single optimization process, it can be useful for more complex models to handle multiple ones.\n\n\nmodel = Trainer(trainops=[trainop1, trainop2])\nmodel.fit(feed_dict=[{in1: X1, label1: Y1}, {in2: X2, in3: X3, label2: Y2}])\n\n\n\n\n\n\n\n\nTo learn more about TrainOp and Trainer, see: \ntrainer\n.\n\n\n\n\n\n\nFor an example, see: \ntrainer.py\n.\n\n\n\n\n\n\nFor prediction, TFLearn implements a \nEvaluator\n class that is working in a similar way as \nTrainer\n. It takes any network as parameter and return the predicted value.\n\n\nmodel = Evaluator(network)\nmodel.predict(feed_dict={input_placeholder: X})\n\n\n\n\n\n\nTo learn more about Evaluator class: \nevaluator\n.\n\n\n\n\nTo handle networks that have layer with different behavior at training and testing time (such as dropout and batch normalization), \nTrainer\n class uses a boolean variable ('is_training'), that specifies if the network is used for training or testing/predicting. This variable is stored under tf.GraphKeys.IS_TRAINING collection, as its first (and only) element.\nSo, when defining such layers, this variable should be used as the op condition:\n\n\n# Example for Dropout:\nx = ...\n\ndef apply_dropout(): # Function to apply when training mode ON.\n  return tf.nn.dropout(x, keep_prob)\n\nis_training = tflearn.get_training_mode() # Retrieve is_training variable.\ntf.cond(is_training, apply_dropout, lambda: x) # Only apply dropout at training time.\n\n\n\n\nTo make it easy, TFLearn implements functions to retrieve that variable or change its value:\n\n\n# Set training mode ON (set is_training var to True)\ntflearn.is_training(True)\n# Set training mode OFF (set is_training var to False)\ntflearn.is_training(False)\n\n\n\n\n\n\nSee: \ntraining config\n.\n\n\n\n\nVariables\n\n\nTFLearn defines a set of functions for users to quickly define variables.\n\n\nWhile in Tensorflow, variable creation requires predefined value or initializer, as well as an explicit device placement, TFLearn simplify variable definition:\n\n\nimport tflearn.variables as vs\nmy_var = vs.variable('W',\n                     shape=[784, 128],\n                     initializer='truncated_normal',\n                     regularizer='L2',\n                     device='/gpu:0')\n\n\n\n\n\n\nFor an example, see: \nvariables.py\n.\n\n\n\n\nSummaries\n\n\nWhen using \nTrainer\n class, it is also very easy to manage summaries. It just additionally required that the activations to monitor are stored into \ntf.GraphKeys.ACTIVATIONS\n collection.\n\n\nThen, simply specify a verbose level to control visualization depth:\n\n\nmodel = Trainer(network, loss=loss, metric=acc, tensorboard_verbose=3)\n\n\n\n\nBeside \nTrainer\n self-managed summaries option, you can also directly use TFLearn ops to quickly add summaries to your current Tensorflow graph.\n\n\nimport tflearn.helpers.summarizer as s\ns.summarize_variables(train_vars=[...]) # Summarize all given variables' weights (All trainable variables if None).\ns.summarize_activations(activations=[...]) # Summarize all given activations\ns.summarize_gradients(grads=[...]) # Summarize all given variables' gradient (All trainable variables if None).\ns.summarize(value, type) # Summarize anything.\n\n\n\n\nEvery function above accepts a collection as parameter, and will return a merged summary over that collection (Default name: 'tflearn_summ'). So you just need to run the last summarizer to get the whole summary ops collection, already merged.\n\n\ns.summarize_variables(collection='my_summaries')\ns.Summarize_gradients(collection='my_summaries')\nsummary_op = s.summarize_activations(collection='my_summaries')\n# summary_op is a the merged op of previously define weights, gradients and activations summary ops.\n\n\n\n\n\n\nFor an example, see: \nsummaries.py\n.\n\n\n\n\nRegularizers\n\n\nAdd regularization to a model can be completed using TFLearn \nregularizer\n. It currently supports weights and activation regularization. Available regularization losses can be found in \nhere\n. All regularization losses are stored into tf.GraphKeys.REGULARIZATION_LOSSES collection.\n\n\n# Add L2 regularization to a variable\nW = tf.Variable(tf.random_normal([784, 256]), name=\nW\n)\ntflearn.add_weight_regularizer(W, 'L2', weight_decay=0.001)\n\n\n\n\nPreprocessing\n\n\nBesides tensor operations, it might be useful to perform some preprocessing on input data. Thus, TFLearn has a set of preprocessing functions to make data manipulation more convenient (such as sequence padding, categorical labels, shuffling at unison, image processing, etc...).\n\n\n\n\nFor more details, see: \ndata_utils\n.\n\n\n\n\nGetting Further\n\n\nThere are a lot of examples along with numerous neural network\nimplementations available for you to practice TFLearn more in depth:\n\n\n\n\nSee: \nExamples\n.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#getting-started-with-tflearn", 
            "text": "Here is a basic guide that introduces TFLearn and its functionalities. First, highlighting TFLearn high-level API for fast neural network building and training, and then showing how TFLearn layers, built-in ops and helpers can directly benefit any model implementation with Tensorflow.", 
            "title": "Getting started with TFLearn"
        }, 
        {
            "location": "/getting_started/#high-level-api-usage", 
            "text": "TFLearn introduces a High-Level API that makes neural network building and training fast and easy. This API is intuitive and fully compatible with Tensorflow.", 
            "title": "High-Level API usage"
        }, 
        {
            "location": "/getting_started/#layers", 
            "text": "Layers are a core feature of TFLearn. While completely defining a model using Tensorflow ops can be time consuming and repetitive, TFLearn brings \"layers\" that represent an abstract set of operations to make building neural networks more convenient. For example, a convolutional layer will:   Create and initialize weights and biases variables  Apply convolution over incoming tensor  Add an activation function after the convolution  etc...   In Tensorflow, writing these kinds of operations can be quite tedious:  with tf.name_scope('conv1'):\n    W = tf.Variable(tf.random_normal([5, 5, 1, 32]), dtype=tf.float32, name='Weights')\n    b = tf.Variable(tf.random_normal([32]), dtype=tf.float32, name='biases')\n    x = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n    x = tf.add_bias(W, b)\n    x = tf.nn.relu(x)  While in TFLearn, it only takes a line:  tflearn.conv_2d(x, 32, 5, activation='relu', name='conv1')  Here is a list of all currently available layers:     File  Layers      core  input_data, fully_connected, dropout, custom_layer, reshape, flatten, activation, single_unit, highway, one_hot_encoding    conv  conv_2d, conv_2d_transpose, max_pool_2d, avg_pool_2d, upsample_2d, conv_1d, max_pool_1d, avg_pool_1d, residual_block, residual_bottleneck, conv_3d, max_pool_3d, avg_pool_3d, highway_conv_2d    recurrent  simple_rnn, lstm, gru, bidirectionnal_rnn, dynamic_rnn    embedding  embedding    normalization  batch_normalization, local_response_normalization    merge  merge, merge_outputs    estimator  regression", 
            "title": "Layers"
        }, 
        {
            "location": "/getting_started/#built-in-operations", 
            "text": "Besides layers concept, TFLearn also provides many different ops to be used when building a neural network. These ops are firstly mean to be be part of the above 'layers' arguments, but they can also be used independently in any other Tensorflow graph for convenience. In practice, just providing the op name as argument is enough (such as activation='relu' or regularizer='L2' for conv_2d), but a function can also be provided for further customization.     File  Ops      activations  linear, tanh, sigmoid, softmax, softplus, softsign, relu, relu6, leaky_relu, prelu, elu    objectives  softmax_categorical_crossentropy, categorical_crossentropy, binary_crossentropy, mean_square, hinge_loss    optimizers  SGD, RMSProp, Adam, Momentum, AdaGrad, Ftrl, AdaDelta    metrics  Accuracy, Top_k, R2    initializations  zeros, uniform, uniform_scaling, normal, truncated_normal    losses  l1, l2     Below are some quick examples:  # Activation and Regularization inside a layer:\nfc2 = tflearn.fully_connected(fc1, 32, activation='tanh', regularizer='L2')\n# Equivalent to:\nfc2 = tflearn.fully_connected(fc1, 32)\ntflearn.add_weights_regularization(fc2, loss='L2')\nfc2 = tflearn.tanh(fc2)\n\n# Optimizer, Objective and Metric:\nreg = tflearn.regression(fc4, optimizer='rmsprop', metric='accuracy', loss='categorical_crossentropy')\n# Ops can also be defined outside, for deeper customization:\nmomentum = tflearn.optimizers.Momentum(learning_rate=0.1, weight_decay=0.96, decay_step=200)\ntop5 = tflearn.metrics.Top_k(k=5)\nreg = tflearn.regression(fc4, optimizer=momentum, metric=top5, loss='categorical_crossentropy')", 
            "title": "Built-in Operations"
        }, 
        {
            "location": "/getting_started/#training-evaluating-predicting", 
            "text": "Training functions are another core feature of TFLearn. In Tensorflow, there are no pre-built API to train a network, so TFLearn integrates a set of functions that can easily handle any neural network training, whatever the number of inputs, outputs and optimizers.  While using TFlearn layers, many parameters are already self managed, so it is very easy to train a model, using  DNN  model class:  network = ... (some layers) ...\nnetwork = regression(network, optimizer='sgd', loss='categorical_crossentropy')\n\nmodel = DNN(network)\nmodel.fit(X, Y)  It can also directly be called for prediction, or evaluation:  network = ...\n\nmodel = DNN(network)\nmodel.load('model.tflearn')\nmodel.predict(X)   To learn more about these wrappers, see:  dnn  and  estimator .", 
            "title": "Training, Evaluating &amp; Predicting"
        }, 
        {
            "location": "/getting_started/#visualization", 
            "text": "While writing a Tensorflow model and adding tensorboard summaries isn't very practical, TFLearn has the ability to self managed a lot of useful logs. Currently, TFLearn supports a verbose level to automatically manage summaries:   0: Loss   Metric (Best speed).  1: Loss, Metric   Gradients.  2: Loss, Metric, Gradients   Weights.  3: Loss, Metric, Gradients, Weights, Activations   Sparsity (Best Visualization).   Using  DNN  model class, it just requires to specify the verbose argument:  model = DNN(network, tensorboard_verbose=3)  Then, Tensorboard can be run to visualize network and performance:  $ tensorboard --logdir='/tmp/tflearn_logs'  Graph   Loss   Accuracy (multiple runs)   Layers", 
            "title": "Visualization"
        }, 
        {
            "location": "/getting_started/#weights-persistence", 
            "text": "To save or restore a model, simply invoke 'save' or 'load' method of  DNN  model class.  # Save a model\nmodel.save('my_model.tflearn')\n# Load a model\nmodel.load('my_model.tflearn')  Retrieving a layer variables can either be done using the layer name, or directly by using 'W' or 'b' attributes that are supercharged to the layer's returned Tensor.  # Let's create a layer\nfc1 = fully_connected(input_layer, 64, name= fc_layer_1 )\n# Using Tensor attributes (Layer will supercharge the returned Tensor with weights attributes)\nfc1_weights_var = fc1.W\nfc1_biases_var = fc1.b\n# Using Tensor name\nfc1_vars = tflearn.get_layer_variables_by_name( fc_layer_1 )\nfc1_weights_var = fc1_vars[0]\nfc1_biases_var = fc1_vars[1]  To get or set the value of these variables, TFLearn models class implement  get_weights  and  set_weights  methods:  input_data = tflearn.input_data(shape=[None, 784])\nfc1 = tflearn.fully_connected(input_data, 64)\nfc2 = tflearn.fully_connected(input_data, 10, activation='softmax')\nnet = tflearn.regression(fc1)\nmodel = DNN(net)\n# Get weights values of fc1\nmodel.get_weights(fc1.W)\n# Assign new random weights to fc1\nmodel.set_weights(fc1.W, numpy.random.rand(64, 10))  Note that you can also directly use TensorFlow  eval  or  assign  ops to get or set the value of these variables.   For an example, see:  weights_persistence.py .", 
            "title": "Weights persistence"
        }, 
        {
            "location": "/getting_started/#fine-tuning", 
            "text": "Fine-tune a pre-trained model on a new task might be useful in many cases. So, when defining a model in TFLearn, you can specify which layer's weights you want to be restored or not (when loading pre-trained model). This can be handle with the 'restore' argument of layer functions (only available for layers with weights).  # Weights will be restored by default.\nfc_layer = tflearn.fully_connected(input_layer, 32)\n# Weights will not be restored, if specified so.\nfc_layer = tflearn.fully_connected(input_layer, 32, restore='False')  All weights that doesn't need to be restored will be added to tf.GraphKeys.EXCL_RESTORE_VARS collection, and when loading a pre-trained model, these variables restoration will simply be ignored.\nThe following example shows how to fine-tune a network on a new task by restoring all weights except the last fully connected layer, and then train the new model on a new dataset:   Fine-tuning example:  finetuning.py .", 
            "title": "Fine-tuning"
        }, 
        {
            "location": "/getting_started/#data-management", 
            "text": "TFLearn supports numpy array data. Additionally, it also supports HDF5 for handling large datasets. HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data ( more info ). TFLearn can directly use HDF5 formatted data:  # Load hdf5 dataset\nh5f = h5py.File('data.h5', 'r')\nX, Y = h5f['MyLargeData']\n\n... define network ...\n\n# Use HDF5 data model to train model\nmodel = DNN(network)\nmodel.fit(X, Y)  For an example, see:  hdf5.py .", 
            "title": "Data management"
        }, 
        {
            "location": "/getting_started/#data-preprocessing-and-data-augmentation", 
            "text": "It is common to perform data pre-processing and data augmentation while training a model, so TFLearn provides wrappers to easily handle it. Note also that TFLearn data stream is designed with computing pipelines in order to speed-up training (by pre-processing data on CPU while GPU is performing model training).  # Real-time image preprocessing\nimg_prep = tflearn.ImagePreprocessing()\n# Zero Center (With mean computed over the whole dataset)\nimg_prep.add_featurewise_zero_center()\n# STD Normalization (With std computed over the whole dataset)\nimg_prep.add_featurewise_stdnorm()\n\n# Real-time data augmentation\nimg_aug = tflearn.ImageAugmentation()\n# Random flip an image\nimg_aug.add_random_flip_leftright()\n\n# Add these methods into an 'input_data' layer\nnetwork = input_data(shape=[None, 32, 32, 3],\n                     data_preprocessing=img_prep,\n                     data_augmentation=img_aug)  For more details, see  Data Preprocessing  and  Data Augmentation", 
            "title": "Data Preprocessing and Data Augmentation"
        }, 
        {
            "location": "/getting_started/#scopes-weights-sharing", 
            "text": "All layers are built over 'variable_op_scope', that make it easy to share variables among multiple layers and make TFLearn suitable for distributed training. All layers with inner  variables support a 'scope' argument to place variables under; layers with same scope name will then share the same weights.  # Define a model builder\ndef my_model(x):\n    x = tflearn.fully_connected(x, 32, scope='fc1')\n    x = tflearn.fully_connected(x, 32, scope='fc2')\n    x = tflearn.fully_connected(x, 2, scope='out')\n\n# 2 different computation graph but sharing the same weights\nwith tf.device('/gpu:0')\n    # Force all Variables to reside on the CPU.\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model1 = my_model(placeholder_X)\n# Reuse Variables for the next model\ntf.get_variable_scope().reuse_variables()\nwith tf.device('/gpu:1')\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model2 = my_model(placeholder_X)\n\n# Model can now be trained by multiple GPUs (see gradient averaging)\n...", 
            "title": "Scopes &amp; Weights sharing"
        }, 
        {
            "location": "/getting_started/#graph-initialization", 
            "text": "It might be useful to limit resources, or assigns more or less GPU RAM memory while training. To do so, a graph initializer can be used to configure a graph before run:  tflearn.init_graph(set_seed=8888, num_cores=16, gpu_memory_fraction=0.5)   See:  config .", 
            "title": "Graph Initialization"
        }, 
        {
            "location": "/getting_started/#extending-tensorflow", 
            "text": "TFLearn is a very flexible library designed to let you use any of its component independently. A model can be succinctly built using any combination of Tensorflow operations and TFLearn built-in layers and operations. The following instructions will show you the basics for extending Tensorflow with TFLearn.", 
            "title": "Extending Tensorflow"
        }, 
        {
            "location": "/getting_started/#layers_1", 
            "text": "Any layer can be used with any other Tensor from Tensorflow, this means that you can directly use TFLearn wrappers into your own Tensorflow graph.  # Some operations using Tensorflow.\nX = tf.placeholder(shape=(None, 784), dtype=tf.float32)\nnet = tf.reshape(X, [-1, 28, 28, 1])\n\n# Using TFLearn convolution layer.\nnet = tflearn.conv_2d(net, 32, 3, activation='relu')\n\n# Using Tensorflow's max pooling op.\nnet = tf.nn.max_pool(net, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n...   For an example, see:  layers.py .", 
            "title": "Layers"
        }, 
        {
            "location": "/getting_started/#built-in-operations_1", 
            "text": "TFLearn built-in ops makes Tensorflow graphs writing faster and more readable. So, similar to layers, built-in ops are fully compatible with any TensorFlow expression. The following code example shows how to use them along with pure Tensorflow API.   See:  builtin_ops.py .   Here is a list of available ops, click on the file for more details:     File  Ops      activations  linear, tanh, sigmoid, softmax, softplus, softsign, relu, relu6, leaky_relu, prelu, elu    objectives  softmax_categorical_crossentropy, categorical_crossentropy, binary_crossentropy, mean_square, hinge_loss    optimizers  SGD, RMSProp, Adam, Momentum, AdaGrad, Ftrl, AdaDelta    metrics  Accuracy, Top_k, R2    initializations  zeros, uniform, uniform_scaling, normal, truncated_normal    losses  l1, l2     Note:\n- Optimizers are designed as class and not function, for usage outside of TFlearn models, check:  optimizers .", 
            "title": "Built-in Operations"
        }, 
        {
            "location": "/getting_started/#trainer-evaluator-predictor", 
            "text": "If you are using you own Tensorflow model, TFLearn also provides some 'helpers' functions that can train any Tensorflow graph. It is suitable to make training more convenient, by introducing realtime monitoring, batch sampling, moving averages, tensorboard logs, data feeding, etc... It supports any number of inputs, outputs and optimization ops.  TFLearn implements a  TrainOp  class to represent an optimization process (i.e. backprop). It is defined as follow:  trainop = TrainOp(net=my_network, loss=loss, metric=accuracy)  Then, all TrainOp can be feeded into a  Trainer  class, that will handle the whole training process, considering all TrainOp together as a whole model.  model = Trainer(trainops=trainop, tensorboard_dir='/tmp/tflearn')\nmodel.fit(feed_dict={input_placeholder: X, target_placeholder: Y})  While most models will only have a single optimization process, it can be useful for more complex models to handle multiple ones.  model = Trainer(trainops=[trainop1, trainop2])\nmodel.fit(feed_dict=[{in1: X1, label1: Y1}, {in2: X2, in3: X3, label2: Y2}])    To learn more about TrainOp and Trainer, see:  trainer .    For an example, see:  trainer.py .    For prediction, TFLearn implements a  Evaluator  class that is working in a similar way as  Trainer . It takes any network as parameter and return the predicted value.  model = Evaluator(network)\nmodel.predict(feed_dict={input_placeholder: X})   To learn more about Evaluator class:  evaluator .   To handle networks that have layer with different behavior at training and testing time (such as dropout and batch normalization),  Trainer  class uses a boolean variable ('is_training'), that specifies if the network is used for training or testing/predicting. This variable is stored under tf.GraphKeys.IS_TRAINING collection, as its first (and only) element.\nSo, when defining such layers, this variable should be used as the op condition:  # Example for Dropout:\nx = ...\n\ndef apply_dropout(): # Function to apply when training mode ON.\n  return tf.nn.dropout(x, keep_prob)\n\nis_training = tflearn.get_training_mode() # Retrieve is_training variable.\ntf.cond(is_training, apply_dropout, lambda: x) # Only apply dropout at training time.  To make it easy, TFLearn implements functions to retrieve that variable or change its value:  # Set training mode ON (set is_training var to True)\ntflearn.is_training(True)\n# Set training mode OFF (set is_training var to False)\ntflearn.is_training(False)   See:  training config .", 
            "title": "Trainer / Evaluator / Predictor"
        }, 
        {
            "location": "/getting_started/#variables", 
            "text": "TFLearn defines a set of functions for users to quickly define variables.  While in Tensorflow, variable creation requires predefined value or initializer, as well as an explicit device placement, TFLearn simplify variable definition:  import tflearn.variables as vs\nmy_var = vs.variable('W',\n                     shape=[784, 128],\n                     initializer='truncated_normal',\n                     regularizer='L2',\n                     device='/gpu:0')   For an example, see:  variables.py .", 
            "title": "Variables"
        }, 
        {
            "location": "/getting_started/#summaries", 
            "text": "When using  Trainer  class, it is also very easy to manage summaries. It just additionally required that the activations to monitor are stored into  tf.GraphKeys.ACTIVATIONS  collection.  Then, simply specify a verbose level to control visualization depth:  model = Trainer(network, loss=loss, metric=acc, tensorboard_verbose=3)  Beside  Trainer  self-managed summaries option, you can also directly use TFLearn ops to quickly add summaries to your current Tensorflow graph.  import tflearn.helpers.summarizer as s\ns.summarize_variables(train_vars=[...]) # Summarize all given variables' weights (All trainable variables if None).\ns.summarize_activations(activations=[...]) # Summarize all given activations\ns.summarize_gradients(grads=[...]) # Summarize all given variables' gradient (All trainable variables if None).\ns.summarize(value, type) # Summarize anything.  Every function above accepts a collection as parameter, and will return a merged summary over that collection (Default name: 'tflearn_summ'). So you just need to run the last summarizer to get the whole summary ops collection, already merged.  s.summarize_variables(collection='my_summaries')\ns.Summarize_gradients(collection='my_summaries')\nsummary_op = s.summarize_activations(collection='my_summaries')\n# summary_op is a the merged op of previously define weights, gradients and activations summary ops.   For an example, see:  summaries.py .", 
            "title": "Summaries"
        }, 
        {
            "location": "/getting_started/#regularizers", 
            "text": "Add regularization to a model can be completed using TFLearn  regularizer . It currently supports weights and activation regularization. Available regularization losses can be found in  here . All regularization losses are stored into tf.GraphKeys.REGULARIZATION_LOSSES collection.  # Add L2 regularization to a variable\nW = tf.Variable(tf.random_normal([784, 256]), name= W )\ntflearn.add_weight_regularizer(W, 'L2', weight_decay=0.001)", 
            "title": "Regularizers"
        }, 
        {
            "location": "/getting_started/#preprocessing", 
            "text": "Besides tensor operations, it might be useful to perform some preprocessing on input data. Thus, TFLearn has a set of preprocessing functions to make data manipulation more convenient (such as sequence padding, categorical labels, shuffling at unison, image processing, etc...).   For more details, see:  data_utils .", 
            "title": "Preprocessing"
        }, 
        {
            "location": "/getting_started/#getting-further", 
            "text": "There are a lot of examples along with numerous neural network\nimplementations available for you to practice TFLearn more in depth:   See:  Examples .", 
            "title": "Getting Further"
        }, 
        {
            "location": "/examples/", 
            "text": "TFLearn Examples\n\n\nBasics\n\n\n\n\nLinear Regression\n. Implement a linear regression using TFLearn.\n\n\nLogical Operators\n. Implement logical operators with TFLearn (also includes a usage of 'merge').\n\n\nWeights Persistence\n. Save and Restore a model.\n\n\nFine-Tuning\n. Fine-Tune a pre-trained model on a new task.\n\n\nUsing HDF5\n. Use HDF5 to handle large datasets.\n\n\nUsing DASK\n. Use DASK to handle large datasets.\n\n\n\n\nExtending TensorFlow\n\n\n\n\nLayers\n. Use TFLearn layers along with TensorFlow.\n\n\nTrainer\n. Use TFLearn trainer class to train any TensorFlow graph.\n\n\nBuilt-in Ops\n. Use TFLearn built-in operations along with TensorFlow.\n\n\nSummaries\n. Use TFLearn summarizers along with TensorFlow.\n\n\nVariables\n. Use TFLearn variables along with TensorFlow.\n\n\n\n\nComputer Vision\n\n\n\n\nMulti-layer perceptron\n. A multi-layer perceptron implementation for MNIST classification task.\n\n\nConvolutional Network (MNIST)\n. A Convolutional neural network implementation for classifying MNIST dataset.\n\n\nConvolutional Network (CIFAR-10)\n. A Convolutional neural network implementation for classifying CIFAR-10 dataset.\n\n\nNetwork in Network\n. 'Network in Network' implementation for classifying CIFAR-10 dataset.\n\n\nAlexnet\n. Apply Alexnet to Oxford Flowers 17 classification task.\n\n\nVGGNet\n. Apply VGG Network to Oxford Flowers 17 classification task.\n\n\nRNN Pixels\n. Use RNN (over sequence of pixels) to classify images.\n\n\nHighway Network\n. Highway Network implementation for classifying MNIST dataset.\n\n\nHighway Convolutional Network\n. Highway Convolutional Network implementation for classifying MNIST dataset.\n\n\nResidual Network (MNIST)\n. A bottleneck residual network applied to MNIST classification task.\n\n\nResidual Network (CIFAR-10)\n. A residual network applied to CIFAR-10 classification task.\n\n\nAuto Encoder\n. An auto encoder applied to MNIST handwritten digits.\n\n\n\n\nNatural Language Processing\n\n\n\n\nRecurrent Neural Network (LSTM)\n. Apply an LSTM to IMDB sentiment dataset classification task.\n\n\nBi-Directional RNN (LSTM)\n. Apply a bi-directional LSTM to IMDB sentiment dataset classification task.\n\n\nDynamic RNN (LSTM)\n. Apply a dynamic LSTM to classify variable length text from IMDB dataset.\n\n\nCity Name Generation\n. Generates new US-cities name, using LSTM network.\n\n\nShakespeare Scripts Generation\n. Generates new Shakespeare scripts, using LSTM network.\n\n\n\n\nReinforcement Learning\n\n\n\n\nAtari Pacman 1-step Q-Learning\n. Teach a machine to play Atari games (Pacman by default) using 1-step Q-learning.\n\n\n\n\nNotebooks\n\n\n\n\nSpiral Classification Problem\n. TFLearn implementation of spiral classification problem from Stanford CS231n.", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#tflearn-examples", 
            "text": "", 
            "title": "TFLearn Examples"
        }, 
        {
            "location": "/examples/#basics", 
            "text": "Linear Regression . Implement a linear regression using TFLearn.  Logical Operators . Implement logical operators with TFLearn (also includes a usage of 'merge').  Weights Persistence . Save and Restore a model.  Fine-Tuning . Fine-Tune a pre-trained model on a new task.  Using HDF5 . Use HDF5 to handle large datasets.  Using DASK . Use DASK to handle large datasets.", 
            "title": "Basics"
        }, 
        {
            "location": "/examples/#extending-tensorflow", 
            "text": "Layers . Use TFLearn layers along with TensorFlow.  Trainer . Use TFLearn trainer class to train any TensorFlow graph.  Built-in Ops . Use TFLearn built-in operations along with TensorFlow.  Summaries . Use TFLearn summarizers along with TensorFlow.  Variables . Use TFLearn variables along with TensorFlow.", 
            "title": "Extending TensorFlow"
        }, 
        {
            "location": "/examples/#computer-vision", 
            "text": "Multi-layer perceptron . A multi-layer perceptron implementation for MNIST classification task.  Convolutional Network (MNIST) . A Convolutional neural network implementation for classifying MNIST dataset.  Convolutional Network (CIFAR-10) . A Convolutional neural network implementation for classifying CIFAR-10 dataset.  Network in Network . 'Network in Network' implementation for classifying CIFAR-10 dataset.  Alexnet . Apply Alexnet to Oxford Flowers 17 classification task.  VGGNet . Apply VGG Network to Oxford Flowers 17 classification task.  RNN Pixels . Use RNN (over sequence of pixels) to classify images.  Highway Network . Highway Network implementation for classifying MNIST dataset.  Highway Convolutional Network . Highway Convolutional Network implementation for classifying MNIST dataset.  Residual Network (MNIST) . A bottleneck residual network applied to MNIST classification task.  Residual Network (CIFAR-10) . A residual network applied to CIFAR-10 classification task.  Auto Encoder . An auto encoder applied to MNIST handwritten digits.", 
            "title": "Computer Vision"
        }, 
        {
            "location": "/examples/#natural-language-processing", 
            "text": "Recurrent Neural Network (LSTM) . Apply an LSTM to IMDB sentiment dataset classification task.  Bi-Directional RNN (LSTM) . Apply a bi-directional LSTM to IMDB sentiment dataset classification task.  Dynamic RNN (LSTM) . Apply a dynamic LSTM to classify variable length text from IMDB dataset.  City Name Generation . Generates new US-cities name, using LSTM network.  Shakespeare Scripts Generation . Generates new Shakespeare scripts, using LSTM network.", 
            "title": "Natural Language Processing"
        }, 
        {
            "location": "/examples/#reinforcement-learning", 
            "text": "Atari Pacman 1-step Q-Learning . Teach a machine to play Atari games (Pacman by default) using 1-step Q-learning.", 
            "title": "Reinforcement Learning"
        }, 
        {
            "location": "/examples/#notebooks", 
            "text": "Spiral Classification Problem . TFLearn implementation of spiral classification problem from Stanford CS231n.", 
            "title": "Notebooks"
        }, 
        {
            "location": "/models/dnn/", 
            "text": "Deep Neural Network Model\n\n\ntflearn.models.dnn.DNN\n  (network,  clip_gradients=5.0,  tensorboard_verbose=0,  tensorboard_dir='/tmp/tflearn_logs/',  checkpoint_path=None,  max_checkpoints=None,  session=None)\n\n\nArguments\n\n\n\n\n\nnetwork\n: \nTensor\n. Neural network to be used.\n\n\ntensorboard_verbose\n: \nint\n. Summary verbose level, it accepts\ndifferent levels of tensorboard logs:\n\n\n\n\n0: Loss, Accuracy (Best Speed).\n1: Loss, Accuracy, Gradients.\n2: Loss, Accuracy, Gradients, Weights.\n3: Loss, Accuracy, Gradients, Weights, Activations, Sparsity.(Best visualization)\n\n\n\n\n\n\ntensorboard_dir\n: \nstr\n. Directory to store tensorboard logs.\nDefault: \"/tmp/tflearn_logs/\"\n\n\ncheckpoint_path\n: \nstr\n. Path to store model checkpoints. If None,\nno model checkpoint will be saved. Default: None.\n\n\nmax_checkpoints\n: \nint\n or None. Maximum amount of checkpoints. If\nNone, no limit. Default: None.\n\n\nsession\n: \nSession\n. A session for running ops. If None, a new one will\nbe created. Note: When providing a session, variables must have been\ninitialized already, otherwise an error will be raised.\n\n\n\n\nAttributes\n\n\n\n\n\ntrainer\n: \nTrainer\n. Handle model training.\n\n\npredictor\n: \nPredictor\n. Handle model prediction.\n\n\nsession\n: \nSession\n. The current model session.\n\n\n\n\nMethods\n\n\n\n \n\n\nevaluate\n  (X,  Y,  batch_size=128)\n\n\nEvaluate model metric(s) on given samples.\n\n\nArguments\n\n\n\n\n\nX\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with inputs layer name as keys). Data to feed to train\nmodel.\n\n\nY\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with estimators layer name as keys). Targets (Labels) to\nfeed to train model. Usually set as the next element of a\nsequence, i.e. for x[0] =\n y[0] = x[1].\n\n\nbatch_size\n: \nint\n. The batch size. Default: 128.\n\n\n\n\nReturns\n\n\n\nThe metric(s) score.\n\n\n \n\n\nfit\n  (X_inputs,  Y_targets,  n_epoch=10,  validation_set=None,  show_metric=False,  batch_size=None,  shuffle=None,  snapshot_epoch=True,  snapshot_step=None,  excl_trainops=None,  run_id=None)\n\n\nTrain model, feeding X_inputs and Y_targets to the network.\n\n\nNOTE: When not feeding dicts, data assignations is made by\ninput/estimator layers creation order (For example, the second\ninput layer created will be feeded by the second value of\nX_inputs list).\n\n\nExamples\n\n\n\nmodel.fit(X, Y) # Single input and output\nmodel.fit({'input1': X}, {'output1': Y}) # Single input and output\nmodel.fit([X1, X2], Y) # Mutliple inputs, Single output\n\n# validate with X_val and [Y1_val, Y2_val]\nmodel.fit(X, [Y1, Y2], validation_set=(X_val, [Y1_val, Y2_val]))\n# 10% of training data used for validation\nmodel.fit(X, Y, validation_set=0.1)\n\n\n\n\nArguments\n\n\n\n\n\nX_inputs\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with inputs layer name as keys). Data to feed to train\nmodel.\n\n\nY_targets\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with estimators layer name as keys). Targets (Labels) to\nfeed to train model.\n\n\nn_epoch\n: \nint\n. Number of epoch to run. Default: None.\n\n\nvalidation_set\n: \ntuple\n. Represents data used for validation.\n\ntuple\n holds data and targets (provided as same type as\nX_inputs and Y_targets). Additionally, it also accepts\n\nfloat\n (\n1) to performs a data split over training data.\n\n\nshow_metric\n: \nbool\n. Display or not accuracy at every step.\n\n\nbatch_size\n: \nint\n or None. If \nint\n, overrides all network\nestimators 'batch_size' by this value.\n\n\nshuffle\n: \nbool\n or None. If \nbool\n, overrides all network\nestimators 'shuffle' by this value.\n\n\nsnapshot_epoch\n: \nbool\n. If True, it will snapshot model at the end\nof every epoch. (Snapshot a model will evaluate this model\non validation set, as well as create a checkpoint if\n'checkpoint_path' specified).\n\n\nsnapshot_step\n: \nint\n or None. If \nint\n, it will snapshot model\nevery 'snapshot_step' steps.\n\n\nexcl_trainops\n: \nlist\n of \nTrainOp\n. A list of train ops to\nexclude from training process (TrainOps can be retrieve\nthrough \ntf.get_collection_ref(tf.GraphKeys.TRAIN_OPS)\n).\n\n\nrun_id\n: \nstr\n. Give a name for this run. (Useful for Tensorboard).\n\n\n\n\n \n\n\nget_weights\n  (weight_tensor)\n\n\nGet a variable weights.\n\n\nExamples\n\n\n\ndnn = DNNTrainer(...)\nw = dnn.get_weights(denselayer.W) # get a dense layer weights\nw = dnn.get_weights(convlayer.b) # get a conv layer biases\n\n\n\n\nArguments\n\n\n\n\n\nweight_tensor\n: \nTensor\n. A Variable.\n\n\n\n\nReturns\n\n\n\nnp.array\n. The provided variable weights.\n\n\n \n\n\nload\n  (model_file,  weights_only=False)\n\n\nRestore model weights.\n\n\nArguments\n\n\n\n\n\nmodel_file\n: \nstr\n. Model path.\n\n\nweights_only\n: \nbool\n. If True, only weights will be restored (\nand not intermediate variable, such as step counter, moving\naverages...). Note that if you are using batch normalization,\naverages will not be restored as well.\n\n\n\n\n \n\n\npredict\n  (X)\n\n\nModel prediction for given input data.\n\n\nArguments\n\n\n\n\n\nX\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with inputs layer name as keys). Data to feed for prediction.\n\n\n\n\nReturns\n\n\n\narray or \nlist\n of array. The predicted value.\n\n\n \n\n\nsave\n  (model_file)\n\n\nSave model weights.\n\n\nArguments\n\n\n\n\n\nmodel_file\n: \nstr\n. Model path.\n\n\n\n\n \n\n\nset_weights\n  (tensor,  weights)\n\n\nAssign a tensor variable a given value.\n\n\nArguments\n\n\n\n\n\ntensor\n: \nTensor\n. The tensor variable to assign value.\n\n\nweights\n: The value to be assigned.", 
            "title": "Deep Neural Network"
        }, 
        {
            "location": "/models/dnn/#deep-neural-network-model", 
            "text": "tflearn.models.dnn.DNN   (network,  clip_gradients=5.0,  tensorboard_verbose=0,  tensorboard_dir='/tmp/tflearn_logs/',  checkpoint_path=None,  max_checkpoints=None,  session=None)", 
            "title": "Deep Neural Network Model"
        }, 
        {
            "location": "/models/generator/", 
            "text": "Sequence Generator Model\n\n\ntflearn.models.generator.SequenceGenerator\n  (network,  dictionary=None,  seq_maxlen=25,  clip_gradients=0.0,  tensorboard_verbose=0,  tensorboard_dir='/tmp/tflearn_logs/',  checkpoint_path=None,  max_checkpoints=None,  session=None)\n\n\nA deep neural network model for generating sequences.\n\n\nArguments\n\n\n\n\n\nnetwork\n: \nTensor\n. Neural network to be used.\n\n\ndictionary\n: \ndict\n. A dictionary associating each sample with a key (\nusually integers). For example: {'a': 0, 'b': 1, 'c': 2, ...}.\n\n\nseq_maxlen\n: \nint\n. The maximum length of a sequence.\n\n\ntensorboard_verbose\n: \nint\n. Summary verbose level, it accepts\ndifferent levels of tensorboard logs:\n\n\n\n\n0 - Loss, Accuracy (Best Speed).\n1 - Loss, Accuracy, Gradients.\n2 - Loss, Accuracy, Gradients, Weights.\n3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity.(Best visualization)\n\n\n\n\n\n\ntensorboard_dir\n: \nstr\n. Directory to store tensorboard logs.\nDefault: \"/tmp/tflearn_logs/\"\n\n\ncheckpoint_path\n: \nstr\n. Path to store model checkpoints. If None,\nno model checkpoint will be saved. Default: None.\n\n\nmax_checkpoints\n: \nint\n or None. Maximum amount of checkpoints. If\nNone, no limit. Default: None.\n\n\nsession\n: \nSession\n. A session for running ops. If None, a new one will\nbe created. Note: When providing a session, variables must have been\ninitialized already, otherwise an error will be raised.\n\n\n\n\nAttributes\n\n\n\n\n\ntrainer\n: \nTrainer\n. Handle model training.\n\n\npredictor\n: \nPredictor\n. Handle model prediction.\n\n\nsession\n: \nSession\n. The current model session.\n\n\n\n\nMethods\n\n\n\n \n\n\nevaluate\n  (X,  Y,  batch_size=128)\n\n\nEvaluate model on given samples.\n\n\nArguments\n\n\n\n\n\nX\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with inputs layer name as keys). Data to feed to train\nmodel.\n\n\nY\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with estimators layer name as keys). Targets (Labels) to\nfeed to train model. Usually set as the next element of a\nsequence, i.e. for x[0] =\n y[0] = x[1].\n\n\nbatch_size\n: \nint\n. The batch size. Default: 128.\n\n\n\n\nReturns\n\n\n\nThe metric score.\n\n\n \n\n\nfit\n  (X_inputs,  Y_targets,  n_epoch=10,  validation_set=None,  show_metric=False,  batch_size=None,  shuffle=None,  snapshot_epoch=True,  snapshot_step=None,  excl_trainops=None,  run_id=None)\n\n\nTrain model, feeding X_inputs and Y_targets to the network.\n\n\nNOTE: When not feeding dicts, data assignations is made by\ninput/estimator layers creation order (For example, the second\ninput layer created will be feeded by the second value of\nX_inputs list).\n\n\nExamples\n\n\n\nmodel.fit(X, Y) # Single input and output\nmodel.fit({'input1': X}, {'output1': Y}) # Single input and output\nmodel.fit([X1, X2], Y) # Mutliple inputs, Single output\n\n# validate with X_val and [Y1_val, Y2_val]\nmodel.fit(X, [Y1, Y2], validation_set=(X_val, [Y1_val, Y2_val]))\n# 10% of training data used for validation\nmodel.fit(X, Y, validation_set=0.1)\n\n\n\n\nArguments\n\n\n\n\n\nX_inputs\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with inputs layer name as keys). Data to feed to train\nmodel.\n\n\nY_targets\n: array, \nlist\n of array (if multiple inputs) or \ndict\n\n(with estimators layer name as keys). Targets (Labels) to\nfeed to train model. Usually set as the next element of a\nsequence, i.e. for x[0] =\n y[0] = x[1].\n\n\nn_epoch\n: \nint\n. Number of epoch to run. Default: None.\n\n\nvalidation_set\n: \ntuple\n. Represents data used for validation.\n\ntuple\n holds data and targets (provided as same type as\nX_inputs and Y_targets). Additionally, it also accepts\n\nfloat\n (\n1) to performs a data split over training data.\n\n\nshow_metric\n: \nbool\n. Display or not accuracy at every step.\n\n\nbatch_size\n: \nint\n or None. If \nint\n, overrides all network\nestimators 'batch_size' by this value.\n\n\nshuffle\n: \nbool\n or None. If \nbool\n, overrides all network\nestimators 'shuffle' by this value.\n\n\nsnapshot_epoch\n: \nbool\n. If True, it will snapshot model at the end\nof every epoch. (Snapshot a model will evaluate this model\non validation set, as well as create a checkpoint if\n'checkpoint_path' specified).\n\n\nsnapshot_step\n: \nint\n or None. If \nint\n, it will snapshot model\nevery 'snapshot_step' steps.\n\n\nexcl_trainops\n: \nlist\n of \nTrainOp\n. A list of train ops to\nexclude from training process (TrainOps can be retrieve\nthrough \ntf.get_collection_ref(tf.GraphKeys.TRAIN_OPS)\n).\n\n\nrun_id\n: \nstr\n. Give a name for this run. (Useful for Tensorboard).\n\n\n\n\n \n\n\ngenerate\n  (seq_length,  temperature=0.5,  seq_seed=None,  display=False)\n\n\nGenerate a sequence. Temperature is controlling the novelty of\nthe created sequence, a temperature near 0 will looks like samples\nused for training, while the higher the temperature, the more novelty.\nFor optimal results, it is suggested to set sequence seed as some\nrandom sequence samples from training dataset.\n\n\nArguments\n\n\n\n\n\nseq_length\n: \nint\n. The generated sequence length.\n\n\ntemperature\n: \nfloat\n. Novelty rate.\n\n\nseq_seed\n: \nsequence\n. A sequence used as a seed to generate a\nnew sequence. Suggested to be a sequence from data used for\ntraining.\n\n\ndisplay\n: \nbool\n. If True, print sequence as it is generated.\n\n\n\n\nReturns\n\n\n\nThe generated sequence.\n\n\n \n\n\nget_weights\n  (weight_tensor)\n\n\nGet a variable weights.\n\n\nExamples\n\n\n\nsgen = SequenceGenerator(...)\nw = sgen.get_weights(denselayer.W) -- get a dense layer weights\n\n\nArguments\n\n\n\n\n\nweight_tensor\n: \ntf.Tensor\n. A Variable.\n\n\n\n\nReturns\n\n\n\nnp.array\n. The provided variable weights.\n\n\n \n\n\nload\n  (model_file)\n\n\nRestore model weights.\n\n\nArguments\n\n\n\n\n\nmodel_file\n: \nstr\n. Model path.\n\n\n\n\n \n\n\nsave\n  (model_file)\n\n\nSave model weights.\n\n\nArguments\n\n\n\n\n\nmodel_file\n: \nstr\n. Model path.\n\n\n\n\n \n\n\nset_weights\n  (tensor,  weights)\n\n\nAssign a tensor variable a given value.\n\n\nArguments\n\n\n\n\n\ntensor\n: \nTensor\n. The tensor variable to assign value.\n\n\nweights\n: The value to be assigned.", 
            "title": "Generative Neural Network"
        }, 
        {
            "location": "/models/generator/#sequence-generator-model", 
            "text": "tflearn.models.generator.SequenceGenerator   (network,  dictionary=None,  seq_maxlen=25,  clip_gradients=0.0,  tensorboard_verbose=0,  tensorboard_dir='/tmp/tflearn_logs/',  checkpoint_path=None,  max_checkpoints=None,  session=None)  A deep neural network model for generating sequences.", 
            "title": "Sequence Generator Model"
        }, 
        {
            "location": "/layers/core/", 
            "text": "Input Data\n\n\ntflearn.layers.core.input_data\n  (shape=None,  placeholder=None,  dtype=tf.float32,  data_preprocessing=None,  data_augmentation=None,  name='InputData')\n\n\nThis layer is used as a data entry (placeholder) of a network. The inner\nplaceholder will then be feeded with data when training.\n\n\nThis layer is used to keep track of the network inputs, by adding the\nplaceholder to INPUTS graphkey. TFLearn training functions may retrieve\nthese variables to setup the network training process.\n\n\nInput\n\n\n\nList of \nint\n (Shape), to create a new placeholder.\nOr\n\nTensor\n (Placeholder), to use an existing placeholder.\n\n\nOutput\n\n\n\nPlaceholder Tensor with given shape.\n\n\nArguments\n\n\n\n\n\nshape\n: list of \nint\n. An array or tuple representing input data shape.\nIt is required if no placeholder provided. First element should\nbe 'None' (representing batch size), if not provided, it will be\nadded automatically.\n\n\nplaceholder\n: A Placeholder to use for feeding this layer (optional).\nIf not specified, a placeholder will be automatically created.\nYou can retrieve that placeholder through graph key: 'INPUTS',\nor the 'placeholder' attribute of this function's returned tensor.\n\n\ndtype\n: \ntf.type\n, Placeholder data type (optional). Default: float32.\n\n\ndata_preprocessing\n: A \nDataPreprocessing\n subclass object to manage\nreal-time data pre-processing when training and predicting (such\nas zero center data, std normalization...).\n\n\ndata_augmentation\n: \nDataAugmentation\n. A \nDataAugmentation\n subclass\nobject to manage real-time data augmentation while training (\nsuch as random image crop, random image flip, random sequence\nreverse...).\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\n\n\nFully Connected\n\n\ntflearn.layers.core.fully_connected\n  (incoming,  n_units,  activation='linear',  bias=True,  weights_init='truncated_normal',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='FullyConnected')\n\n\nA fully connected layer.\n\n\nInput\n\n\n\n(2+)-D Tensor [samples, input dim]. If not 2D, input will be flatten.\n\n\nOutput\n\n\n\n2D Tensor [samples, n_units].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming (2+)D Tensor.\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'FullyConnected'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nTensor\n. Variable representing units weights.\n\n\nb\n: \nTensor\n. Variable representing biases.\n\n\n\n\n\n\nDropout\n\n\ntflearn.layers.core.dropout\n  (incoming,  keep_prob,  name='Dropout')\n\n\nOutputs the input element scaled up by \n1 / keep_prob\n. The scaling is so\nthat the expected sum is unchanged.\n\n\nArguments\n\n\n\n\n\nincoming : A \nTensor\n. The incoming tensor.\n\n\nkeep_prob : A float representing the probability that each element\nis kept.\n\n\nname : A name for this layer (optional).\n\n\n\n\nReferences\n\n\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting.\nN. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever \n R. Salakhutdinov,\n(2014), Journal of Machine Learning Research, 5(Jun)(2), 1929-1958.\n\n\nLinks\n\n\n\nhttps://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n\n\n\n\nCustom Layer\n\n\ntflearn.layers.core.custom_layer\n  (incoming,  custom_fn,  **kwargs)\n\n\nA custom layer that can apply any operations to the incoming Tensor or\nlist of \nTensor\n. The custom function can be pass as a parameter along\nwith its parameters.\n\n\nArguments\n\n\n\n\n\nincoming : A \nTensor\n or list of \nTensor\n. Incoming tensor.\n\n\ncustom_fn : A custom \nfunction\n, to apply some ops on incoming tensor.\n\n\n**kwargs: Some custom parameters that custom function might need.\n\n\n\n\n\n\nReshape\n\n\ntflearn.layers.core.reshape\n  (incoming,  new_shape,  name='Reshape')\n\n\nA layer that reshape the incoming layer tensor output to the desired shape.\n\n\nArguments\n\n\n\n\n\nincoming\n: A \nTensor\n. The incoming tensor.\n\n\nnew_shape\n: A list of \nint\n. The desired shape.\n\n\nname\n: A name for this layer (optional).\n\n\n\n\n\n\nFlatten\n\n\ntflearn.layers.core.flatten\n  (incoming,  name='Flatten')\n\n\nFlatten the incoming Tensor.\n\n\nInput\n\n\n\n(2+)-D \nTensor\n.\n\n\nOutput\n\n\n\n2-D \nTensor\n [batch, flatten_dims].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. The incoming tensor.\n\n\n\n\n\n\nActivation\n\n\ntflearn.layers.core.activation\n  (incoming,  activation='linear')\n\n\nApply given activation to incoming tensor.\n\n\nArguments\n\n\n\n\n\nincoming\n: A \nTensor\n. The incoming tensor.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\n\n\n\n\nSingle Unit\n\n\ntflearn.layers.core.single_unit\n  (incoming,  activation='linear',  bias=True,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Linear')\n\n\nA single unit (Linear) Layer.\n\n\nInput\n\n\n\n1-D Tensor [samples]. If not 2D, input will be flatten.\n\n\nOutput\n\n\n\n1-D Tensor [samples].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming Tensor.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n. Activation applied to this\nlayer (see tflearn.activations). Default: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Linear'.\n\n\n\n\nAttributes\n\n\n\n\n\nW\n: \nTensor\n. Variable representing weight.\n\n\nb\n: \nTensor\n. Variable representing bias.\n\n\n\n\n\n\nFully Connected Highway\n\n\ntflearn.layers.core.highway\n  (incoming,  n_units,  activation='linear',  transform_dropout=None,  weights_init='truncated_normal',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='FullyConnectedHighway')\n\n\nA fully connected highway network layer, with some inspiration from\n\nhttps://github.com/fomorians/highway-fcn\n.\n\n\nInput\n\n\n\n(2+)-D Tensor [samples, input dim]. If not 2D, input will be flatten.\n\n\nOutput\n\n\n\n2D Tensor [samples, n_units].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming (2+)D Tensor.\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\ntransform_dropout\n: \nfloat\n: Keep probability on the highway transform gate.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'FullyConnectedHighway'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nTensor\n. Variable representing units weights.\n\n\nW_t\n: \nTensor\n. Variable representing units weights for transform gate.\n\n\nb\n: \nTensor\n. Variable representing biases.\n\n\nb_t\n: \nTensor\n. Variable representing biases for transform gate.\n\n\n\n\nLinks\n\n\n\nhttps://arxiv.org/abs/1505.00387\n\n\n\n\nOne Hot Encoding\n\n\ntflearn.layers.core.one_hot_encoding\n  (target,  n_classes,  on_value=1.0,  off_value=1.0,  name='OneHotEncoding')\n\n\nTransform numeric labels into a binary vector.\n\n\nInput\n\n\n\nThe Labels Placeholder.\n\n\nOutput\n\n\n\n2-D Tensor, The encoded labels.\n\n\nArguments\n\n\n\n\n\ntarget\n: \nPlaceholder\n. The labels placeholder.\n\n\nn_classes\n: \nint\n. Total number of classes.\n\n\non_value\n: \nscalar\n. A scalar defining the on-value.\n\n\noff_value\n: \nscalar\n. A scalar defining the off-value.\n\n\nname\n: A name for this layer (optional). Default: 'OneHotEncoding'.", 
            "title": "Core Layers"
        }, 
        {
            "location": "/layers/core/#input-data", 
            "text": "tflearn.layers.core.input_data   (shape=None,  placeholder=None,  dtype=tf.float32,  data_preprocessing=None,  data_augmentation=None,  name='InputData')  This layer is used as a data entry (placeholder) of a network. The inner\nplaceholder will then be feeded with data when training.  This layer is used to keep track of the network inputs, by adding the\nplaceholder to INPUTS graphkey. TFLearn training functions may retrieve\nthese variables to setup the network training process.", 
            "title": "Input Data"
        }, 
        {
            "location": "/layers/core/#fully-connected", 
            "text": "tflearn.layers.core.fully_connected   (incoming,  n_units,  activation='linear',  bias=True,  weights_init='truncated_normal',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='FullyConnected')  A fully connected layer.", 
            "title": "Fully Connected"
        }, 
        {
            "location": "/layers/core/#dropout", 
            "text": "tflearn.layers.core.dropout   (incoming,  keep_prob,  name='Dropout')  Outputs the input element scaled up by  1 / keep_prob . The scaling is so\nthat the expected sum is unchanged.", 
            "title": "Dropout"
        }, 
        {
            "location": "/layers/core/#custom-layer", 
            "text": "tflearn.layers.core.custom_layer   (incoming,  custom_fn,  **kwargs)  A custom layer that can apply any operations to the incoming Tensor or\nlist of  Tensor . The custom function can be pass as a parameter along\nwith its parameters.", 
            "title": "Custom Layer"
        }, 
        {
            "location": "/layers/core/#reshape", 
            "text": "tflearn.layers.core.reshape   (incoming,  new_shape,  name='Reshape')  A layer that reshape the incoming layer tensor output to the desired shape.", 
            "title": "Reshape"
        }, 
        {
            "location": "/layers/core/#flatten", 
            "text": "tflearn.layers.core.flatten   (incoming,  name='Flatten')  Flatten the incoming Tensor.", 
            "title": "Flatten"
        }, 
        {
            "location": "/layers/core/#activation", 
            "text": "tflearn.layers.core.activation   (incoming,  activation='linear')  Apply given activation to incoming tensor.", 
            "title": "Activation"
        }, 
        {
            "location": "/layers/core/#single-unit", 
            "text": "tflearn.layers.core.single_unit   (incoming,  activation='linear',  bias=True,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Linear')  A single unit (Linear) Layer.", 
            "title": "Single Unit"
        }, 
        {
            "location": "/layers/core/#fully-connected-highway", 
            "text": "tflearn.layers.core.highway   (incoming,  n_units,  activation='linear',  transform_dropout=None,  weights_init='truncated_normal',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='FullyConnectedHighway')  A fully connected highway network layer, with some inspiration from https://github.com/fomorians/highway-fcn .", 
            "title": "Fully Connected Highway"
        }, 
        {
            "location": "/layers/core/#one-hot-encoding", 
            "text": "tflearn.layers.core.one_hot_encoding   (target,  n_classes,  on_value=1.0,  off_value=1.0,  name='OneHotEncoding')  Transform numeric labels into a binary vector.", 
            "title": "One Hot Encoding"
        }, 
        {
            "location": "/layers/conv/", 
            "text": "Convolution 2D\n\n\ntflearn.layers.conv.conv_2d\n  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv2D')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, new height, new width, nb_filter].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: \nint\n or \nlist of int\n. Size of filters.\n\n\nstrides\n: 'int\nor list of\nint`. Strides of conv operation.\nDefault: [1 1 1 1].\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Conv2D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\n\n\n\n\nConvolution 2D Transpose\n\n\ntflearn.layers.conv.conv_2d_transpose\n  (incoming,  nb_filter,  filter_size,  output_shape,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv2DTranspose')\n\n\nThis operation is sometimes called \"deconvolution\" after (Deconvolutional\nNetworks)[http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf], but is\nactually the transpose (gradient) of \nconv_2d\n rather than an actual\ndeconvolution.\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, new height, new width, nb_filter].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: \nint\n or \nlist of int\n. Size of filters.\n\n\noutput_shape\n: \nlist of int\n. Dimensions of the output tensor.\nCan optionally include the number of conv filters.\n[new height, new width, nb_filter] or [new height, new width].\n\n\nstrides\n: \nint\n or list of \nint\n. Strides of conv operation.\nDefault: [1 1 1 1].\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Conv2DTranspose'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\n\n\n\n\nMax Pooling 2D\n\n\ntflearn.layers.conv.max_pool_2d\n  (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool2D')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Pooling kernel size.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'MaxPool2D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nAverage Pooling 2D\n\n\ntflearn.layers.conv.avg_pool_2d\n  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool2D')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Pooling kernel size.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'AvgPool2D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nUpSample 2D\n\n\ntflearn.layers.conv.upsample_2d\n  (incoming,  kernel_size,  name='UpSample2D')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer to upsample.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Upsampling kernel size.\n\n\nname\n: A name for this layer (optional). Default: 'UpSample2D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nUpscore\n\n\ntflearn.layers.conv.upscore_layer\n  (incoming,  num_classes,  shape=None,  kernel_size=4,  strides=2,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Upscore')\n\n\nThis implements the upscore layer as used in\n(Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038].\nThe upscore layer is initialized as bilinear upsampling filter.\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, pooled height, pooled width, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer to upsample.\n\n\nnum_classes\n: \nint\n. Number of output feature maps.\n\n\nshape\n: \nlist of int\n. Dimension of the output map\n[batch_size, new height, new width]. For convinience four values\n are allows [batch_size, new height, new width, X], where X\n is ignored.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Upsampling kernel size.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: [1 2 2 1].\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\nname: A name for this layer (optional). Default: 'Upscore'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\nLinks\n\n\n\n(Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038]\n\n\n\n\nConvolution 1D\n\n\ntflearn.layers.conv.conv_1d\n  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv1D')\n\n\nInput\n\n\n\n3-D Tensor [batch, steps, in_channels].\n\n\nOutput\n\n\n\n3-D Tensor [batch, new steps, nb_filters].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: 'int\nor\nlist of int`. Size of filters.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: [1 1 1 1].\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Conv1D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\n\n\n\n\nMax Pooling 1D\n\n\ntflearn.layers.conv.max_pool_1d\n  (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool1D')\n\n\nInput\n\n\n\n3-D Tensor [batch, steps, in_channels].\n\n\nOutput\n\n\n\n3-D Tensor [batch, pooled steps, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Layer.\n\n\nkernel_size\n: \nint\n or \nlist of int\n. Pooling kernel size.\n\n\nstrides\n: \nint\n or \nlist of int\n. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'MaxPool1D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nAverage Pooling 1D\n\n\ntflearn.layers.conv.avg_pool_1d\n  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool1D')\n\n\nInput\n\n\n\n3-D Tensor [batch, steps, in_channels].\n\n\nOutput\n\n\n\n3-D Tensor [batch, pooled steps, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Layer.\n\n\nkernel_size\n: \nint\n or \nlist of int\n. Pooling kernel size.\n\n\nstrides\n: \nint\n or \nlist of int\n. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'AvgPool1D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nConvolution 3D\n\n\ntflearn.layers.conv.conv_3d\n  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  scope=None,  name='Conv3D')\n\n\nInput\n\n\n\n5-D Tensor [batch, in_depth, in_height, in_width, in_channels].\n\n\nOutput\n\n\n\n5-D Tensor [filter_depth, filter_height, filter_width, in_channels, out_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 5-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: \nint\n or \nlist of int\n. Size of filters.\n\n\nstrides\n: 'int\nor list of\nint`. Strides of conv operation.\nDefault: [1 1 1 1 1]. Must have strides[0] = strides[4] = 1.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Conv3D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\n\n\n\n\nMax Pooling 3D\n\n\ntflearn.layers.conv.max_pool_3d\n  (incoming,  kernel_size,  strides=1,  padding='same',  name='MaxPool3D')\n\n\nInput\n\n\n\n5-D Tensor [batch, depth, rows, cols, channels].\n\n\nOutput\n\n\n\n5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 5-D Layer.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Pooling kernel size.Must have kernel_size[0] = kernel_size[1] = 1\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.Must have strides[0] = strides[4] = 1.\nDefault: [1 1 1 1 1]\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'MaxPool3D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nAverage Pooling 3D\n\n\ntflearn.layers.conv.avg_pool_3d\n  (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool3D')\n\n\nInput\n\n\n\n5-D Tensor [batch, depth, rows, cols, channels].\n\n\nOutput\n\n\n\n5-D Tensor [batch, pooled depth, pooled rows, pooled cols, in_channels].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 5-D Layer.\n\n\nkernel_size\n: 'int\nor\nlist of int`. Pooling kernel size.Must have kernel_size[0] = kernel_size[1] = 1\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.Must have strides[0] = strides[4] = 1.\nDefault: [1 1 1 1 1]\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'AvgPool3D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\n\n\n\n\nGlobal Average Pooling\n\n\ntflearn.layers.conv.global_avg_pool\n  (incoming,  name='GlobalAvgPool')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n2-D Tensor [batch, pooled dim]\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Tensor.\n\n\nname\n: A name for this layer (optional). Default: 'GlobalAvgPool'.\n\n\n\n\n\n\nResidual Block\n\n\ntflearn.layers.conv.residual_block\n  (incoming,  nb_blocks,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='ResidualBlock')\n\n\nA residual block as described in MSRA's Deep Residual Network paper.\nFull pre-activation architecture is used here.\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, new height, new width, nb_filter].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer.\n\n\nnb_blocks\n: \nint\n. Number of layer blocks.\n\n\nout_channels\n: \nint\n. The number of convolutional filters of the\nconvolution layers.\n\n\ndownsample\n: \nbool\n. If True, apply downsampling using\n'downsample_strides' for strides.\n\n\ndownsample_strides\n: \nint\n. The strides to use when downsampling.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbatch_norm\n: \nbool\n. If True, apply batch normalization.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'uniform_scaling'.\n\n\nbias_init\n: \nstr\n (name) or \ntf.Tensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'ShallowBottleneck'.\n\n\n\n\nReferences\n\n\n\n\n\nDeep Residual Learning for Image Recognition. Kaiming He, Xiangyu\nZhang, Shaoqing Ren, Jian Sun. 2015.\n\n\nIdentity Mappings in Deep Residual Networks. Kaiming He, Xiangyu\nZhang, Shaoqing Ren, Jian Sun. 2015.\n\n\n\n\nLinks\n\n\n\n\n\nhttp://arxiv.org/pdf/1512.03385v1.pdf\n\n\nIdentity Mappings in Deep Residual Networks\n\n\n\n\n\n\nResidual Bottleneck\n\n\ntflearn.layers.conv.residual_bottleneck\n  (incoming,  nb_blocks,  bottleneck_size,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='ResidualBottleneck')\n\n\nA residual bottleneck block as described in MSRA's Deep Residual Network\npaper. Full pre-activation architecture is used here.\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, new height, new width, nb_filter].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Layer.\n\n\nnb_blocks\n: \nint\n. Number of layer blocks.\n\n\nbottleneck_size\n: \nint\n. The number of convolutional filter of the\nbottleneck convolutional layer.\n\n\nout_channels\n: \nint\n. The number of convolutional filters of the\nlayers surrounding the bottleneck layer.\n\n\ndownsample\n: \nbool\n. If True, apply downsampling using\n'downsample_strides' for strides.\n\n\ndownsample_strides\n: \nint\n. The strides to use when downsampling.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nbatch_norm\n: \nbool\n. If True, apply batch normalization.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'uniform_scaling'.\n\n\nbias_init\n: \nstr\n (name) or \ntf.Tensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'DeepBottleneck'.\n\n\n\n\nReferences\n\n\n\n\n\nDeep Residual Learning for Image Recognition. Kaiming He, Xiangyu\nZhang, Shaoqing Ren, Jian Sun. 2015.\n\n\nIdentity Mappings in Deep Residual Networks. Kaiming He, Xiangyu\nZhang, Shaoqing Ren, Jian Sun. 2015.\n\n\n\n\nLinks\n\n\n\n\n\nhttp://arxiv.org/pdf/1512.03385v1.pdf\n\n\nIdentity Mappings in Deep Residual Networks\n\n\n\n\n\n\nHighway Convolution 2D\n\n\ntflearn.layers.conv.highway_conv_2d\n  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='HighwayConv2D')\n\n\nInput\n\n\n\n4-D Tensor [batch, height, width, in_channels].\n\n\nOutput\n\n\n\n4-D Tensor [batch, new height, new width, nb_filter].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 4-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: 'int\nor\nlist of int`. Size of filters.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: [1 1 1 1].\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Conv2D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nW_T\n: \nVariable\n. Variable representing gate weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\nb_T\n: \nVariable\n. Variable representing gate biases.\n\n\n\n\n\n\nHighway Convolution 1D\n\n\ntflearn.layers.conv.highway_conv_1d\n  (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='HighwayConv1D')\n\n\nInput\n\n\n\n3-D Tensor [batch, steps, in_channels].\n\n\nOutput\n\n\n\n3-D Tensor [batch, new steps, nb_filters].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Tensor.\n\n\nnb_filter\n: \nint\n. The number of convolutional filters.\n\n\nfilter_size\n: 'int\nor\nlist of int`. Size of filters.\n\n\nstrides\n: 'int\nor\nlist of int`. Strides of conv operation.\nDefault: [1 1 1 1].\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\nbias_init\n: \nstr\n (name) or \nTensor\n. Bias initialization.\n(see tflearn.initializations) Default: 'zeros'.\n\n\nregularizer\n: \nstr\n (name) or \nTensor\n. Add a regularizer to this\nlayer weights (see tflearn.regularizers). Default: None.\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'HighwayConv1D'.\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nScope\n. This layer scope.\n\n\nW\n: \nVariable\n. Variable representing filter weights.\n\n\nW_T\n: \nVariable\n. Variable representing gate weights.\n\n\nb\n: \nVariable\n. Variable representing biases.\n\n\nb_T\n: \nVariable\n. Variable representing gate biases.", 
            "title": "Convolutional Layers"
        }, 
        {
            "location": "/layers/conv/#convolution-2d", 
            "text": "tflearn.layers.conv.conv_2d   (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv2D')", 
            "title": "Convolution 2D"
        }, 
        {
            "location": "/layers/conv/#convolution-2d-transpose", 
            "text": "tflearn.layers.conv.conv_2d_transpose   (incoming,  nb_filter,  filter_size,  output_shape,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv2DTranspose')  This operation is sometimes called \"deconvolution\" after (Deconvolutional\nNetworks)[http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf], but is\nactually the transpose (gradient) of  conv_2d  rather than an actual\ndeconvolution.", 
            "title": "Convolution 2D Transpose"
        }, 
        {
            "location": "/layers/conv/#max-pooling-2d", 
            "text": "tflearn.layers.conv.max_pool_2d   (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool2D')", 
            "title": "Max Pooling 2D"
        }, 
        {
            "location": "/layers/conv/#average-pooling-2d", 
            "text": "tflearn.layers.conv.avg_pool_2d   (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool2D')", 
            "title": "Average Pooling 2D"
        }, 
        {
            "location": "/layers/conv/#upsample-2d", 
            "text": "tflearn.layers.conv.upsample_2d   (incoming,  kernel_size,  name='UpSample2D')", 
            "title": "UpSample 2D"
        }, 
        {
            "location": "/layers/conv/#upscore", 
            "text": "tflearn.layers.conv.upscore_layer   (incoming,  num_classes,  shape=None,  kernel_size=4,  strides=2,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Upscore')  This implements the upscore layer as used in\n(Fully Convolutional Networks)[http://arxiv.org/abs/1411.4038].\nThe upscore layer is initialized as bilinear upsampling filter.", 
            "title": "Upscore"
        }, 
        {
            "location": "/layers/conv/#convolution-1d", 
            "text": "tflearn.layers.conv.conv_1d   (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Conv1D')", 
            "title": "Convolution 1D"
        }, 
        {
            "location": "/layers/conv/#max-pooling-1d", 
            "text": "tflearn.layers.conv.max_pool_1d   (incoming,  kernel_size,  strides=None,  padding='same',  name='MaxPool1D')", 
            "title": "Max Pooling 1D"
        }, 
        {
            "location": "/layers/conv/#average-pooling-1d", 
            "text": "tflearn.layers.conv.avg_pool_1d   (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool1D')", 
            "title": "Average Pooling 1D"
        }, 
        {
            "location": "/layers/conv/#convolution-3d", 
            "text": "tflearn.layers.conv.conv_3d   (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  bias=True,  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  scope=None,  name='Conv3D')", 
            "title": "Convolution 3D"
        }, 
        {
            "location": "/layers/conv/#max-pooling-3d", 
            "text": "tflearn.layers.conv.max_pool_3d   (incoming,  kernel_size,  strides=1,  padding='same',  name='MaxPool3D')", 
            "title": "Max Pooling 3D"
        }, 
        {
            "location": "/layers/conv/#average-pooling-3d", 
            "text": "tflearn.layers.conv.avg_pool_3d   (incoming,  kernel_size,  strides=None,  padding='same',  name='AvgPool3D')", 
            "title": "Average Pooling 3D"
        }, 
        {
            "location": "/layers/conv/#global-average-pooling", 
            "text": "tflearn.layers.conv.global_avg_pool   (incoming,  name='GlobalAvgPool')", 
            "title": "Global Average Pooling"
        }, 
        {
            "location": "/layers/conv/#residual-block", 
            "text": "tflearn.layers.conv.residual_block   (incoming,  nb_blocks,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='ResidualBlock')  A residual block as described in MSRA's Deep Residual Network paper.\nFull pre-activation architecture is used here.", 
            "title": "Residual Block"
        }, 
        {
            "location": "/layers/conv/#residual-bottleneck", 
            "text": "tflearn.layers.conv.residual_bottleneck   (incoming,  nb_blocks,  bottleneck_size,  out_channels,  downsample=False,  downsample_strides=2,  activation='relu',  batch_norm=True,  bias=True,  weights_init='variance_scaling',  bias_init='zeros',  regularizer='L2',  weight_decay=0.0001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='ResidualBottleneck')  A residual bottleneck block as described in MSRA's Deep Residual Network\npaper. Full pre-activation architecture is used here.", 
            "title": "Residual Bottleneck"
        }, 
        {
            "location": "/layers/conv/#highway-convolution-2d", 
            "text": "tflearn.layers.conv.highway_conv_2d   (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='HighwayConv2D')", 
            "title": "Highway Convolution 2D"
        }, 
        {
            "location": "/layers/conv/#highway-convolution-1d", 
            "text": "tflearn.layers.conv.highway_conv_1d   (incoming,  nb_filter,  filter_size,  strides=1,  padding='same',  activation='linear',  weights_init='uniform_scaling',  bias_init='zeros',  regularizer=None,  weight_decay=0.001,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='HighwayConv1D')", 
            "title": "Highway Convolution 1D"
        }, 
        {
            "location": "/layers/recurrent/", 
            "text": "Simple RNN\n\n\ntflearn.layers.recurrent.simple_rnn\n  (incoming,  n_units,  activation='sigmoid',  dropout=None,  bias=True,  weights_init=None,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='SimpleRNN')\n\n\nSimple Recurrent Layer.\n\n\nInput\n\n\n\n3-D Tensor [samples, timesteps, input dim].\n\n\nOutput\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor [samples, output dim].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Tensor.\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'linear'.\n\n\ndropout\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). The\ninput and output keep probability.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(See tflearn.initializations)\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_state\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state\n: \nTensor\n. An initial state for the RNN.  This must be\na tensor of appropriate type and shape [batch_size x cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\n\n\nLSTM\n\n\ntflearn.layers.recurrent.lstm\n  (incoming,  n_units,  activation='sigmoid',  inner_activation='tanh',  dropout=None,  bias=True,  weights_init=None,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='LSTM')\n\n\nLong Short Term Memory Recurrent Layer.\n\n\nInput\n\n\n\n3-D Tensor [samples, timesteps, input dim].\n\n\nOutput\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor [samples, output dim].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Tensor.\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'sigmoid'.\n\n\ninner_activation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nLSTM inner activation. Default: 'tanh'.\n\n\ndropout\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). The\ninput and output keep probability.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(See tflearn.initializations).\n\n\nforget_bias\n: \nfloat\n. Bias of the forget gate. Default: 1.0.\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_state\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state\n: \nTensor\n. An initial state for the RNN.  This must be\na tensor of appropriate type and shape [batch_size x cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\nReferences\n\n\n\nLong Short Term Memory, Sepp Hochreiter \n Jurgen Schmidhuber,\nNeural Computation 9(8): 1735-1780, 1997.\n\n\nLinks\n\n\n\nhttp://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n\n\n\n\nGRU\n\n\ntflearn.layers.recurrent.gru\n  (incoming,  n_units,  activation='sigmoid',  inner_activation='tanh',  dropout=None,  bias=True,  weights_init=None,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='GRU')\n\n\nGated Recurrent Unit Layer.\n\n\nInput\n\n\n\n3-D Tensor Layer [samples, timesteps, input dim].\n\n\nOutput\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor [samples, output dim].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 3-D Tensor.\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nactivation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nActivation applied to this layer (see tflearn.activations).\nDefault: 'sigmoid'.\n\n\ninner_activation\n: \nstr\n (name) or \nfunction\n (returning a \nTensor\n).\nGRU inner activation. Default: 'tanh'.\n\n\ndropout\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). The\ninput and output keep probability.\n\n\nbias\n: \nbool\n. If True, a bias is used.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(See tflearn.initializations).\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_state\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state\n: \nTensor\n. An initial state for the RNN.  This must be\na tensor of appropriate type and shape [batch_size x cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\nReferences\n\n\n\nLearning Phrase Representations using RNN Encoder\u2013Decoder for\nStatistical Machine Translation, K. Cho et al., 2014.\n\n\nLinks\n\n\n\nhttp://arxiv.org/abs/1406.1078\n\n\n\n\nBidirectional RNN\n\n\ntflearn.layers.recurrent.bidirectional_rnn\n  (incoming,  rnncell_fw,  rnncell_bw,  return_seq=False,  return_states=False,  initial_state_fw=None,  initial_state_bw=None,  dynamic=False,  scope=None,  name='BiRNN')\n\n\nBuild a bidirectional recurrent neural network, it requires 2 RNN Cells\nto process sequence in forward and backward order. Any RNN Cell can be\nused i.e. SimpleRNN, LSTM, GRU... with its own parameters. But the two\ncells number of units must match.\n\n\nInput\n\n\n\n3-D Tensor Layer [samples, timesteps, input dim].\n\n\nOutput\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor Layer [samples, output dim].\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. The incoming Tensor.\n\n\nrnncell_fw\n: \nRNNCell\n. The RNN Cell to use for foward computation.\n\n\nrnncell_bw\n: \nRNNCell\n. The RNN Cell to use for backward computation.\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_states\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state_fw\n: \nTensor\n. An initial state for the forward RNN.\nThis must be a tensor of appropriate type and shape [batch_size\nx cell.state_size].\n\n\ninitial_state_bw\n: \nTensor\n. An initial state for the backward RNN.\nThis must be a tensor of appropriate type and shape [batch_size\nx cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: \nstr\n. A name for this layer (optional).", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/layers/recurrent/#simple-rnn", 
            "text": "tflearn.layers.recurrent.simple_rnn   (incoming,  n_units,  activation='sigmoid',  dropout=None,  bias=True,  weights_init=None,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='SimpleRNN')  Simple Recurrent Layer.", 
            "title": "Simple RNN"
        }, 
        {
            "location": "/layers/recurrent/#lstm", 
            "text": "tflearn.layers.recurrent.lstm   (incoming,  n_units,  activation='sigmoid',  inner_activation='tanh',  dropout=None,  bias=True,  weights_init=None,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='LSTM')  Long Short Term Memory Recurrent Layer.", 
            "title": "LSTM"
        }, 
        {
            "location": "/layers/recurrent/#gru", 
            "text": "tflearn.layers.recurrent.gru   (incoming,  n_units,  activation='sigmoid',  inner_activation='tanh',  dropout=None,  bias=True,  weights_init=None,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=False,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='GRU')  Gated Recurrent Unit Layer.", 
            "title": "GRU"
        }, 
        {
            "location": "/layers/recurrent/#bidirectional-rnn", 
            "text": "tflearn.layers.recurrent.bidirectional_rnn   (incoming,  rnncell_fw,  rnncell_bw,  return_seq=False,  return_states=False,  initial_state_fw=None,  initial_state_bw=None,  dynamic=False,  scope=None,  name='BiRNN')  Build a bidirectional recurrent neural network, it requires 2 RNN Cells\nto process sequence in forward and backward order. Any RNN Cell can be\nused i.e. SimpleRNN, LSTM, GRU... with its own parameters. But the two\ncells number of units must match.", 
            "title": "Bidirectional RNN"
        }, 
        {
            "location": "/layers/normalization/", 
            "text": "Batch Normalization\n\n\ntflearn.layers.normalization.batch_normalization\n  (incoming,  beta=0.0,  gamma=1.0,  epsilon=1e-05,  decay=0.9,  stddev=0.002,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='BatchNormalization')\n\n\nNormalize activations of the previous layer at each batch.\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming Tensor.\n\n\nbeta\n: \nfloat\n. Default: 0.0.\n\n\ngamma\n: \nfloat\n. Default: 1.0.\n\n\nepsilon\n: \nfloat\n. Defalut: 1e-5.\n\n\ndecay\n: \nfloat\n. Default: 0.9.\n\n\nstddev\n: \nfloat\n. Standard deviation for weights initialization.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\nReferences\n\n\n\nBatch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shif. Sergey Ioffe, Christian Szegedy. 2015.\n\n\nLinks\n\n\n\nhttp://arxiv.org/pdf/1502.03167v3.pdf\n\n\n\n\nLocal Response Normalization\n\n\ntflearn.layers.normalization.local_response_normalization\n  (incoming,  depth_radius=5,  bias=1.0,  alpha=0.0001,  beta=0.75,  name='LocalResponseNormalization')\n\n\nInput\n\n\n\n4-D Tensor Layer.\n\n\nOutput\n\n\n\n4-D Tensor Layer. (Same dimension as input).\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming Tensor.\n\n\ndepth_radius\n: \nint\n. 0-D.  Half-width of the 1-D normalization window.\nDefaults to 5.\n\n\nbias\n: \nfloat\n. An offset (usually positive to avoid dividing by 0).\nDefaults to 1.0.\n\n\nalpha\n: \nfloat\n. A scale factor, usually positive. Defaults to 0.0001.\n\n\nbeta\n: \nfloat\n. An exponent. Defaults to \n0.5\n.\n\n\nname\n: \nstr\n. A name for this layer (optional).", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/layers/normalization/#batch-normalization", 
            "text": "tflearn.layers.normalization.batch_normalization   (incoming,  beta=0.0,  gamma=1.0,  epsilon=1e-05,  decay=0.9,  stddev=0.002,  trainable=True,  restore=True,  reuse=False,  scope=None,  name='BatchNormalization')  Normalize activations of the previous layer at each batch.", 
            "title": "Batch Normalization"
        }, 
        {
            "location": "/layers/normalization/#local-response-normalization", 
            "text": "tflearn.layers.normalization.local_response_normalization   (incoming,  depth_radius=5,  bias=1.0,  alpha=0.0001,  beta=0.75,  name='LocalResponseNormalization')", 
            "title": "Local Response Normalization"
        }, 
        {
            "location": "/layers/embedding_ops/", 
            "text": "Embedding\n\n\ntflearn.layers.embedding_ops.embedding\n  (incoming,  input_dim,  output_dim,  validate_indices=False,  weights_init='truncated_normal',  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Embedding')\n\n\nEmbedding layer for a sequence of ids.\n\n\nInput\n\n\n\n2-D Tensor [samples, ids].\n\n\nOutput\n\n\n\n3-D Tensor [samples, embedded_ids, features].\n\n\nArguments\n\n\n\n\n\nincoming\n: Incoming 2-D Tensor.\n\n\ninput_dim\n: list of \nint\n. Vocabulary size (number of ids).\n\n\noutput_dim\n: list of \nint\n. Embedding size.\n\n\nvalidate_indices\n: \nbool\n. Whether or not to validate gather indices.\n\n\nweights_init\n: \nstr\n (name) or \nTensor\n. Weights initialization.\n(see tflearn.initializations) Default: 'truncated_normal'.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nrestore\n: \nbool\n. If True, this layer weights will be restored when\nloading a model\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share varibales between layers. Note that scope will\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'Embedding'.", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/layers/embedding_ops/#embedding", 
            "text": "tflearn.layers.embedding_ops.embedding   (incoming,  input_dim,  output_dim,  validate_indices=False,  weights_init='truncated_normal',  trainable=True,  restore=True,  reuse=False,  scope=None,  name='Embedding')  Embedding layer for a sequence of ids.", 
            "title": "Embedding"
        }, 
        {
            "location": "/layers/merge_ops/", 
            "text": "Merge\n\n\ntflearn.layers.merge_ops.merge\n  (tensors_list,  mode,  axis=1,  name='Merge')\n\n\nMerge a list of \nTensor\n into a single one.\n\n\nInput\n\n\n\nList of Tensors.\n\n\nOutput\n\n\n\nMerged Tensors.\n\n\nArguments\n\n\n\n\n\ntensors_list\n: A list of \nTensor\n, A list of tensors to merge.\n\n\nmode\n: \nstr\n. Merging mode, it supports:\n\n\n\n\n'concat': concatenate outputs along specified axis\n'elemwise_sum': outputs element-wise sum\n'elemwise_mul': outputs element-wise sum\n'sum': outputs element-wise sum along specified axis\n'mean': outputs element-wise average along specified axis\n'prod': outputs element-wise multiplication along specified axis\n'max': outputs max elements along specified axis\n'min': outputs min elements along specified axis\n'and': `logical and` btw outputs elements along specified axis\n'or': `logical or` btw outputs elements along specified axis\n\n\n\n\n\n\naxis\n: \nint\n. Represents the axis to use for merging mode.\nIn most cases: 0 for concat and 1 for other modes.\n\n\nname\n: A name for this layer (optional). Default: 'Merge'.\n\n\n\n\n\n\nMerge Outputs\n\n\ntflearn.layers.merge_ops.merge_outputs\n  (tensor_list,  name='MergeOutputs')\n\n\nA layer that concatenate all outputs of a network into a single tensor.\n\n\nInput\n\n\n\nList of Tensors [\nshape\n].\n\n\nOutput\n\n\n\nConcatenated Tensors [nb_tensors, \nshape\n].\n\n\nArguments\n\n\n\n\n\ntensor_list\n: list of \nTensor\n. The network outputs.\n\n\nname\n: \nstr\n. A name for this layer (optional).\n\n\n\n\nReturns\n\n\n\nA \nTensor\n.", 
            "title": "Merge Layers"
        }, 
        {
            "location": "/layers/merge_ops/#merge", 
            "text": "tflearn.layers.merge_ops.merge   (tensors_list,  mode,  axis=1,  name='Merge')  Merge a list of  Tensor  into a single one.", 
            "title": "Merge"
        }, 
        {
            "location": "/layers/merge_ops/#merge-outputs", 
            "text": "tflearn.layers.merge_ops.merge_outputs   (tensor_list,  name='MergeOutputs')  A layer that concatenate all outputs of a network into a single tensor.", 
            "title": "Merge Outputs"
        }, 
        {
            "location": "/layers/estimator/", 
            "text": "Regression\n\n\ntflearn.layers.estimator.regression\n  (incoming,  placeholder=None,  optimizer='adam',  loss='categorical_crossentropy',  metric='default',  learning_rate=0.001,  dtype=tf.float32,  batch_size=64,  shuffle_batches=True,  to_one_hot=False,  n_classes=None,  trainable_vars=None,  restore=True,  op_name=None,  name=None)\n\n\nInput\n\n\n\n2-D Tensor Layer.\n\n\nOutput\n\n\n\n2-D Tensor Layer (Same as input).\n\n\nArguments\n\n\n\n\n\nincoming\n: \nTensor\n. Incoming 2-D Tensor.\n\n\nplaceholder\n: \nTensor\n. This regression target (label) placeholder.\nIf 'None' provided, a placeholder will be added automatically.\nYou can retrieve that placeholder through graph key: 'TARGETS',\nor the 'placeholder' attribute of this function's returned tensor.\n\n\noptimizer\n: \nstr\n (name), \nOptimizer\n or \nfunction\n. Optimizer to use.\nDefault: 'sgd' (Stochastic Descent Gradient).\n\n\nloss\n: \nstr\n (name) or \nfunction\n. Loss function used by this layer\noptimizer. Default: 'categorical_crossentropy'.\n\n\nmetric\n: \nstr\n, \nMetric\n or \nfunction\n. The metric to be used.\nDefault: 'default' metric is 'accuracy'. To disable metric\ncalculation, set it to 'None'.\n\n\nlearning_rate\n: \nfloat\n. This layer optimizer's learning rate.\n\n\ndtype\n: \ntf.types\n. This layer placeholder type. Default: tf.float32.\n\n\nbatch_size\n: \nint\n. Batch size of data to use for training. tflearn\nsupports different batch size for every optimizers. Default: 64.\n\n\nshuffle_batches\n: \nbool\n. Shuffle or not this optimizer batches at\nevery epoch. Default: True.\n\n\nto_one_hot\n: \nbool\n. If True, labels will be encoded to one hot vectors.\n'n_classes' must then be specified.\n\n\nn_classes\n: \nint\n. The total number of classes. Only required when using\n'to_one_hot' option.\n\n\ntrainable_vars\n: list of \nVariable\n. If specified, this regression will\nonly update given variable weights. Else, all trainale variable\nare going to be updated.\n\n\nrestore\n: \nbool\n. If False, variables related to optimizers such\nas moving averages will not be restored when loading a\npre-trained model.\n\n\nop_name\n: A name for this layer optimizer (optional).\nDefault: optimizer op name.\n\n\nname\n: A name for this layer's placeholder scope.\n\n\n\n\nAttributes\n\n\n\n\n\nplaceholder\n: \nTensor\n. Placeholder for feeding labels.", 
            "title": "Estimator Layers"
        }, 
        {
            "location": "/layers/estimator/#regression", 
            "text": "tflearn.layers.estimator.regression   (incoming,  placeholder=None,  optimizer='adam',  loss='categorical_crossentropy',  metric='default',  learning_rate=0.001,  dtype=tf.float32,  batch_size=64,  shuffle_batches=True,  to_one_hot=False,  n_classes=None,  trainable_vars=None,  restore=True,  op_name=None,  name=None)", 
            "title": "Regression"
        }, 
        {
            "location": "/activations/", 
            "text": "Linear\n\n\ntflearn.activations.linear\n  (x)\n\n\nf(x) = x\n\n\nArguments\n\n\n\n\n\nx : A \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n,\n\nint16\n, or \nint8\n.\n\n\n\n\nReturns\n\n\n\nThe incoming Tensor (without changes).\n\n\n\n\nTanh\n\n\ntflearn.activations.tanh\n  (x)\n\n\nComputes hyperbolic tangent of \nx\n element-wise.\n\n\nArguments\n\n\n\n\n\nx\n: A Tensor with type \nfloat\n, \ndouble\n, \nint32\n, \ncomplex64\n, \nint64\n,\nor \nqint32\n.\n\n\n\n\nReturns\n\n\n\nA Tensor with the same type as \nx\n if \nx.dtype != qint32\n otherwise\n  the return type is \nquint8\n.\n\n\n\n\nSigmoid\n\n\ntflearn.activations.sigmoid\n  (x)\n\n\nComputes sigmoid of \nx\n element-wise.\nSpecifically, \ny = 1 / (1 + exp(-x))\n.\n\n\nArguments\n\n\n\n\n\nx\n: A Tensor with type \nfloat\n, \ndouble\n, \nint32\n, \ncomplex64\n, \nint64\n,\nor \nqint32\n.\n\n\n\n\nReturns\n\n\n\nA Tensor with the same type as \nx\n if \nx.dtype != qint32\n otherwise\nthe return type is \nquint8\n.\n\n\n\n\nSoftmax\n\n\ntflearn.activations.softmax\n  (x)\n\n\nComputes softmax activations.\n\n\nFor each batch \ni\n and class \nj\n we have\n\n\nsoftmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n. Must be one of the following types: \nfloat32\n,\n\nfloat64\n. 2-D with shape \n[batch_size, num_classes]\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n. Has the same type as \nx\n. Same shape as \nx\n.\n\n\n\n\nSoftplus\n\n\ntflearn.activations.softplus\n  (x)\n\n\nComputes softplus: \nlog(exp(features) + 1)\n.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n. Must be one of the following types: \nfloat32\n,\n\nfloat64\n, \nint32\n, \nint64\n, \nuint8\n, \nint16\n, \nint8\n, \nuint16\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n. Has the same type as \nx\n.\n\n\n\n\nSoftsign\n\n\ntflearn.activations.softsign\n  (x)\n\n\nComputes softsign: \nfeatures / (abs(features) + 1)\n.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n. Must be one of the following types: \nfloat32\n,\n\nfloat64\n, \nint32\n, \nint64\n, \nuint8\n, \nint16\n, \nint8\n, \nuint16\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n. Has the same type as \nx\n.\n\n\n\n\nReLU\n\n\ntflearn.activations.relu\n  (x)\n\n\nComputes rectified linear: \nmax(features, 0)\n.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n. Must be one of the following types: \nfloat32\n,\n\nfloat64\n, \nint32\n, \nint64\n, \nuint8\n, \nint16\n, \nint8\n, \nuint16\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n. Has the same type as \nx\n.\n\n\n\n\nReLU6\n\n\ntflearn.activations.relu6\n  (x)\n\n\nComputes Rectified Linear 6: \nmin(max(features, 0), 6)\n.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n,\n\nint16\n, or \nint8\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n with the same type as \nx\n.\n\n\n\n\nLeakyReLU\n\n\ntflearn.activations.leaky_relu\n  (x,  alpha=0.1,  name='LeakyReLU')\n\n\nModified version of ReLU, introducing a nonzero gradient for negative\ninput.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n,\n\nint16\n, or \nint8\n.\n\n\nalpha\n: \nfloat\n. slope.\n\n\nname\n: A name for this activation op (optional).\n\n\n\n\nReturns\n\n\n\nA \nTensor\n with the same type as \nx\n.\n\n\nReferences\n\n\n\nRectifier Nonlinearities Improve Neural Network Acoustic Models,\nMaas et al. (2013).\n\n\nLinks\n\n\n\nhttp://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf\n\n\n\n\nPReLU\n\n\ntflearn.activations.prelu\n  (x,  weights_init='zeros',  restore=True,  name='PReLU')\n\n\nParametric Rectified Linear Unit.\n\n\nArguments\n\n\n\n\n\nx\n: A \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n,\n\nint16\n, or \nint8\n.\n\n\nweights_init\n: \nstr\n. Weights initialization. Default: zeros.\n\n\nrestore\n: \nbool\n. Restore or not alphas\n\n\nname\n: A name for this activation op (optional).\n\n\n\n\nAttributes\n\n\n\n\n\nscope\n: \nstr\n. This op scope.\n\n\nalphas\n: \nVariable\n. PReLU alphas.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n with the same type as \nx\n.\n\n\nReferences\n\n\n\nDelving Deep into Rectifiers: Surpassing Human-Level Performance\non ImageNet Classification. He et al., 2014.\n\n\nLinks\n\n\n\nhttp://arxiv.org/pdf/1502.01852v1.pdf\n\n\n\n\nELU\n\n\ntflearn.activations.elu\n  (x)\n\n\nExponential Linear Unit.\n\n\nArguments\n\n\n\n\n\nx : A \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n,\n\nint16\n, or \nint8\n.\n\n\nname : A name for this activation op (optional).\n\n\n\n\nReturns\n\n\n\nA \ntuple\n of \ntf.Tensor\n. This layer inference, i.e. output Tensors\nat training and testing time.\n\n\nReferences\n\n\n\nFast and Accurate Deep Network Learning by Exponential Linear Units,\nDjork-Arn\u00e9 Clevert, Thomas Unterthiner, Sepp Hochreiter. 2015.\n\n\nLinks\n\n\n\nhttp://arxiv.org/abs/1511.07289", 
            "title": "Activations"
        }, 
        {
            "location": "/activations/#linear", 
            "text": "tflearn.activations.linear   (x)  f(x) = x", 
            "title": "Linear"
        }, 
        {
            "location": "/activations/#tanh", 
            "text": "tflearn.activations.tanh   (x)  Computes hyperbolic tangent of  x  element-wise.", 
            "title": "Tanh"
        }, 
        {
            "location": "/activations/#sigmoid", 
            "text": "tflearn.activations.sigmoid   (x)  Computes sigmoid of  x  element-wise.\nSpecifically,  y = 1 / (1 + exp(-x)) .", 
            "title": "Sigmoid"
        }, 
        {
            "location": "/activations/#softmax", 
            "text": "tflearn.activations.softmax   (x)  Computes softmax activations.  For each batch  i  and class  j  we have  softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))", 
            "title": "Softmax"
        }, 
        {
            "location": "/activations/#softplus", 
            "text": "tflearn.activations.softplus   (x)  Computes softplus:  log(exp(features) + 1) .", 
            "title": "Softplus"
        }, 
        {
            "location": "/activations/#softsign", 
            "text": "tflearn.activations.softsign   (x)  Computes softsign:  features / (abs(features) + 1) .", 
            "title": "Softsign"
        }, 
        {
            "location": "/activations/#relu", 
            "text": "tflearn.activations.relu   (x)  Computes rectified linear:  max(features, 0) .", 
            "title": "ReLU"
        }, 
        {
            "location": "/activations/#relu6", 
            "text": "tflearn.activations.relu6   (x)  Computes Rectified Linear 6:  min(max(features, 0), 6) .", 
            "title": "ReLU6"
        }, 
        {
            "location": "/activations/#leakyrelu", 
            "text": "tflearn.activations.leaky_relu   (x,  alpha=0.1,  name='LeakyReLU')  Modified version of ReLU, introducing a nonzero gradient for negative\ninput.", 
            "title": "LeakyReLU"
        }, 
        {
            "location": "/activations/#prelu", 
            "text": "tflearn.activations.prelu   (x,  weights_init='zeros',  restore=True,  name='PReLU')  Parametric Rectified Linear Unit.", 
            "title": "PReLU"
        }, 
        {
            "location": "/activations/#elu", 
            "text": "tflearn.activations.elu   (x)  Exponential Linear Unit.", 
            "title": "ELU"
        }, 
        {
            "location": "/objectives/", 
            "text": "Softmax Categorical Crossentropy\n\n\ntflearn.objectives.softmax_categorical_crossentropy\n  (y_pred,  y_true)\n\n\nComputes softmax cross entropy between y_pred (logits) and\ny_true (labels).\n\n\nMeasures the probability error in discrete classification tasks in which\nthe classes are mutually exclusive (each entry is in exactly one class).\nFor example, each CIFAR-10 image is labeled with one and only one label:\nan image can be a dog or a truck, but not both.\n\n\nWARNING:\n This op expects unscaled logits, since it performs a \nsoftmax\n\non \ny_pred\n internally for efficiency.  Do not call this op with the\noutput of \nsoftmax\n, as it will produce incorrect results.\n\n\ny_pred\n and \ny_true\n must have the same shape \n[batch_size, num_classes]\n\nand the same dtype (either \nfloat32\n or \nfloat64\n). It is also required\nthat \ny_true\n (labels) are binary arrays (For example, class 2 out of a\ntotal of 5 different classes, will be define as [0., 1., 0., 0., 0.])\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n. Predicted values.\n\n\ny_true\n: \nTensor\n . Targets (labels), a probability distribution.\n\n\n\n\n\n\nCategorical Crossentropy\n\n\ntflearn.objectives.categorical_crossentropy\n  (y_pred,  y_true)\n\n\nComputes cross entropy between y_pred (logits) and y_true (labels).\n\n\nMeasures the probability error in discrete classification tasks in which\nthe classes are mutually exclusive (each entry is in exactly one class).\nFor example, each CIFAR-10 image is labeled with one and only one label:\nan image can be a dog or a truck, but not both.\n\n\ny_pred\n and \ny_true\n must have the same shape \n[batch_size, num_classes]\n\nand the same dtype (either \nfloat32\n or \nfloat64\n). It is also required\nthat \ny_true\n (labels) are binary arrays (For example, class 2 out of a\ntotal of 5 different classes, will be define as [0., 1., 0., 0., 0.])\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n. Predicted values.\n\n\ny_true\n: \nTensor\n . Targets (labels), a probability distribution.\n\n\n\n\n\n\nBinary Crossentropy\n\n\ntflearn.objectives.binary_crossentropy\n  (y_pred,  y_true)\n\n\nComputes sigmoid cross entropy between y_pred (logits) and y_true\n(labels).\n\n\nMeasures the probability error in discrete classification tasks in which\neach class is independent and not mutually exclusive. For instance,\none could perform multilabel classification where a picture can contain\nboth an elephant and a dog at the same time.\n\n\nFor brevity, let \nx = logits\n, \nz = targets\n.  The logistic loss is\n\n\nx - x * z + log(1 + exp(-x))\n\n\nTo ensure stability and avoid overflow, the implementation uses\n\n\nmax(x, 0) - x * z + log(1 + exp(-abs(x)))\n\n\ny_pred\n and \ny_true\n must have the same type and shape.\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n of \nfloat\n type. Predicted values.\n\n\ny_true\n: \nTensor\n of \nfloat\n type. Targets (labels).\n\n\n\n\n\n\nMean Square Loss\n\n\ntflearn.objectives.mean_square\n  (y_pred,  y_true)\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n of \nfloat\n type. Predicted values.\n\n\ny_true\n: \nTensor\n of \nfloat\n type. Targets (labels).\n\n\n\n\n\n\nHinge Loss\n\n\ntflearn.objectives.hinge_loss\n  (y_pred,  y_true)\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n of \nfloat\n type. Predicted values.\n\n\ny_true\n: \nTensor\n of \nfloat\n type. Targets (labels).\n\n\n\n\n\n\nROC AUC Score\n\n\ntflearn.objectives.roc_auc_score\n  (y_pred,  y_true)\n\n\nApproximates the Area Under Curve score, using approximation based on\nthe Wilcoxon-Mann-Whitney U statistic.\n\n\nYan, L., Dodier, R., Mozer, M. C., \n Wolniewicz, R. (2003).\nOptimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n\n\nMeasures overall performance for a full range of threshold levels.\n\n\nArguments\n\n\n\n\n\ny_pred\n: \nTensor\n. Predicted values.\n\n\ny_true\n: \nTensor\n . Targets (labels), a probability distribution.\n\n\n\n\n\n\nWeak Crossentropy 2d\n\n\ntflearn.objectives.weak_cross_entropy_2d\n  (y_pred,  y_true,  num_classes=None,  epsilon=0.0001,  head=None)\n\n\nCalculate the semantic segmentation using weak softmax cross entropy loss.\n\n\nGiven the prediction \ny_pred\n shaped as 2d image and the corresponding\ny_true, this calculated the widely used semantic segmentation loss.\nUsing \ntf.nn.softmax_cross_entropy_with_logits\n is currently not supported.\nSee https://github.com/tensorflow/tensorflow/issues/2327#issuecomment-224491229\n\n\nArguments\n\n\n\n\n\ny_pred\n: \ntensor, float\n - [batch_size, width, height, num_classes].\n\n\ny_true\n: \nLabels tensor, int32\n - [batch_size, width, height, num_classes].\nThe ground truth of your data.\n\n\nhead\n: \nnumpy array\n - [num_classes]. Weighting the loss of each class.\n\n\n\n\nReturns\n\n\n\nLoss tensor of type float.", 
            "title": "Objectives"
        }, 
        {
            "location": "/objectives/#softmax-categorical-crossentropy", 
            "text": "tflearn.objectives.softmax_categorical_crossentropy   (y_pred,  y_true)  Computes softmax cross entropy between y_pred (logits) and\ny_true (labels).  Measures the probability error in discrete classification tasks in which\nthe classes are mutually exclusive (each entry is in exactly one class).\nFor example, each CIFAR-10 image is labeled with one and only one label:\nan image can be a dog or a truck, but not both.  WARNING:  This op expects unscaled logits, since it performs a  softmax \non  y_pred  internally for efficiency.  Do not call this op with the\noutput of  softmax , as it will produce incorrect results.  y_pred  and  y_true  must have the same shape  [batch_size, num_classes] \nand the same dtype (either  float32  or  float64 ). It is also required\nthat  y_true  (labels) are binary arrays (For example, class 2 out of a\ntotal of 5 different classes, will be define as [0., 1., 0., 0., 0.])", 
            "title": "Softmax Categorical Crossentropy"
        }, 
        {
            "location": "/objectives/#categorical-crossentropy", 
            "text": "tflearn.objectives.categorical_crossentropy   (y_pred,  y_true)  Computes cross entropy between y_pred (logits) and y_true (labels).  Measures the probability error in discrete classification tasks in which\nthe classes are mutually exclusive (each entry is in exactly one class).\nFor example, each CIFAR-10 image is labeled with one and only one label:\nan image can be a dog or a truck, but not both.  y_pred  and  y_true  must have the same shape  [batch_size, num_classes] \nand the same dtype (either  float32  or  float64 ). It is also required\nthat  y_true  (labels) are binary arrays (For example, class 2 out of a\ntotal of 5 different classes, will be define as [0., 1., 0., 0., 0.])", 
            "title": "Categorical Crossentropy"
        }, 
        {
            "location": "/objectives/#binary-crossentropy", 
            "text": "tflearn.objectives.binary_crossentropy   (y_pred,  y_true)  Computes sigmoid cross entropy between y_pred (logits) and y_true\n(labels).  Measures the probability error in discrete classification tasks in which\neach class is independent and not mutually exclusive. For instance,\none could perform multilabel classification where a picture can contain\nboth an elephant and a dog at the same time.  For brevity, let  x = logits ,  z = targets .  The logistic loss is  x - x * z + log(1 + exp(-x))  To ensure stability and avoid overflow, the implementation uses  max(x, 0) - x * z + log(1 + exp(-abs(x)))  y_pred  and  y_true  must have the same type and shape.", 
            "title": "Binary Crossentropy"
        }, 
        {
            "location": "/objectives/#mean-square-loss", 
            "text": "tflearn.objectives.mean_square   (y_pred,  y_true)", 
            "title": "Mean Square Loss"
        }, 
        {
            "location": "/objectives/#hinge-loss", 
            "text": "tflearn.objectives.hinge_loss   (y_pred,  y_true)", 
            "title": "Hinge Loss"
        }, 
        {
            "location": "/objectives/#roc-auc-score", 
            "text": "tflearn.objectives.roc_auc_score   (y_pred,  y_true)  Approximates the Area Under Curve score, using approximation based on\nthe Wilcoxon-Mann-Whitney U statistic.  Yan, L., Dodier, R., Mozer, M. C.,   Wolniewicz, R. (2003).\nOptimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.  Measures overall performance for a full range of threshold levels.", 
            "title": "ROC AUC Score"
        }, 
        {
            "location": "/objectives/#weak-crossentropy-2d", 
            "text": "tflearn.objectives.weak_cross_entropy_2d   (y_pred,  y_true,  num_classes=None,  epsilon=0.0001,  head=None)  Calculate the semantic segmentation using weak softmax cross entropy loss.  Given the prediction  y_pred  shaped as 2d image and the corresponding\ny_true, this calculated the widely used semantic segmentation loss.\nUsing  tf.nn.softmax_cross_entropy_with_logits  is currently not supported.\nSee https://github.com/tensorflow/tensorflow/issues/2327#issuecomment-224491229", 
            "title": "Weak Crossentropy 2d"
        }, 
        {
            "location": "/optimizers/", 
            "text": "Base Optimizer class\n\n\ntflearn.optimizers.Optimizer\n  (learning_rate,  use_locking,  name)\n\n\nA basic class to create optimizers to be used with TFLearn estimators.\nFirst, The Optimizer class is initialized with given parameters,\nbut no Tensor is created. In a second step, invoking \nget_tensor\n method\nwill actually build the Tensorflow \nOptimizer\n Tensor, and return it.\n\n\nThis way, a user can easily specifies an optimizer with non default\nparameters and learning rate decay, while TFLearn estimators will\nbuild the optimizer and a step tensor by itself.\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. The optimizer name.\n\n\n\n\nAttributes\n\n\n\n\n\ntensor\n: \nOptimizer\n. The optimizer tensor.\n\n\nhas_decay\n: \nbool\n. True if optimizer has a learning rate decay.\n\n\n\n\nMethods\n\n\n\n \n\n\nbuild\n  (step_tensor=None)\n\n\nThis method creates the optimizer with specified parameters. It must\nbe implemented for every \nOptimizer\n.\n\n\nArguments\n\n\n\n\n\nstep_tensor\n: \ntf.Tensor\n. A variable holding the training step.\nOnly necessary when optimizer has a learning rate decay.\n\n\n\n\n \n\n\nget_tensor\n  (self)\n\n\nA method to retrieve the optimizer tensor.\n\n\nReturns\n\n\n\nThe \nOptimizer\n.\n\n\n\n\nStochastic Gradient Descent\n\n\ntflearn.optimizers.SGD\n  (learning_rate=0.001,  lr_decay=0.0,  decay_step=100,  staircase=False,  use_locking=False,  name='SGD')\n\n\nSGD Optimizer accepts learning rate decay. When training a model,\nit is often recommended to lower the learning rate as the training\nprogresses. The function returns the decayed learning rate.  It is\ncomputed as:\n\n\ndecayed_learning_rate = learning_rate *  decay_rate ^ (global_step / decay_steps)\n\n\n\n\nExamples\n\n\n\n# With TFLearn estimators.\nsgd = SGD(learning_rate=0.01, lr_decay=0.96, decay_step=100)\nregression = regression(net, optimizer=sgd)\n\n# Without TFLearn estimators (returns tf.Optimizer).\nsgd = SGD(learning_rate=0.01).get_tensor()\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nlr_decay\n: \nfloat\n. The learning rate decay to apply.\n\n\ndecay_step\n: \nint\n. Apply decay every provided steps.\n\n\nstaircase\n: \nbool\n. It \nTrue\n decay learning rate at discrete intervals.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"GradientDescent\".\n\n\n\n\n\n\nRMSprop\n\n\ntflearn.optimizers.RMSProp\n  (learning_rate=0.001,  decay=0.9,  momentum=0.0,  epsilon=1e-10,  use_locking=False,  name='RMSProp')\n\n\nMaintain a moving (discounted) average of the square of gradients.\nDivide gradient by the root of this average.\n\n\nExamples\n\n\n\n# With TFLearn estimators.\nrmsprop = RMSProp(learning_rate=0.1, decay=0.999)\nregression = regression(net, optimizer=rmsprop)\n\n# Without TFLearn estimators (returns tf.Optimizer).\nrmsprop = RMSProp(learning_rate=0.01, decay=0.999).get_tensor()\n# or\nrmsprop = RMSProp(learning_rate=0.01, decay=0.999)()\n\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\ndecay\n: \nfloat\n. Discounting factor for the history/coming gradient.\n\n\nmomentum\n: \nfloat\n. Momentum.\n\n\nepsilon\n: \nfloat\n. Small value to avoid zero denominator.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"RMSProp\".\n\n\n\n\n\n\nAdam\n\n\ntflearn.optimizers.Adam\n  (learning_rate=0.001,  beta1=0.9,  beta2=0.999,  epsilon=1e-08,  use_locking=False,  name='Adam')\n\n\nThe default value of 1e-8 for epsilon might not be a good default in\ngeneral. For example, when training an Inception network on ImageNet a\ncurrent good choice is 1.0 or 0.1.\n\n\nExamples\n\n\n\n# With TFLearn estimators\nadam = Adam(learning_rate=0.001, beta1=0.99)\nregression = regression(net, optimizer=adam)\n\n# Without TFLearn estimators (returns tf.Optimizer)\nadam = Adam(learning_rate=0.01).get_tensor()\n\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\nbeta1\n: \nfloat\n. The exponential decay rate for the 1st moment\nestimates.\n\n\nbeta2\n: \nfloat\n. The exponential decay rate for the 2nd moment\nestimates.\n\n\nepsilon\n: \nfloat\n. A small constant for numerical stability.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"Adam\".\n\n\n\n\nReferences\n\n\n\nAdam: A Method for Stochastic Optimization. Diederik Kingma,\nJimmy Ba. ICLR 2015.\n\n\nLinks\n\n\n\nPaper\n\n\n\n\nMomentum\n\n\ntflearn.optimizers.Momentum\n  (learning_rate=0.001,  momentum=0.9,  lr_decay=0.0,  decay_step=100,  staircase=False,  use_locking=False,  name='Momentum')\n\n\nMomentum Optimizer accepts learning rate decay. When training a model,\nit is often recommended to lower the learning rate as the training\nprogresses. The function returns the decayed learning rate.  It is\ncomputed as:\n\n\ndecayed_learning_rate = learning_rate *  decay_rate ^ (global_step / decay_steps)\n\n\n\n\nExamples\n\n\n\n# With TFLearn estimators\nmomentum = Momentum(learning_rate=0.01, lr_decay=0.96, decay_step=100)\nregression = regression(net, optimizer=momentum)\n\n# Without TFLearn estimators (returns tf.Optimizer)\nmm = Momentum(learning_rate=0.01, lr_decay=0.96).get_tensor()\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\nmomentum\n: \nfloat\n. Momentum.\n\n\nlr_decay\n: \nfloat\n. The learning rate decay to apply.\n\n\ndecay_step\n: \nint\n. Apply decay every provided steps.\n\n\nstaircase\n: \nbool\n. It \nTrue\n decay learning rate at discrete intervals.\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"Momentum\".\n\n\n\n\n\n\nAdaGrad\n\n\ntflearn.optimizers.AdaGrad\n  (learning_rate=0.001,  initial_accumulator_value=0.1,  use_locking=False,  name='AdaGrad')\n\n\nExamples\n\n\n\n# With TFLearn estimators\nadagrad = AdaGrad(learning_rate=0.01, initial_accumulator_value=0.01)\nregression = regression(net, optimizer=adagrad)\n\n# Without TFLearn estimators (returns tf.Optimizer)\nadagrad = AdaGrad(learning_rate=0.01).get_tensor()\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\ninitial_accumulator_value\n: \nfloat\n. Starting value for the\naccumulators, must be positive\n\n\nuse_locking\n: \nbool\n. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"AdaGrad\".\n\n\n\n\nReferences\n\n\n\nAdaptive Subgradient Methods for Online Learning and Stochastic\nOptimization. J. Duchi, E. Hazan \n Y. Singer. Journal of Machine\nLearning Research 12 (2011) 2121-2159.\n\n\nLinks\n\n\n\nPaper\n\n\n\n\nFtrl Proximal\n\n\ntflearn.optimizers.Ftrl\n  (learning_rate=3.0,  learning_rate_power=-0.5,  initial_accumulator_value=0.1,  l1_regularization_strength=0.0,  l2_regularization_strength=0.0,  use_locking=False,  name='Ftrl')\n\n\nThe Ftrl-proximal algorithm, abbreviated for Follow-the-regularized-leader,\nis described in the paper below.\n\n\nIt can give a good performance vs. sparsity tradeoff.\n\n\nFtrl-proximal uses its own global base learning rate and can behave like\nAdagrad with \nlearning_rate_power=-0.5\n, or like gradient descent with\n\nlearning_rate_power=0.0\n.\n\n\nExamples\n\n\n\n# With TFLearn estimators.\nftrl = Ftrl(learning_rate=0.01, learning_rate_power=-0.1)\nregression = regression(net, optimizer=ftrl)\n\n# Without TFLearn estimators (returns tf.Optimizer).\nftrl = Ftrl(learning_rate=0.01).get_tensor()\n\n\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: \nfloat\n. Learning rate.\n\n\nlearning_rate_power\n: \nfloat\n. Must be less or equal to zero.\n\n\ninitial_accumulator_value\n: \nfloat\n. The starting value for accumulators.\nOnly positive values are allowed.\n\n\nl1_regularization_strength\n: \nfloat\n. Must be less or equal to zero.\n\n\nl2_regularization_strength\n: \nfloat\n. Must be less or equal to zero.\n\n\nuse_locking\n: bool`. If True use locks for update operation.\n\n\nname\n: \nstr\n. Optional name prefix for the operations created when\napplying gradients. Defaults to \"Ftrl\".\n\n\n\n\nLinks\n\n\n\nAd Click Prediction: a View from the Trenches\n\n\n\n\nAdaDelta\n\n\ntflearn.optimizers.AdaDelta\n  (learning_rate=0.001,  rho=0.1,  epsilon=1e-08,  use_locking=False,  name='AdaDelta')\n\n\nConstruct a new Adadelta optimizer.\n\n\nArguments\n\n\n\n\n\nlearning_rate\n: A \nTensor\n or a floating point value. The learning rate.\n\n\nrho\n: A \nTensor\n or a floating point value. The decay rate.\n\n\nepsilon\n: A \nTensor\n or a floating point value.  A constant epsilon used\nto better conditioning the grad update.\n\n\nuse_locking\n: If \nTrue\n use locks for update operations.\n\n\nname\n: Optional name prefix for the operations created when applying\ngradients.  Defaults to \"Adadelta\".\n\n\n\n\nReferences\n\n\n\nADADELTA: An Adaptive Learning Rate Method, Matthew D. Zeiler, 2012.\n\n\nLinks\n\n\n\nhttp://arxiv.org/abs/1212.5701", 
            "title": "Optimizers"
        }, 
        {
            "location": "/optimizers/#base-optimizer-class", 
            "text": "tflearn.optimizers.Optimizer   (learning_rate,  use_locking,  name)  A basic class to create optimizers to be used with TFLearn estimators.\nFirst, The Optimizer class is initialized with given parameters,\nbut no Tensor is created. In a second step, invoking  get_tensor  method\nwill actually build the Tensorflow  Optimizer  Tensor, and return it.  This way, a user can easily specifies an optimizer with non default\nparameters and learning rate decay, while TFLearn estimators will\nbuild the optimizer and a step tensor by itself.", 
            "title": "Base Optimizer class"
        }, 
        {
            "location": "/optimizers/#stochastic-gradient-descent", 
            "text": "tflearn.optimizers.SGD   (learning_rate=0.001,  lr_decay=0.0,  decay_step=100,  staircase=False,  use_locking=False,  name='SGD')  SGD Optimizer accepts learning rate decay. When training a model,\nit is often recommended to lower the learning rate as the training\nprogresses. The function returns the decayed learning rate.  It is\ncomputed as:  decayed_learning_rate = learning_rate *  decay_rate ^ (global_step / decay_steps)", 
            "title": "Stochastic Gradient Descent"
        }, 
        {
            "location": "/optimizers/#rmsprop", 
            "text": "tflearn.optimizers.RMSProp   (learning_rate=0.001,  decay=0.9,  momentum=0.0,  epsilon=1e-10,  use_locking=False,  name='RMSProp')  Maintain a moving (discounted) average of the square of gradients.\nDivide gradient by the root of this average.", 
            "title": "RMSprop"
        }, 
        {
            "location": "/optimizers/#adam", 
            "text": "tflearn.optimizers.Adam   (learning_rate=0.001,  beta1=0.9,  beta2=0.999,  epsilon=1e-08,  use_locking=False,  name='Adam')  The default value of 1e-8 for epsilon might not be a good default in\ngeneral. For example, when training an Inception network on ImageNet a\ncurrent good choice is 1.0 or 0.1.", 
            "title": "Adam"
        }, 
        {
            "location": "/optimizers/#momentum", 
            "text": "tflearn.optimizers.Momentum   (learning_rate=0.001,  momentum=0.9,  lr_decay=0.0,  decay_step=100,  staircase=False,  use_locking=False,  name='Momentum')  Momentum Optimizer accepts learning rate decay. When training a model,\nit is often recommended to lower the learning rate as the training\nprogresses. The function returns the decayed learning rate.  It is\ncomputed as:  decayed_learning_rate = learning_rate *  decay_rate ^ (global_step / decay_steps)", 
            "title": "Momentum"
        }, 
        {
            "location": "/optimizers/#adagrad", 
            "text": "tflearn.optimizers.AdaGrad   (learning_rate=0.001,  initial_accumulator_value=0.1,  use_locking=False,  name='AdaGrad')", 
            "title": "AdaGrad"
        }, 
        {
            "location": "/optimizers/#ftrl-proximal", 
            "text": "tflearn.optimizers.Ftrl   (learning_rate=3.0,  learning_rate_power=-0.5,  initial_accumulator_value=0.1,  l1_regularization_strength=0.0,  l2_regularization_strength=0.0,  use_locking=False,  name='Ftrl')  The Ftrl-proximal algorithm, abbreviated for Follow-the-regularized-leader,\nis described in the paper below.  It can give a good performance vs. sparsity tradeoff.  Ftrl-proximal uses its own global base learning rate and can behave like\nAdagrad with  learning_rate_power=-0.5 , or like gradient descent with learning_rate_power=0.0 .", 
            "title": "Ftrl Proximal"
        }, 
        {
            "location": "/optimizers/#adadelta", 
            "text": "tflearn.optimizers.AdaDelta   (learning_rate=0.001,  rho=0.1,  epsilon=1e-08,  use_locking=False,  name='AdaDelta')  Construct a new Adadelta optimizer.", 
            "title": "AdaDelta"
        }, 
        {
            "location": "/metrics/", 
            "text": "Base Metric Class\n\n\ntflearn.metrics.Metric\n  (name=None)\n\n\nMetric class is meant to be used by TFLearn models class. It can be\nfirst initialized with desired parameters, and a model class will\nbuild it later using the given network output and targets.\n\n\nAttributes\n\n\n\n\n\ntensor\n: \nTensor\n. The metric tensor.\n\n\n\n\nMethods\n\n\n\n \n\n\nbuild\n  (predictions,  targets,  inputs)\n\n\nBuild metric method, with common arguments to all Metrics.\n\n\nArguments\n\n\n\n\n\nprediction\n: \nTensor\n. The network to perform prediction.\n\n\ntargets\n: \nTensor\n. The targets (labels).\n\n\ninputs\n: \nTensor\n. The input data.\n\n\n\n\n \n\n\nget_tensor\n  (self)\n\n\nGet the metric tensor.\n\n\nReturns\n\n\n\nThe metric \nTensor\n.\n\n\n\n\nAccuracy\n\n\ntflearn.metrics.Accuracy\n  (name='acc')\n\n\nComputes the model accuracy.\n\n\nExamples\n\n\n\n# To be used with TFLearn estimators\nacc = Accuracy()\nregression = regression(net, metric=acc)\n\n\n\n\nArguments\n\n\n\n\n\nname\n: The name to display.\n\n\n\n\n\n\nTop-k\n\n\ntflearn.metrics.Top_k\n  (k=1,  name=None)\n\n\nComputes Top-k mean accuracy (whether the targets are in the top 'K'\npredictions).\n\n\nExamples\n\n\n\n# To be used with TFLearn estimators\ntop5 = Top_k(k=5)\nregression = regression(net, metric=top5)\n\n\n\n\nArguments\n\n\n\n\n\nk\n: \nint\n. Number of top elements to look at for computing precision.\n\n\nname\n: The name to display.\n\n\n\n\n\n\nStandard Error\n\n\ntflearn.metrics.R2\n  (name=None)\n\n\nComputes coefficient of determination. Useful to evaluate a linear\nregression.\n\n\nExamples\n\n\n\n# To be used with TFLearn estimators\nr2 = R2()\nregression = regression(net, metric=r2)\n\n\n\n\nArguments\n\n\n\n\n\nname\n: The name to display.\n\n\n\n\n\n\naccuracy_op\n\n\ntflearn.metrics.accuracy_op\n  (predictions,  targets)\n\n\nAn op that calculates mean accuracy.\n\n\nExamples\n\n\n\ninput_data = placeholder(shape=[None, 784])\ny_pred = my_network(input_data) # Apply some ops\ny_true = placeholder(shape=[None, 10]) # Labels\nacc_op = accuracy_op(y_pred, y_true)\n\n# Calculate accuracy by feeding data X and labels Y\naccuracy = sess.run(acc_op, feed_dict={input_data: X, y_true: Y})\n\n\n\n\nArguments\n\n\n\n\n\npredictions\n: \nTensor\n.\n\n\ntargets\n: \nTensor\n.\n\n\n\n\nReturns\n\n\n\nFloat\n. The mean accuracy.\n\n\n\n\ntop_k_op\n\n\ntflearn.metrics.top_k_op\n  (predictions,  targets,  k=1)\n\n\nAn op that calculates top-k mean accuracy.\n\n\nExamples\n\n\n\ninput_data = placeholder(shape=[None, 784])\ny_pred = my_network(input_data) # Apply some ops\ny_true = placeholder(shape=[None, 10]) # Labels\ntop3_op = top_k_op(y_pred, y_true, 3)\n\n# Calculate Top-3 accuracy by feeding data X and labels Y\ntop3_accuracy = sess.run(top3_op, feed_dict={input_data: X, y_true: Y})\n\n\n\n\nArguments\n\n\n\n\n\npredictions\n: \nTensor\n.\n\n\ntargets\n: \nTensor\n.\n\n\nk\n: \nint\n. Number of top elements to look at for computing precision.\n\n\n\n\nReturns\n\n\n\nFloat\n. The top-k mean accuracy.\n\n\n\n\nr2_op\n\n\ntflearn.metrics.r2_op\n  (predictions,  targets,  inputs)\n\n\nAn op that calculates the standard error.\n\n\nExamples\n\n\n\ninput_data = placeholder(shape=[None, 784])\ny_pred = my_network(input_data) # Apply some ops\ny_true = placeholder(shape=[None, 10]) # Labels\nstderr_op = r2_op(y_pred, y_true, input_data)\n\n# Calculate standard error by feeding data X and labels Y\nstd_error = sess.run(stderr_op, feed_dict={input_data: X, y_true: Y})\n\n\n\n\nArguments\n\n\n\n\n\npredictions\n: \nTensor\n.\n\n\ntargets\n: \nTensor\n.\n\n\ninputs\n: \nTensor\n.\n\n\n\n\nReturns\n\n\n\nFloat\n. The standard error.", 
            "title": "Metrics"
        }, 
        {
            "location": "/metrics/#base-metric-class", 
            "text": "tflearn.metrics.Metric   (name=None)  Metric class is meant to be used by TFLearn models class. It can be\nfirst initialized with desired parameters, and a model class will\nbuild it later using the given network output and targets.", 
            "title": "Base Metric Class"
        }, 
        {
            "location": "/metrics/#accuracy", 
            "text": "tflearn.metrics.Accuracy   (name='acc')  Computes the model accuracy.", 
            "title": "Accuracy"
        }, 
        {
            "location": "/metrics/#top-k", 
            "text": "tflearn.metrics.Top_k   (k=1,  name=None)  Computes Top-k mean accuracy (whether the targets are in the top 'K'\npredictions).", 
            "title": "Top-k"
        }, 
        {
            "location": "/metrics/#standard-error", 
            "text": "tflearn.metrics.R2   (name=None)  Computes coefficient of determination. Useful to evaluate a linear\nregression.", 
            "title": "Standard Error"
        }, 
        {
            "location": "/metrics/#accuracy_op", 
            "text": "tflearn.metrics.accuracy_op   (predictions,  targets)  An op that calculates mean accuracy.", 
            "title": "accuracy_op"
        }, 
        {
            "location": "/metrics/#top_k_op", 
            "text": "tflearn.metrics.top_k_op   (predictions,  targets,  k=1)  An op that calculates top-k mean accuracy.", 
            "title": "top_k_op"
        }, 
        {
            "location": "/metrics/#r2_op", 
            "text": "tflearn.metrics.r2_op   (predictions,  targets,  inputs)  An op that calculates the standard error.", 
            "title": "r2_op"
        }, 
        {
            "location": "/initializations/", 
            "text": "Zeros\n\n\ntflearn.initializations.zeros\n  (shape=None,  dtype=tf.float32,  seed=None)\n\n\nInitialize a tensor with all elements set to zero.\n\n\nArguments\n\n\n\n\n\nshape\n: List of \nint\n. A shape to initialize a Tensor (optional).\n\n\ndtype\n: The tensor data type.\n\n\n\n\nReturns\n\n\n\nThe Initializer, or an initialized \nTensor\n if a shape is specified.\n\n\n\n\nUniform\n\n\ntflearn.initializations.uniform\n  (shape=None,  minval=0,  maxval=None,  dtype=tf.float32,  seed=None)\n\n\nInitialization with random values from a uniform distribution.\n\n\nThe generated values follow a uniform distribution in the range\n\n[minval, maxval)\n. The lower bound \nminval\n is included in the range,\nwhile the upper bound \nmaxval\n is excluded.\n\n\nFor floats, the default range is \n[0, 1)\n.  For ints, at least \nmaxval\n\nmust be specified explicitly.\n\n\nIn the integer case, the random integers are slightly biased unless\n\nmaxval - minval\n is an exact power of two.  The bias is small for values of\n\nmaxval - minval\n significantly smaller than the range of the output (either\n\n2**32\n or \n2**64\n).\n\n\nArguments\n\n\n\n\n\nshape\n: List of \nint\n. A shape to initialize a Tensor (optional).\n\n\ndtype\n: The tensor data type. Only float are supported.\n\n\nseed\n: \nint\n. Used to create a random seed for the distribution.\n\n\n\n\nReturns\n\n\n\nThe Initializer, or an initialized \nTensor\n if shape is specified.\n\n\n\n\nUniform Scaling\n\n\ntflearn.initializations.uniform_scaling\n  (shape=None,  factor=1.0,  dtype=tf.float32,  seed=None)\n\n\nInitialization with random values from uniform distribution without scaling\nvariance.\n\n\nWhen initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. If the input is \nx\n and the operation \nx * W\n,\nand we want to initialize \nW\n uniformly at random, we need to pick \nW\n from\n\n\n[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]\n\n\nto keep the scale intact, where \ndim = W.shape[0]\n (the size of the input).\nA similar calculation for convolutional networks gives an analogous result\nwith \ndim\n equal to the product of the first 3 dimensions.  When\nnonlinearities are present, we need to multiply this by a constant \nfactor\n.\nSee \nSussillo et al., 2014\n\n(\npdf\n) for deeper motivation, experiments\nand the calculation of constants. In section 2.3 there, the constants were\nnumerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.\n\n\nArguments\n\n\n\n\n\nshape\n: List of \nint\n. A shape to initialize a Tensor (optional).\n\n\nfactor\n: \nfloat\n. A multiplicative factor by which the values will be\nscaled.\n\n\ndtype\n: The tensor data type. Only float are supported.\n\n\nseed\n: \nint\n. Used to create a random seed for the distribution.\n\n\n\n\nReturns\n\n\n\nThe Initializer, or an initialized \nTensor\n if shape is specified.\n\n\n\n\nNormal\n\n\ntflearn.initializations.normal\n  (shape=None,  mean=0.0,  stddev=0.02,  dtype=tf.float32,  seed=None)\n\n\nInitialization with random values from a normal distribution.\n\n\nArguments\n\n\n\n\n\nshape\n: List of \nint\n. A shape to initialize a Tensor (optional).\n\n\nmean\n: Same as \ndtype\n. The mean of the truncated normal distribution.\n\n\nstddev\n: Same as \ndtype\n. The standard deviation of the truncated\nnormal distribution.\n\n\ndtype\n: The tensor data type.\n\n\nseed\n: \nint\n. Used to create a random seed for the distribution.\n\n\n\n\nReturns\n\n\n\nThe Initializer, or an initialized \nTensor\n if shape is specified.\n\n\n\n\nTruncated Normal\n\n\ntflearn.initializations.truncated_normal\n  (shape=None,  mean=0.0,  stddev=0.02,  dtype=tf.float32,  seed=None)\n\n\nInitialization with random values from a normal truncated distribution.\n\n\nThe generated values follow a normal distribution with specified mean and\nstandard deviation, except that values whose magnitude is more than 2 standard\ndeviations from the mean are dropped and re-picked.\n\n\nArguments\n\n\n\n\n\nshape\n: List of \nint\n. A shape to initialize a Tensor (optional).\n\n\nmean\n: Same as \ndtype\n. The mean of the truncated normal distribution.\n\n\nstddev\n: Same as \ndtype\n. The standard deviation of the truncated\nnormal distribution.\n\n\ndtype\n: The tensor data type.\n\n\nseed\n: \nint\n. Used to create a random seed for the distribution.\n\n\n\n\nReturns\n\n\n\nThe Initializer, or an initialized \nTensor\n if shape is specified.\n\n\n\n\nXavier\n\n\ntflearn.initializations.xavier\n  (uniform=True,  seed=None,  dtype=tf.float32)\n\n\nReturns an initializer performing \"Xavier\" initialization for weights.\n\n\nThis initializer is designed to keep the scale of the gradients roughly the\nsame in all layers. In uniform distribution this ends up being the range:\n\nx = sqrt(6. / (in + out)); [-x, x]\n and for normal distribution a standard\ndeviation of \nsqrt(3. / (in + out))\n is used.\n\n\nArguments\n\n\n\n\n\nuniform\n: Whether to use uniform or normal distributed random\ninitialization.\n\n\nseed\n: A Python integer. Used to create random seeds. See\n\nset_random_seed\n for behavior.\n\n\ndtype\n: The data type. Only floating point types are supported.\n\n\n\n\nReturns\n\n\n\nAn initializer for a weight matrix.\n\n\nReferences\n\n\n\nUnderstanding the difficulty of training deep feedforward neural\nnetworks. International conference on artificial intelligence and\nstatistics. Xavier Glorot and Yoshua Bengio (2010).\n\n\nLinks\n\n\n\nhttp://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n\n\n\n\nVariance Scaling\n\n\ntflearn.initializations.variance_scaling\n  (factor=2.0,  mode='FAN_IN',  uniform=False,  seed=None,  dtype=tf.float32)\n\n\nReturns an initializer that generates tensors without scaling variance.\n\n\nWhen initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. This initializer use the following formula:\n\n\nif mode='FAN_IN': # Count only number of input connections.\n  n = fan_in\nelif mode='FAN_OUT': # Count only number of output connections.\n  n = fan_out\nelif mode='FAN_AVG': # Average number of inputs and output connections.\n  n = (fan_in + fan_out)/2.0\n\n  truncated_normal(shape, 0.0, stddev=sqrt(factor / n))\n\n\n\n\nTo get http://arxiv.org/pdf/1502.01852v1.pdf use (Default):\n- factor=2.0 mode='FAN_IN' uniform=False\n\n\nTo get http://arxiv.org/abs/1408.5093 use:\n- factor=1.0 mode='FAN_IN' uniform=True\n\n\nTo get http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf use:\n- factor=1.0 mode='FAN_AVG' uniform=True.\n\n\nTo get xavier_initializer use either:\n- factor=1.0 mode='FAN_AVG' uniform=True.\n- factor=1.0 mode='FAN_AVG' uniform=False.\n\n\nArguments\n\n\n\n\n\nfactor\n: Float.  A multiplicative factor.\n\n\nmode\n: String.  'FAN_IN', 'FAN_OUT', 'FAN_AVG'.\n\n\nuniform\n: Whether to use uniform or normal distributed random\ninitialization.\n\n\nseed\n: A Python integer. Used to create random seeds. See\n\nset_random_seed\n for behavior.\n\n\ndtype\n: The data type. Only floating point types are supported.\n\n\n\n\nReturns\n\n\n\nAn initializer that generates tensors with unit variance.", 
            "title": "Initializations"
        }, 
        {
            "location": "/initializations/#zeros", 
            "text": "tflearn.initializations.zeros   (shape=None,  dtype=tf.float32,  seed=None)  Initialize a tensor with all elements set to zero.", 
            "title": "Zeros"
        }, 
        {
            "location": "/initializations/#uniform", 
            "text": "tflearn.initializations.uniform   (shape=None,  minval=0,  maxval=None,  dtype=tf.float32,  seed=None)  Initialization with random values from a uniform distribution.  The generated values follow a uniform distribution in the range [minval, maxval) . The lower bound  minval  is included in the range,\nwhile the upper bound  maxval  is excluded.  For floats, the default range is  [0, 1) .  For ints, at least  maxval \nmust be specified explicitly.  In the integer case, the random integers are slightly biased unless maxval - minval  is an exact power of two.  The bias is small for values of maxval - minval  significantly smaller than the range of the output (either 2**32  or  2**64 ).", 
            "title": "Uniform"
        }, 
        {
            "location": "/initializations/#uniform-scaling", 
            "text": "tflearn.initializations.uniform_scaling   (shape=None,  factor=1.0,  dtype=tf.float32,  seed=None)  Initialization with random values from uniform distribution without scaling\nvariance.  When initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. If the input is  x  and the operation  x * W ,\nand we want to initialize  W  uniformly at random, we need to pick  W  from  [-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]  to keep the scale intact, where  dim = W.shape[0]  (the size of the input).\nA similar calculation for convolutional networks gives an analogous result\nwith  dim  equal to the product of the first 3 dimensions.  When\nnonlinearities are present, we need to multiply this by a constant  factor .\nSee  Sussillo et al., 2014 \n( pdf ) for deeper motivation, experiments\nand the calculation of constants. In section 2.3 there, the constants were\nnumerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.", 
            "title": "Uniform Scaling"
        }, 
        {
            "location": "/initializations/#normal", 
            "text": "tflearn.initializations.normal   (shape=None,  mean=0.0,  stddev=0.02,  dtype=tf.float32,  seed=None)  Initialization with random values from a normal distribution.", 
            "title": "Normal"
        }, 
        {
            "location": "/initializations/#truncated-normal", 
            "text": "tflearn.initializations.truncated_normal   (shape=None,  mean=0.0,  stddev=0.02,  dtype=tf.float32,  seed=None)  Initialization with random values from a normal truncated distribution.  The generated values follow a normal distribution with specified mean and\nstandard deviation, except that values whose magnitude is more than 2 standard\ndeviations from the mean are dropped and re-picked.", 
            "title": "Truncated Normal"
        }, 
        {
            "location": "/initializations/#xavier", 
            "text": "tflearn.initializations.xavier   (uniform=True,  seed=None,  dtype=tf.float32)  Returns an initializer performing \"Xavier\" initialization for weights.  This initializer is designed to keep the scale of the gradients roughly the\nsame in all layers. In uniform distribution this ends up being the range: x = sqrt(6. / (in + out)); [-x, x]  and for normal distribution a standard\ndeviation of  sqrt(3. / (in + out))  is used.", 
            "title": "Xavier"
        }, 
        {
            "location": "/initializations/#variance-scaling", 
            "text": "tflearn.initializations.variance_scaling   (factor=2.0,  mode='FAN_IN',  uniform=False,  seed=None,  dtype=tf.float32)  Returns an initializer that generates tensors without scaling variance.  When initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. This initializer use the following formula:  if mode='FAN_IN': # Count only number of input connections.\n  n = fan_in\nelif mode='FAN_OUT': # Count only number of output connections.\n  n = fan_out\nelif mode='FAN_AVG': # Average number of inputs and output connections.\n  n = (fan_in + fan_out)/2.0\n\n  truncated_normal(shape, 0.0, stddev=sqrt(factor / n))  To get http://arxiv.org/pdf/1502.01852v1.pdf use (Default):\n- factor=2.0 mode='FAN_IN' uniform=False  To get http://arxiv.org/abs/1408.5093 use:\n- factor=1.0 mode='FAN_IN' uniform=True  To get http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf use:\n- factor=1.0 mode='FAN_AVG' uniform=True.  To get xavier_initializer use either:\n- factor=1.0 mode='FAN_AVG' uniform=True.\n- factor=1.0 mode='FAN_AVG' uniform=False.", 
            "title": "Variance Scaling"
        }, 
        {
            "location": "/losses/", 
            "text": "L2\n\n\ntflearn.losses.L2\n  (tensor,  wd=0.001)\n\n\nComputes half the L2 norm of a tensor without the \nsqrt\n:\n\n\noutput = sum(t ** 2) / 2 * wd\n\n\nArguments\n\n\n\n\n\ntensor\n: \nTensor\n. The tensor to apply regularization.\n\n\nwd\n: \nfloat\n. The decay.\n\n\n\n\nReturns\n\n\n\nThe regularization \nTensor\n.\n\n\n\n\nL1\n\n\ntflearn.losses.L1\n  (tensor,  wd=0.001)\n\n\nComputes the L1 norm of a tensor:\n\n\noutput = sum(|t|) * wd\n\n\nArguments\n\n\n\n\n\ntensor\n: \nTensor\n. The tensor to apply regularization.\n\n\nwd\n: \nfloat\n. The decay.\n\n\n\n\nReturns\n\n\n\nThe regularization \nTensor\n.", 
            "title": "Losses"
        }, 
        {
            "location": "/losses/#l2", 
            "text": "tflearn.losses.L2   (tensor,  wd=0.001)  Computes half the L2 norm of a tensor without the  sqrt :  output = sum(t ** 2) / 2 * wd", 
            "title": "L2"
        }, 
        {
            "location": "/losses/#l1", 
            "text": "tflearn.losses.L1   (tensor,  wd=0.001)  Computes the L1 norm of a tensor:  output = sum(|t|) * wd", 
            "title": "L1"
        }, 
        {
            "location": "/summaries/", 
            "text": "get_summary\n\n\ntflearn.summaries.get_summary\n  (stype,  tag,  value=None,  collection_key=None,  break_if_exists=False)\n\n\nCreate or retrieve a summary. It keep tracks of all graph summaries\nthrough summary_tags collection. If a summary tags already exists,\nit will return that summary tensor or raise an error (according to\n'break_if_exists').\n\n\nArguments\n\n\n\n\n\nstype\n: \nstr\n. Summary type: 'histogram', 'scalar' or 'image'.\n\n\ntag\n: \nstr\n. The summary tag (name).\n\n\nvalue\n: \nTensor\n. The summary initialization value. Default: None.\n\n\ncollection_key\n: \nstr\n. If specified, the created summary will be\nadded to that collection (optional).\n\n\nbreak_if_exists\n: \nbool\n. If True, if a summary with same tag already\nexists, it will raise an exception (instead of returning that\nexisting summary).\n\n\n\n\nReturns\n\n\n\nThe summary \nTensor\n.\n\n\n\n\nadd_activations_summary\n\n\ntflearn.summaries.add_activations_summary\n  (activation_ops,  name_prefix='',  name_suffix='',  collection_key=None)\n\n\nAdd histogram summary for given activations.\n\n\nArguments\n\n\n\n\n\nactivation_ops\n: A list of \nTensor\n. The activations to summarize.\n\n\nname_prefix\n: \nstr\n. A prefix to add to summary scope.\n\n\nname_suffix\n: \nstr\n. A suffix to add to summary scope.\n\n\ncollection_key\n: \nstr\n. A collection to store the summaries.\n\n\n\n\nReturns\n\n\n\nThe list of created activation summaries.\n\n\n\n\nadd_gradients_summary\n\n\ntflearn.summaries.add_gradients_summary\n  (grads,  name_prefix='',  name_suffix='',  collection_key=None)\n\n\nAdd histogram summary for given gradients.\n\n\nArguments\n\n\n\n\n\ngrads\n: A list of \nTensor\n. The gradients to summarize.\n\n\nname_prefix\n: \nstr\n. A prefix to add to summary scope.\n\n\nname_suffix\n: \nstr\n. A suffix to add to summary scope.\n\n\ncollection_key\n: \nstr\n. A collection to store the summaries.\n\n\n\n\nReturns\n\n\n\nThe list of created gradient summaries.\n\n\n\n\nadd_trainable_vars_summary\n\n\ntflearn.summaries.add_trainable_vars_summary\n  (variables,  name_prefix='',  name_suffix='',  collection_key=None)\n\n\nAdd histogram summary for given variables weights.\n\n\nArguments\n\n\n\n\n\nvariables\n: A list of \nVariable\n. The variables to summarize.\n\n\nname_prefix\n: \nstr\n. A prefix to add to summary scope.\n\n\nname_suffix\n: \nstr\n. A suffix to add to summary scope.\n\n\ncollection_key\n: \nstr\n. A collection to store the summaries.\n\n\n\n\nReturns\n\n\n\nThe list of created weights summaries.\n\n\n\n\nget_value_from_summary_string\n\n\ntflearn.summaries.get_value_from_summary_string\n  (tag,  summary_str)\n\n\nRetrieve a summary value from a summary string.\n\n\nArguments\n\n\n\n\n\ntag\n: \nstr\n. The summary tag (name).\n\n\nsummary_str\n: \nstr\n. The summary string to look in.\n\n\n\n\nReturns\n\n\n\nA \nfloat\n. The retrieved value.\n\n\n\n\nadd_loss_summaries\n\n\ntflearn.summaries.add_loss_summaries\n  (total_loss,  loss,  regul_losses_collection_key,  name_prefix='',  summaries_collection_key=None,  exp_moving_avg=0.9,  ema_num_updates=None)\n\n\nAdd scalar summaries (raw and averages) for given losses.\n\n\nGenerates moving average for all losses and associated summaries for\nvisualizing the performance of the network.\n\n\nArguments\n\n\n\n\n\ntotal_loss\n: \nTensor\n. The total loss (Regression loss +\nregularization losses).\n\n\nloss\n: \nTensor\n. Regression loss.\n\n\nname_prefix\n: \nstr\n. A prefix to add to the summary name.\n\n\nregul_losses_collection_key\n: \nstr\n. A collection name to retrieve\nregularization losses.\n\n\nexp_moving_avg\n: \nfloat\n. Exponential moving average.\n\n\nema_num_updates\n: \nint\n. Step to be used with exp moving avg.\n\n\n\n\nReturns\n\n\n\nloss_averages_op: op for generating moving averages of losses.\n\n\n\n\nsummary_exists\n\n\ntflearn.summaries.summary_exists\n  (tag)\n\n\nCheck if a summary exists.\n\n\nArguments\n\n\n\n\n\ntag\n: \nstr\n. The summary name.\n\n\n\n\nReturns\n\n\n\nA \nbool\n. Whether the summary exists or not.", 
            "title": "Summaries"
        }, 
        {
            "location": "/summaries/#get_summary", 
            "text": "tflearn.summaries.get_summary   (stype,  tag,  value=None,  collection_key=None,  break_if_exists=False)  Create or retrieve a summary. It keep tracks of all graph summaries\nthrough summary_tags collection. If a summary tags already exists,\nit will return that summary tensor or raise an error (according to\n'break_if_exists').", 
            "title": "get_summary"
        }, 
        {
            "location": "/summaries/#add_activations_summary", 
            "text": "tflearn.summaries.add_activations_summary   (activation_ops,  name_prefix='',  name_suffix='',  collection_key=None)  Add histogram summary for given activations.", 
            "title": "add_activations_summary"
        }, 
        {
            "location": "/summaries/#add_gradients_summary", 
            "text": "tflearn.summaries.add_gradients_summary   (grads,  name_prefix='',  name_suffix='',  collection_key=None)  Add histogram summary for given gradients.", 
            "title": "add_gradients_summary"
        }, 
        {
            "location": "/summaries/#add_trainable_vars_summary", 
            "text": "tflearn.summaries.add_trainable_vars_summary   (variables,  name_prefix='',  name_suffix='',  collection_key=None)  Add histogram summary for given variables weights.", 
            "title": "add_trainable_vars_summary"
        }, 
        {
            "location": "/summaries/#get_value_from_summary_string", 
            "text": "tflearn.summaries.get_value_from_summary_string   (tag,  summary_str)  Retrieve a summary value from a summary string.", 
            "title": "get_value_from_summary_string"
        }, 
        {
            "location": "/summaries/#add_loss_summaries", 
            "text": "tflearn.summaries.add_loss_summaries   (total_loss,  loss,  regul_losses_collection_key,  name_prefix='',  summaries_collection_key=None,  exp_moving_avg=0.9,  ema_num_updates=None)  Add scalar summaries (raw and averages) for given losses.  Generates moving average for all losses and associated summaries for\nvisualizing the performance of the network.", 
            "title": "add_loss_summaries"
        }, 
        {
            "location": "/summaries/#summary_exists", 
            "text": "tflearn.summaries.summary_exists   (tag)  Check if a summary exists.", 
            "title": "summary_exists"
        }, 
        {
            "location": "/variables/", 
            "text": "variable\n\n\ntflearn.variables.variable\n  (\nargs,  \n*kwargs)\n\n\nInstantiate a new variable.\n\n\nArguments\n\n\n\n\n\nname\n: \nstr\n. A name for this variable.\n\n\nshape\n: list of \nint\n. The variable shape (optional).\n\n\ndtype\n: \ntype\n. The variable data type.\n\n\ninitializer\n: \nstr\n or \nTensor\n. The variable initialization. (See\ntflearn.initializations for references).\n\n\nregularizer\n: \nstr\n or \nTensor\n. The variable regularizer. (See\ntflearn.losses for references).\n\n\ntrainable\n: \nbool\n. If True, this variable weights will be trained.\n\n\ncollections\n: \nstr\n. A collection to add the new variable to (optional).\n\n\ndevice\n: \nstr\n. Device ID to store the variable. Default: '/cpu:0'.\n\n\nrestore\n: \nbool\n. Restore or not this variable when loading a\npre-trained model (Only compatible with tflearn pre-built\ntraining functions).\n\n\n\n\nReturns\n\n\n\nA Variable.\n\n\n\n\nget_all_variables\n\n\ntflearn.variables.get_all_variables\n  ()\n\n\nGet all Graph variables.\n\n\nReturns\n\n\n\nA list of Variables.\n\n\n\n\nget_all_variables\n\n\ntflearn.variables.get_all_trainable_variable\n  ()\n\n\nGet all Graph trainable variables.\n\n\nReturns\n\n\n\nA list of Variables.\n\n\n\n\nget_layer_variables_by_name\n\n\ntflearn.variables.get_layer_variables_by_name\n  (name)\n\n\nRetrieve a layer's variables, given its name.\n\n\nArguments\n\n\n\n\n\nname\n: \nstr\n. The layer name.\n\n\n\n\nReturns\n\n\n\nA list of Variables.\n\n\n\n\nget_value\n\n\ntflearn.variables.get_value\n  (var,  session=None)\n\n\nGet a variable's value. If no session provided, use default one.\n\n\nArguments\n\n\n\n\n\nvar\n: \nVariable\n. The variable to get value from.\n\n\nsession\n: \nSession\n. The session to run the op. Default: the default\nsession.\n\n\n\n\nReturns\n\n\n\nThe variable's value.\n\n\n\n\nget_value\n\n\ntflearn.variables.set_value\n  (var,  value,  session=None)\n\n\nSet a variable's value. If no session provided, use default one.\n\n\nArguments\n\n\n\n\n\nvar\n: \nVariable\n. The variable to assign a value.\n\n\nvalue\n: The value to assign. Must be compatible with variable dtype.\n\n\nsession\n: \nSession\n. The session to perform the assignation.\nDefault: the default session.", 
            "title": "Variables"
        }, 
        {
            "location": "/variables/#variable", 
            "text": "tflearn.variables.variable   ( args,   *kwargs)  Instantiate a new variable.", 
            "title": "variable"
        }, 
        {
            "location": "/variables/#get_all_variables", 
            "text": "tflearn.variables.get_all_variables   ()  Get all Graph variables.", 
            "title": "get_all_variables"
        }, 
        {
            "location": "/variables/#get_all_variables_1", 
            "text": "tflearn.variables.get_all_trainable_variable   ()  Get all Graph trainable variables.", 
            "title": "get_all_variables"
        }, 
        {
            "location": "/variables/#get_layer_variables_by_name", 
            "text": "tflearn.variables.get_layer_variables_by_name   (name)  Retrieve a layer's variables, given its name.", 
            "title": "get_layer_variables_by_name"
        }, 
        {
            "location": "/variables/#get_value", 
            "text": "tflearn.variables.get_value   (var,  session=None)  Get a variable's value. If no session provided, use default one.", 
            "title": "get_value"
        }, 
        {
            "location": "/variables/#get_value_1", 
            "text": "tflearn.variables.set_value   (var,  value,  session=None)  Set a variable's value. If no session provided, use default one.", 
            "title": "get_value"
        }, 
        {
            "location": "/data_utils/", 
            "text": "Vocabulary Processor\n\n\ntflearn.data_utils.VocabularyProcessor\n  (max_document_length,  min_frequency=0,  vocabulary=None,  tokenizer_fn=None)\n\n\nMaps documents to sequences of word ids.\n\n\nArguments\n\n\n\n\n\nmax_document_length\n: Maximum length of documents.\nif documents are longer, they will be trimmed, if shorter - padded.\n\n\nmin_frequency\n: Minimum frequency of words in the vocabulary.\n\n\nvocabulary\n: CategoricalVocabulary object.\n\n\n\n\nAttributes\n\n\n\n\n\nvocabulary_\n: CategoricalVocabulary object.\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (raw_documents,  unused_y=None)\n\n\nLearn a vocabulary dictionary of all tokens in the raw documents.\n\n\nArguments\n\n\n\n\n\nraw_documents\n: An iterable which yield either str or unicode.\n\n\nunused_y\n: to match fit format signature of estimators.\n\n\n\n\nReturns\n\n\n\nself\n\n\n \n\n\nfit_transform\n  (raw_documents,  unused_y=None)\n\n\nLearn the vocabulary dictionary and return indexies of words.\n\n\nArguments\n\n\n\n\n\nraw_documents\n: An iterable which yield either str or unicode.\n\n\nunused_y\n: to match fit_transform signature of estimators.\n\n\n\n\nReturns\n\n\n\nX: iterable, [n_samples, max_document_length] Word-id matrix.\n\n\n \n\n\nrestore\n  (cls,  filename)\n\n\nRestores vocabulary processor from given file.\n\n\nArguments\n\n\n\n\n\nfilename\n: Path to file to load from.\n\n\n\n\nReturns\n\n\n\nVocabularyProcessor object.\n\n\n \n\n\nreverse\n  (documents)\n\n\nReverses output of vocabulary mapping to words.\n\n\nArguments\n\n\n\n\n\ndocuments\n: iterable, list of class ids.\n\n\n\n\nReturns\n\n\n\nIterator over mapped in words documents.\n\n\n \n\n\nsave\n  (filename)\n\n\nSaves vocabulary processor into given file.\n\n\nArguments\n\n\n\n\n\nfilename\n: Path to output file.\n\n\n\n\n \n\n\ntransform\n  (raw_documents)\n\n\nTransform documents to word-id matrix.\n\n\nConvert words to ids with vocabulary fitted with fit or the one\nprovided in the constructor.\n\n\nArguments\n\n\n\n\n\nraw_documents\n: An iterable which yield either str or unicode.\n\n\n\n\n\n\nto_categorical\n\n\ntflearn.data_utils.to_categorical\n  (y,  nb_classes)\n\n\nConvert class vector (integers from 0 to nb_classes)\nto binary class matrix, for use with categorical_crossentropy.\n\n\nArguments\n\n\n\n\n\ny\n: \narray\n. Class vector to convert.\n\n\nnb_classes\n: \nint\n. Total number of classes.\n\n\n\n\n\n\npad_sequences\n\n\ntflearn.data_utils.pad_sequences\n  (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0)\n\n\nPad each sequence to the same length: the length of the longest sequence.\nIf maxlen is provided, any sequence longer than maxlen is truncated to\nmaxlen. Truncation happens off either the beginning (default) or the\nend of the sequence. Supports post-padding and pre-padding (default).\n\n\nArguments\n\n\n\n\n\nsequences\n: list of lists where each element is a sequence.\n\n\nmaxlen\n: int, maximum length.\n\n\ndtype\n: type to cast the resulting sequence.\n\n\npadding\n: 'pre' or 'post', pad either before or after each sequence.\n\n\ntruncating\n: 'pre' or 'post', remove values from sequences larger than\nmaxlen either in the beginning or in the end of the sequence\n\n\nvalue\n: float, value to pad the sequences to the desired value.\n\n\n\n\nReturns\n\n\n\nx: \nnumpy array\n with dimensions (number_of_sequences, maxlen)\n\n\n\n\nstring_to_semi_redundant_sequences\n\n\ntflearn.data_utils.string_to_semi_redundant_sequences\n  (string,  seq_maxlen=25,  redun_step=3)\n\n\nVectorize a string and returns parsed sequences and targets, along with\nthe associated dictionary.\n\n\nArguments\n\n\n\n\n\nstring\n: \nstr\n. Lower-case text from input text file.\n\n\nseq_maxlen\n: \nint\n. Maximum length of a sequence. Default: 25.\n\n\nredun_step\n: \nint\n. Redundancy step. Default: 3.\n\n\n\n\nReturns\n\n\n\nA tuple: (inputs, targets, dictionary)\n\n\n\n\nBuild HDF5 Image Dataset\n\n\ntflearn.data_utils.build_hdf5_image_dataset\n  (target_path,  image_shape,  output_path='dataset.h5',  mode='file',  categorical_labels=True,  normalize=True,  grayscale=False,  files_extension=None,  chunks=True)\n\n\nBuild an HDF5 dataset by providing either a root folder or a plain text\nfile with images path and class id.\n\n\n'folder' mode: Root folder should be arranged as follow:\n\n\nROOT_FOLDER -\n SUBFOLDER_0 (CLASS 0) -\n CLASS0_IMG1.jpg -\n CLASS0_IMG2.jpg -\n ...-\n SUBFOLDER_1 (CLASS 1) -\n CLASS1_IMG1.jpg -\n ...-\n ...\n\n\n\n\nNote that if sub-folders are not integers from 0 to n_classes, an id will\nbe assigned to each sub-folder following alphabetical order.\n\n\n'file' mode: Plain text file should be formatted as follow:\n\n\n/path/to/img1 class_id\n/path/to/img2 class_id\n/path/to/img3 class_id\n\n\n\n\nExamples\n\n\n\n# Load path/class_id image file:\ndataset_file = 'my_dataset.txt'\n\n# Build a HDF5 dataset (only required once)\nfrom tflearn.data_utils import build_hdf5_image_dataset\nbuild_hdf5_image_dataset(dataset_file, image_shape=(128, 128), mode='file', output_path='dataset.h5', categorical_labels=True, normalize_img=True)\n\n# Load HDF5 dataset\nimport h5py\nh5f = h5py.File('dataset.h5', 'w')\nX = h5f['X']\nY = h5f['Y']\n\n# Build neural network and train\nnetwork = ...\nmodel = DNN(network, ...)\nmodel.fit(X, Y)\n\n\n\n\nArguments\n\n\n\n\n\ntarget_path\n: \nstr\n. Path of root folder or images plain text file.\n\n\nimage_shape\n: \ntuple (height, width)\n. The images shape. Images that\ndoesn't match that shape will be resized.\n\n\noutput_path\n: \nstr\n. The output path for the hdf5 dataset. Default:\n'dataset.h5'\n\n\nmode\n: \nstr\n in ['file', 'folder']. The data source mode. 'folder'\naccepts a root folder with each of his sub-folder representing a\nclass containing the images to classify.\n'file' accepts a single plain text file that contains every\nimage path with their class id.\nDefault: 'folder'.\n\n\ncategorical_labels\n: \nbool\n. If True, labels are converted to binary\nvectors.\n\n\nnormalize\n: \nbool\n. If True, normalize all pictures by dividing\nevery image array by 255.\n\n\ngrayscale\n: \nbool\n. If true, images are converted to grayscale.\n\n\nfiles_extension\n: \nlist of str\n. A list of allowed image file\nextension, for example ['.jpg', '.jpeg', '.png']. If None,\nall files are allowed.\n\n\nchunks\n: \nbool\n or \nlist of int\n. Whether to chunks the dataset or not.\nAdditionaly, a specific shape for each chunk can be provided.\n\n\n\n\n\n\nImage PreLoader\n\n\ntflearn.data_utils.image_preloader\n  (target_path,  image_shape,  mode='file',  normalize=True,  grayscale=False,  categorical_labels=True,  files_extension=None)\n\n\nCreate a python array (\nPreloader\n) that loads images on the fly (from\ndisk or url). There is two ways to provide image samples 'folder' or\n'file', see the specifications below.\n\n\n'folder' mode: Load images from disk, given a root folder. This folder\nshould be arranged as follow:\n\n\nROOT_FOLDER -\n SUBFOLDER_0 (CLASS 0) -\n CLASS0_IMG1.jpg -\n CLASS0_IMG2.jpg -\n ...-\n SUBFOLDER_1 (CLASS 1) -\n CLASS1_IMG1.jpg -\n ...-\n ...\n\n\n\n\nNote that if sub-folders are not integers from 0 to n_classes, an id will\nbe assigned to each sub-folder following alphabetical order.\n\n\n'file' mode: A plain text file listing every image path and class id.\nThis file should be formatted as follow:\n\n\n/path/to/img1 class_id\n/path/to/img2 class_id\n/path/to/img3 class_id\n\n\n\n\nNote that load images on the fly and convert is time inefficient,\nso you can instead use \nbuild_hdf5_image_dataset\n to build a HDF5 dataset\nthat enable fast retrieval (this function takes similar arguments).\n\n\nExamples\n\n\n\n# Load path/class_id image file:\ndataset_file = 'my_dataset.txt'\n\n# Build the preloader array, resize images to 128x128\nfrom tflearn.data_utils import image_preloader\nX, Y = image_preloader(dataset_file, image_shape=(128, 128),   mode='file', categorical_labels=True,   normalize=True)\n\n# Build neural network and train\nnetwork = ...\nmodel = DNN(network, ...)\nmodel.fit(X, Y)\n\n\n\n\nArguments\n\n\n\n\n\ntarget_path\n: \nstr\n. Path of root folder or images plain text file.\n\n\nimage_shape\n: \ntuple (height, width)\n. The images shape. Images that\ndoesn't match that shape will be resized.\n\n\nmode\n: \nstr\n in ['file', 'folder']. The data source mode. 'folder'\naccepts a root folder with each of his sub-folder representing a\nclass containing the images to classify.\n'file' accepts a single plain text file that contains every\nimage path with their class id.\nDefault: 'folder'.\n\n\ncategorical_labels\n: \nbool\n. If True, labels are converted to binary\nvectors.\n\n\nnormalize\n: \nbool\n. If True, normalize all pictures by dividing\nevery image array by 255.\n\n\ngrayscale\n: \nbool\n. If true, images are converted to grayscale.\n\n\nfiles_extension\n: \nlist of str\n. A list of allowed image file\nextension, for example ['.jpg', '.jpeg', '.png']. If None,\nall files are allowed.\n\n\n\n\nReturns\n\n\n\n(X, Y): with X the images array and Y the labels array.\n\n\n\n\nshuffle\n\n\ntflearn.data_utils.shuffle\n  (*arrs)\n\n\nShuffle given arrays at unison, along first axis.\n\n\nArguments\n\n\n\n\n\n*arrs: Each array to shuffle at unison.\n\n\n\n\nReturns\n\n\n\nTuple of shuffled arrays.\n\n\n\n\nsamplewise_zero_center\n\n\ntflearn.data_utils.samplewise_zero_center\n  (X)\n\n\nZero center each sample by subtracting it by its mean.\n\n\nArguments\n\n\n\n\n\nX\n: \narray\n. The batch of samples to center.\n\n\n\n\nReturns\n\n\n\nA numpy array with same shape as input.\n\n\n\n\nsamplewise_std_normalization\n\n\ntflearn.data_utils.samplewise_std_normalization\n  (X)\n\n\nScale each sample with its standard deviation.\n\n\nArguments\n\n\n\n\n\nX\n: \narray\n. The batch of samples to scale.\n\n\n\n\nReturns\n\n\n\nA numpy array with same shape as input.\n\n\n\n\nfeaturewise_zero_center\n\n\ntflearn.data_utils.featurewise_zero_center\n  (X,  mean=None)\n\n\nZero center every sample with specified mean. If not specified, the mean\nis evaluated over all samples.\n\n\nArguments\n\n\n\n\n\nX\n: \narray\n. The batch of samples to center.\n\n\nmean\n: \nfloat\n. The mean to use for zero centering. If not specified, it\nwill be evaluated on provided data.\n\n\n\n\nReturns\n\n\n\nA numpy array with same shape as input. Or a tuple (array, mean) if no\nmean value was specified.\n\n\n\n\nfeaturewise_std_normalization\n\n\ntflearn.data_utils.featurewise_std_normalization\n  (X,  std=None)\n\n\nScale each sample by the specified standard deviation. If no std\nspecified, std is evaluated over all samples data.\n\n\nArguments\n\n\n\n\n\nX\n: \narray\n. The batch of samples to scale.\n\n\nstd\n: \nfloat\n. The std to use for scaling data. If not specified, it\nwill be evaluated over the provided data.\n\n\n\n\nReturns\n\n\n\nA numpy array with same shape as input. Or a tuple (array, std) if no\nstd value was specified.", 
            "title": "Data Utils"
        }, 
        {
            "location": "/data_utils/#vocabulary-processor", 
            "text": "tflearn.data_utils.VocabularyProcessor   (max_document_length,  min_frequency=0,  vocabulary=None,  tokenizer_fn=None)  Maps documents to sequences of word ids.", 
            "title": "Vocabulary Processor"
        }, 
        {
            "location": "/data_utils/#to_categorical", 
            "text": "tflearn.data_utils.to_categorical   (y,  nb_classes)  Convert class vector (integers from 0 to nb_classes)\nto binary class matrix, for use with categorical_crossentropy.", 
            "title": "to_categorical"
        }, 
        {
            "location": "/data_utils/#pad_sequences", 
            "text": "tflearn.data_utils.pad_sequences   (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0)  Pad each sequence to the same length: the length of the longest sequence.\nIf maxlen is provided, any sequence longer than maxlen is truncated to\nmaxlen. Truncation happens off either the beginning (default) or the\nend of the sequence. Supports post-padding and pre-padding (default).", 
            "title": "pad_sequences"
        }, 
        {
            "location": "/data_utils/#string_to_semi_redundant_sequences", 
            "text": "tflearn.data_utils.string_to_semi_redundant_sequences   (string,  seq_maxlen=25,  redun_step=3)  Vectorize a string and returns parsed sequences and targets, along with\nthe associated dictionary.", 
            "title": "string_to_semi_redundant_sequences"
        }, 
        {
            "location": "/data_utils/#build-hdf5-image-dataset", 
            "text": "tflearn.data_utils.build_hdf5_image_dataset   (target_path,  image_shape,  output_path='dataset.h5',  mode='file',  categorical_labels=True,  normalize=True,  grayscale=False,  files_extension=None,  chunks=True)  Build an HDF5 dataset by providing either a root folder or a plain text\nfile with images path and class id.  'folder' mode: Root folder should be arranged as follow:  ROOT_FOLDER -  SUBFOLDER_0 (CLASS 0) -  CLASS0_IMG1.jpg -  CLASS0_IMG2.jpg -  ...-  SUBFOLDER_1 (CLASS 1) -  CLASS1_IMG1.jpg -  ...-  ...  Note that if sub-folders are not integers from 0 to n_classes, an id will\nbe assigned to each sub-folder following alphabetical order.  'file' mode: Plain text file should be formatted as follow:  /path/to/img1 class_id\n/path/to/img2 class_id\n/path/to/img3 class_id", 
            "title": "Build HDF5 Image Dataset"
        }, 
        {
            "location": "/data_utils/#image-preloader", 
            "text": "tflearn.data_utils.image_preloader   (target_path,  image_shape,  mode='file',  normalize=True,  grayscale=False,  categorical_labels=True,  files_extension=None)  Create a python array ( Preloader ) that loads images on the fly (from\ndisk or url). There is two ways to provide image samples 'folder' or\n'file', see the specifications below.  'folder' mode: Load images from disk, given a root folder. This folder\nshould be arranged as follow:  ROOT_FOLDER -  SUBFOLDER_0 (CLASS 0) -  CLASS0_IMG1.jpg -  CLASS0_IMG2.jpg -  ...-  SUBFOLDER_1 (CLASS 1) -  CLASS1_IMG1.jpg -  ...-  ...  Note that if sub-folders are not integers from 0 to n_classes, an id will\nbe assigned to each sub-folder following alphabetical order.  'file' mode: A plain text file listing every image path and class id.\nThis file should be formatted as follow:  /path/to/img1 class_id\n/path/to/img2 class_id\n/path/to/img3 class_id  Note that load images on the fly and convert is time inefficient,\nso you can instead use  build_hdf5_image_dataset  to build a HDF5 dataset\nthat enable fast retrieval (this function takes similar arguments).", 
            "title": "Image PreLoader"
        }, 
        {
            "location": "/data_utils/#shuffle", 
            "text": "tflearn.data_utils.shuffle   (*arrs)  Shuffle given arrays at unison, along first axis.", 
            "title": "shuffle"
        }, 
        {
            "location": "/data_utils/#samplewise_zero_center", 
            "text": "tflearn.data_utils.samplewise_zero_center   (X)  Zero center each sample by subtracting it by its mean.", 
            "title": "samplewise_zero_center"
        }, 
        {
            "location": "/data_utils/#samplewise_std_normalization", 
            "text": "tflearn.data_utils.samplewise_std_normalization   (X)  Scale each sample with its standard deviation.", 
            "title": "samplewise_std_normalization"
        }, 
        {
            "location": "/data_utils/#featurewise_zero_center", 
            "text": "tflearn.data_utils.featurewise_zero_center   (X,  mean=None)  Zero center every sample with specified mean. If not specified, the mean\nis evaluated over all samples.", 
            "title": "featurewise_zero_center"
        }, 
        {
            "location": "/data_utils/#featurewise_std_normalization", 
            "text": "tflearn.data_utils.featurewise_std_normalization   (X,  std=None)  Scale each sample by the specified standard deviation. If no std\nspecified, std is evaluated over all samples data.", 
            "title": "featurewise_std_normalization"
        }, 
        {
            "location": "/data_preprocessing/", 
            "text": "Data Preprocessing\n\n\ntflearn.data_preprocessing.DataPreprocessing\n  (name='DataPreprocessing')\n\n\nBase class for applying common real-time data preprocessing.\n\n\nThis class is meant to be used as an argument of \ninput_data\n. When training\na model, the defined pre-processing methods will be applied at both\ntraining and testing time. Note that DataAugmentation is similar to\nDataPreprocessing, but only applies at training time.\n\n\nArguments\n\n\n\n\n\nNone.\n\n\n\n\nMethods\n\n\n\n \n\n\nadd_featurewise_stdnorm\n  (std=None)\n\n\nScale each sample by the specified standard deviation. If no std\nspecified, std is evaluated over all samples data.\n\n\nArguments\n\n\n\n\n\nstd\n: \nfloat\n (optional). Provides a custom standard derivation.\nIf none provided, it will be automatically caluclated based on\nthe training dataset. Default: None.\n\n\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_featurewise_zero_center\n  (mean=None)\n\n\nZero center every sample with specified mean. If not specified,\nthe mean is evaluated over all samples.\n\n\nArguments\n\n\n\n\n\nmean\n: \nfloat\n (optional). Provides a custom mean. If none\nprovided, it will be automatically caluclated based on\nthe training dataset. Default: None.\n\n\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_samplewise_stdnorm\n  (self)\n\n\nScale each sample with its standard deviation.\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_samplewise_zero_center\n  (self)\n\n\nZero center each sample by subtracting it by its mean.\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_zca_whitening\n  (pc=None)\n\n\nApply ZCA Whitening to data.\n\n\nArguments\n\n\n\n\n\npc\n: \narray\n (optional). Use the provided pre-computed principal\ncomponent instead of computing it.\n\n\n\n\nReturns\n\n\n\nNothing.", 
            "title": "Data Preprocessing"
        }, 
        {
            "location": "/data_preprocessing/#data-preprocessing", 
            "text": "tflearn.data_preprocessing.DataPreprocessing   (name='DataPreprocessing')  Base class for applying common real-time data preprocessing.  This class is meant to be used as an argument of  input_data . When training\na model, the defined pre-processing methods will be applied at both\ntraining and testing time. Note that DataAugmentation is similar to\nDataPreprocessing, but only applies at training time.", 
            "title": "Data Preprocessing"
        }, 
        {
            "location": "/data_augmentation/", 
            "text": "Data Augmentation\n\n\ntflearn.data_augmentation.DataAugmentation\n  (self)\n\n\nBase class for applying common real-time data augmentation.\n\n\nThis class is meant to be used as an argument of \ninput_data\n. When training\na model, the defined augmentation methods will be applied at training\ntime only. Note that DataPreprocessing is similar to DataAugmentation,\nbut applies at both training time and testing time.\n\n\nArguments\n\n\n\n\n\nNone\n\n\n\n\n\n\nImage Augmentation\n\n\ntflearn.data_augmentation.ImageAugmentation\n  (self)\n\n\nBase class for applying real-time augmentation related to images.\n\n\nThis class is meant to be used as an argument of \ninput_data\n. When training\na model, the defined augmentation methods will be applied at training\ntime only. Note that ImagePreprocessing is similar to ImageAugmentation,\nbut applies at both training time and testing time.\n\n\nArguments\n\n\n\n\n\nNone.\n\n\n\n\nMethods\n\n\n\n \n\n\nadd_random_blur\n  (sigma_max=5.0)\n\n\nRandomly blur an image by applying a gaussian filter with a random\nsigma (0., sigma_max).\n\n\nArguments\n\n\n\n\n\nsigma\n: \nfloat\n or list of \nfloat\n. Standard deviation for Gaussian\nkernel. The standard deviations of the Gaussian filter are\ngiven for each axis as a sequence, or as a single number,\nin which case it is equal for all axes.\n\n\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_random_crop\n  (crop_shape,  padding=None)\n\n\nRandomly crop a picture according to 'crop_shape'. An optional padding\ncan be specified, for padding picture with 0s (To conserve original\nimage shape).\n\n\nExamples\n\n\n\n# Example: pictures of 32x32\nimgaug = tflearn.ImageAugmentation()\n# Random crop of 24x24 into a 32x32 picture =\n output 24x24\nimgaug.add_random_crop((24, 24))\n# Random crop of 32x32 with image padding of 6 (to conserve original image shape) =\n output 32x32\nimgaug.add_random_crop((32, 32), 6)\n\n\n\n\nArguments\n\n\n\n\n\ncrop_shape\n: \ntuple\n of \nint\n. The crop shape (height, width).\n\n\npadding\n: \nint\n. If not None, the image is padded with 'padding' 0s.\n\n\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_random_flip_leftright\n  (self)\n\n\nRandomly flip an image (left to right).\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_random_flip_updown\n  (self)\n\n\nRandomly flip an image (upside down).\n\n\nReturns\n\n\n\nNothing.\n\n\n \n\n\nadd_random_rotation\n  (max_angle=20.0)\n\n\nRandomly rotate an image by a random angle (-max_angle, max_angle).\n\n\nArguments\n\n\n\n\n\nmax_angle\n: \nfloat\n. The maximum rotation angle.\n\n\n\n\nReturns\n\n\n\nNothing.", 
            "title": "Data Augmentation"
        }, 
        {
            "location": "/data_augmentation/#data-augmentation", 
            "text": "tflearn.data_augmentation.DataAugmentation   (self)  Base class for applying common real-time data augmentation.  This class is meant to be used as an argument of  input_data . When training\na model, the defined augmentation methods will be applied at training\ntime only. Note that DataPreprocessing is similar to DataAugmentation,\nbut applies at both training time and testing time.", 
            "title": "Data Augmentation"
        }, 
        {
            "location": "/data_augmentation/#image-augmentation", 
            "text": "tflearn.data_augmentation.ImageAugmentation   (self)  Base class for applying real-time augmentation related to images.  This class is meant to be used as an argument of  input_data . When training\na model, the defined augmentation methods will be applied at training\ntime only. Note that ImagePreprocessing is similar to ImageAugmentation,\nbut applies at both training time and testing time.", 
            "title": "Image Augmentation"
        }, 
        {
            "location": "/data_flow/", 
            "text": "Data Flow\n\n\ntflearn.data_flow.DataFlow\n  (coord,  num_threads=8,  max_queue=32,  shuffle=False,  continuous=False,  ensure_data_order=False,  dprep_dict=None,  daug_dict=None)\n\n\nBase class for using real time pre-processing and controlling data flow.\nSupports pipelining for faster computation.\n\n\nArguments\n\n\n\n\n\ncoord\n: \nCoordinator\n. A Tensorflow coordinator.\n\n\nnum_threads\n: \nint\n. Total number of simultaneous threads to process data.\n\n\nmax_queue\n: \nint\n. Maximum number of data stored in a queue.\n\n\nshuffle\n: \nbool\n. If True, data will be shuffle.\n\n\ncontinuous\n: \nbool\n. If True, when an epoch is over, same data will be\nfeeded again.\n\n\nensure_data_order\n: \nbool\n. Ensure that data order is keeped when using\n'next' to retrieve data (Processing will be slower).\n\n\ndprep_dict\n: dict. Optional data pre-processing parameter for performing\nreal time data pre-processing. Keys must be placeholders and values\n\nDataPreprocessing\n subclass object.\n\n\ndaug_dict\n: dict. Optional data augmentation parameter for performing\nreal time data augmentation. Keys must be placeholders and values\n\nDataAugmentation\n subclass object.\n\n\n\n\n\n\nFeedDictFlow\n\n\ntflearn.data_flow.FeedDictFlow\n  (feed_dict,  coord,  batch_size=128,  num_threads=8,  max_queue=32,  shuffle=False,  continuous=False,  ensure_data_order=False,  dprep_dict=None,  daug_dict=None,  index_array=None)\n\n\nGenerate a stream of batches from a dataset. It uses two queues, one for\ngenerating batch of data ids, and the other one to load data and apply pre\nprocessing. If continuous is \nTrue\n, data flow will never ends until \nstop\n\nis invoked, or \ncoord\n interrupt threads.\n\n\nArguments\n\n\n\n\n\nfeed_dict\n: \ndict\n. A TensorFlow formatted feed dict (with placeholders\nas keys and data as values).\n\n\ncoord\n: \nCoordinator\n. A Tensorflow coordinator.\n\n\nnum_threads\n: \nint\n. Total number of simultaneous threads to process data.\n\n\nmax_queue\n: \nint\n. Maximum number of data stored in a queue.\n\n\nshuffle\n: \nbool\n. If True, data will be shuffle.\n\n\ncontinuous\n: \nbool\n. If True, when an epoch is over, same data will be\nfeeded again.\n\n\nensure_data_order\n: \nbool\n. Ensure that data order is keeped when using\n'next' to retrieve data (Processing will be slower).\n\n\ndprep_dict\n: dict. Optional data pre-processing parameter for performing\nreal time data pre-processing. Keys must be placeholders and values\n\nDataPreprocessing\n subclass object.\n\n\ndaug_dict\n: dict. Optional data augmentation parameter for performing\nreal time data augmentation. Keys must be placeholders and values\n\nDataAugmentation\n subclass object.\n\n\nindex_array\n: \nlist\n. An optional list of index to be used instead of\nusing the whole dataset indexes (Useful for validation split).\n\n\n\n\nMethods\n\n\n\n \n\n\nnext\n  (timeout=None)\n\n\nGet the next feed dict.\n\n\nReturns\n\n\n\nA TensorFlow feed dict, or 'False' if it has no more data.\n\n\n \n\n\nstart\n  (reset_status=True)\n\n\nArguments\n\n\n\n\n\nreset_status\n: \nbool\n. If True, \nDataStatus\n will be reset.\n\n\n\n\nReturns", 
            "title": "Data Flow"
        }, 
        {
            "location": "/data_flow/#data-flow", 
            "text": "tflearn.data_flow.DataFlow   (coord,  num_threads=8,  max_queue=32,  shuffle=False,  continuous=False,  ensure_data_order=False,  dprep_dict=None,  daug_dict=None)  Base class for using real time pre-processing and controlling data flow.\nSupports pipelining for faster computation.", 
            "title": "Data Flow"
        }, 
        {
            "location": "/data_flow/#feeddictflow", 
            "text": "tflearn.data_flow.FeedDictFlow   (feed_dict,  coord,  batch_size=128,  num_threads=8,  max_queue=32,  shuffle=False,  continuous=False,  ensure_data_order=False,  dprep_dict=None,  daug_dict=None,  index_array=None)  Generate a stream of batches from a dataset. It uses two queues, one for\ngenerating batch of data ids, and the other one to load data and apply pre\nprocessing. If continuous is  True , data flow will never ends until  stop \nis invoked, or  coord  interrupt threads.", 
            "title": "FeedDictFlow"
        }, 
        {
            "location": "/config/", 
            "text": "init_graph\n\n\ntflearn.config.init_graph\n  (seed=None,  log_device=False,  num_cores=0,  gpu_memory_fraction=0,  soft_placement=True)\n\n\nInitialize a graph with specific parameters.\n\n\nArguments\n\n\n\n\n\nseed\n: \nint\n. Set the graph random seed.\n\n\nlog_device\n: \nbool\n. Log device placement or not.\n\n\nnum_cores\n: Number of CPU cores to be used. Default: All.\n\n\ngpu_memory_fraction\n: A value between 0 and 1 that indicates what\nfraction of the available GPU memory to pre-allocate for each\nprocess. 1 means to pre-allocate all of the GPU memory,\n0.5 means the process allocates ~50% of the available GPU\nmemory. Default: Use all GPU's available memory.\n\n\nsoft_placement\n: \nbool\n. Whether soft placement is allowed. If true,\nan op will be placed on CPU if:1. there's no GPU implementation for the OP - or2. no GPU devices are known or registered - or3. need to co-locate with reftype input(s) which are from CPU.\n\n\n\n\n\n\nis_training\n\n\ntflearn.config.is_training\n  (is_training=False,  session=None)\n\n\nSet the graph training mode.\n\n\nThis is meant to be used to control ops that have different output at\ntraining and testing time., such as dropout or batch normalization,\n\n\nExamples\n\n\n\n # Retrieve variable responsible for managing training mode\n\n training_mode = tflearn.get_training_mode()\n\n # Define a conditional op\n\n my_conditional_op = tf.cond(training_mode, if_yes_op, if_no_op)\n\n # Set training mode to True\n\n tflearn.is_training(True)\n\n session.run(my_conditional_op)\nif_yes_op\n\n # Set training mode to False\n\n tflearn.is_training(False)\n\n session.run(my_conditional_op)\nif_no_op\n\n\n\n\nReturns\n\n\n\nA \nbool\n, True if training, False else.\n\n\n\n\nget_training_mode\n\n\ntflearn.config.get_training_mode\n  ()\n\n\nReturns variable in-use to set training mode.\n\n\nReturns\n\n\n\nA \nVariable\n, the training mode holder.", 
            "title": "Graph Config"
        }, 
        {
            "location": "/config/#init_graph", 
            "text": "tflearn.config.init_graph   (seed=None,  log_device=False,  num_cores=0,  gpu_memory_fraction=0,  soft_placement=True)  Initialize a graph with specific parameters.", 
            "title": "init_graph"
        }, 
        {
            "location": "/config/#is_training", 
            "text": "tflearn.config.is_training   (is_training=False,  session=None)  Set the graph training mode.  This is meant to be used to control ops that have different output at\ntraining and testing time., such as dropout or batch normalization,", 
            "title": "is_training"
        }, 
        {
            "location": "/config/#get_training_mode", 
            "text": "tflearn.config.get_training_mode   ()  Returns variable in-use to set training mode.", 
            "title": "get_training_mode"
        }, 
        {
            "location": "/helpers/trainer/", 
            "text": "Trainer\n\n\ntflearn.helpers.trainer.Trainer\n  (train_ops,  graph=None,  clip_gradients=5.0,  tensorboard_dir='/tmp/tflearn_logs/',  tensorboard_verbose=0,  checkpoint_path=None,  max_checkpoints=None,  keep_checkpoint_every_n_hours=10000.0,  random_seed=None,  session=None)\n\n\nGeneric class to handle any TensorFlow graph training. It requires\nthe use of \nTrainOp\n to specify all optimization parameters.\n\n\nArguments\n\n\n\n\n\ntrain_ops\n: list of \nTrainOp\n. A list of a network training\noperations for performing optimizations.\n\n\ngraph\n: \ntf.Graph\n. The TensorFlow graph to use. Default: default tf\ngraph.\n\n\nclip_gradients\n: \nfloat\n. Clip gradient. Default: 5.0.\n\n\ntensorboard_dir\n: \nstr\n. Tensorboard log directory.\nDefault: \"/tmp/tflearn_logs/\".\n\n\ntensorboard_verbose\n: \nint\n. Verbose level. It supports:\n\n\n\n\n0 - Loss, Accuracy. (Best Speed)\n1 - Loss, Accuracy, Gradients.\n2 - Loss, Accuracy, Gradients, Weights.\n3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity.(Best Visualization)\n\n\n\n\n\n\ncheckpoint_path\n: \nstr\n. Path to store model checkpoints. If None,\nno model checkpoint will be saved. Default: None.\n\n\nmax_checkpoints\n: \nint\n or None. Maximum amount of checkpoints. If\nNone, no limit. Default: None.\n\n\nkeep_checkpoint_every_n_hours\n: \nfloat\n. Number of hours between each\nmodel checkpoints.\n\n\nrandom_seed\n: \nint\n. Random seed, for test reproductivity.\nDefault: None.\n\n\nsession\n: \nSession\n. A session for running ops. If None, a new one will\nbe created. Note: When providing a session, variables must have been\ninitialized already, otherwise an error will be raised.\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (feed_dicts,  n_epoch=10,  val_feed_dicts=None,  show_metric=False,  snapshot_step=None,  snapshot_epoch=True,  shuffle_all=None,  dprep_dict=None,  daug_dict=None,  excl_trainops=None,  run_id=None)\n\n\nTrain network with feeded data dicts.\n\n\nExamples\n\n\n\n# 1 Optimizer\ntrainer.fit(feed_dicts={input1: X, output1: Y},val_feed_dicts={input1: X, output1: Y})\ntrainer.fit(feed_dicts={input1: X1, input2: X2, output1: Y},val_feed_dicts=0.1) # 10% of data used for validation\n\n# 2 Optimizers\ntrainer.fit(feed_dicts=[{in1: X1, out1:Y}, {in2: X2, out2:Y2}],val_feed_dicts=[{in1: X1, out1:Y}, {in2: X2, out2:Y2}])\n\n\n\n\nArguments\n\n\n\n\n\nfeed_dicts\n: \ndict\n or list of \ndict\n. The dictionary to feed\ndata to the network. It follows Tensorflow feed dict\nspecifications: '{placeholder: data}'. In case of multiple\noptimizers, a list of dict is expected, that will\nrespectively feed optimizers.\n\n\nn_epoch\n: \nint\n. Number of epoch to runs.\n\n\nval_feed_dicts\n: \ndict\n, list of \ndict\n, \nfloat\n or list of\n\nfloat\n. The data used for validation. Feed dict are\nfollowing the same specification as \nfeed_dicts\n above. It\nis also possible to provide a \nfloat\n for splitting training\ndata for validation (Note that this will shuffle data).\n\n\nshow_metric\n: \nbool\n. If True, accuracy will be calculated and\ndisplayed at every step. Might give slower training.\n\n\nsnapshot_step\n: \nint\n. If not None, the network will be snapshot\nevery provided step (calculate validation loss/accuracy and\nsave model, if a \ncheckpoint_path\n is specified in \nTrainer\n).\n\n\nsnapshot_epoch\n: \nbool\n. If True, snapshot the network at the end\nof every epoch.\n\n\nshuffle_all\n: \nbool\n. If True, shuffle all data batches (overrides\n\nTrainOp\n shuffle parameter behavior).\n\n\ndprep_dict\n: \ndict\n with \nPlaceholder\n as key and\n\nDataPreprocessing\n as value. Apply realtime data\npreprocessing to the given placeholders (Applied at training\nand testing time).\n\n\ndaug_dict\n: \ndict\n with \nPlaceholder\n as key and\n\nDataAugmentation\n as value. Apply realtime data\naugmentation to the given placeholders (Only applied at\ntraining time).\n\n\nexcl_trainops\n: \nlist\n of \nTrainOp\n. A list of train ops to\nexclude from training process.\n\n\nrun_id\n: \nstr\n. A name for the current run. Used for Tensorboard\ndisplay. If no name provided, a random one will be generated.\n\n\n\n\n \n\n\nrestore\n  (model_file,  trainable_variable_only=False)\n\n\nRestore a Tensorflow model\n\n\nArguments\n\n\n\n\n\nmodel_file\n: path of tensorflow model to restore\n\n\ntrainable_variable_only\n: If True, only restore trainable variables.\n\n\n\n\n \n\n\nsave\n  (model_file,  global_step=None)\n\n\nSave a Tensorflow model\n\n\nArguments\n\n\n\n\n\nmodel_file\n: \nstr\n. Saving path of tensorflow model\n\n\nglobal_step\n: \nfloat\n. The training step to append to the\nmodel file name (optional).\n\n\n\n\n\n\nTrainOp\n\n\ntflearn.helpers.trainer.TrainOp\n  (loss,  optimizer,  metric=None,  batch_size=64,  ema=0.0,  trainable_vars=None,  shuffle=True,  step_tensor=None,  name=None,  graph=None)\n\n\nTrainOp represents a set of operation used for optimizing a network.\n\n\nA TrainOp is meant to hold all training parameters of an optimizer.\n\nTrainer\n class will then instantiate them all specifically considering all\noptimizers of the network (set names, scopes... set optimization ops...).\n\n\nArguments\n\n\n\n\n\nloss\n: \nTensor\n. Loss operation to evaluate network cost.\nOptimizer will use this cost function to train network.\n\n\noptimizer\n: \nOptimizer\n. Tensorflow Optimizer. The optimizer to\nuse to train network.\n\n\nmetric\n:  \nTensor\n. The metric tensor to be used for evaluation.\n\n\nbatch_size\n: \nint\n. Batch size for data feeded to this optimizer.\nDefault: 64.\n\n\nema\n: \nfloat\n. Exponential moving averages.\n\n\ntrainable_vars\n: list of \ntf.Variable\n. List of trainable variables to\nuse for training. Default: all trainable variables.\n\n\nshuffle\n: \nbool\n. Shuffle data.\n\n\nstep_tensor\n: \ntf.Tensor\n. A variable holding training step. If not\nprovided, it will be created. Early defining the step tensor\nmight be useful for network creation, such as for learning rate\ndecay.\n\n\ninput_vars\n: list of \nVariable\n. The input data for this training op\nto be transformed by data augmentation. Default:\ntf.GraphKeys.INPUTS collection. (optional) Only necessary when\nusing data augmentation.\n\n\ndata_preprocessing\n: A \nDataPreprocessing\n subclass object to manage\nreal-time data pre-processing when training and predicting (such\nas zero center data, std normalization...).\n\n\ndata_augmentation\n: \nDataAugmentation\n. A \nDataAugmentation\n subclass\nobject to manage real-time data augmentation while training (\nsuch as random image crop, random image flip, random sequence\nreverse...).\n\n\nname\n: \nstr\n. A name for this class (optional).\n\n\ngraph\n: \ntf.Graph\n. Tensorflow Graph to use for training. Default:\ndefault tf graph.\n\n\n\n\nMethods\n\n\n\n \n\n\ninitialize_fit\n  (feed_dict,  val_feed_dict,  dprep_dict,  daug_dict,  show_metric,  summ_writer,  coord)\n\n\nInitialize data for feeding the training process. It is meant to\nbe used by \nTrainer\n before starting to fit data.\n\n\nArguments\n\n\n\n\n\nfeed_dict\n: \ndict\n. The data dictionary to feed.\n\n\nval_feed_dict\n: \ndict\n or \nfloat\n. The validation data dictionary to\nfeed or validation split.\n\n\ndprep_dict\n: \ndict\n. Data Preprocessing dict (with placeholder as\nkey and corresponding \nDataPreprocessing\n object as value).\n\n\ndaug_dict\n: \ndict\n. Data Augmentation dict (with placeholder as\nkey and corresponding \nDataAugmentation\n object as value).\n\n\nshow_metric\n: \nbool\n. If True, display accuracy at every step.\n\n\nsumm_writer\n: \nSummaryWriter\n. The summary writer to use for\nTensorboard logging.\n\n\n\n\n \n\n\ninitialize_training_ops\n  (i,  session,  tensorboard_verbose,  clip_gradients)\n\n\nInitialize all ops used for training. Because a network can have\nmultiple optimizers, an id 'i' is allocated to differentiate them.\nThis is meant to be used by \nTrainer\n when initializing all train ops.\n\n\nArguments\n\n\n\n\n\ni\n: \nint\n. This optimizer training process ID.\n\n\nsession\n: \ntf.Session\n. The session used to train the network.\n\n\ntensorboard_verbose\n: \nint\n. Logs verbose. Supports:\n\n\n\n\n0 - Loss, Accuracy.\n1 - Loss, Accuracy, Gradients.\n2 - Loss, Accuracy, Gradients, Weights.\n3 - Loss, Accuracy, Gradients, Weights, Activations, Sparsity..\n\n\n\n\n\n\nclip_gradients\n: \nfloat\n. Option for clipping gradients.", 
            "title": "Trainer"
        }, 
        {
            "location": "/helpers/trainer/#trainer", 
            "text": "tflearn.helpers.trainer.Trainer   (train_ops,  graph=None,  clip_gradients=5.0,  tensorboard_dir='/tmp/tflearn_logs/',  tensorboard_verbose=0,  checkpoint_path=None,  max_checkpoints=None,  keep_checkpoint_every_n_hours=10000.0,  random_seed=None,  session=None)  Generic class to handle any TensorFlow graph training. It requires\nthe use of  TrainOp  to specify all optimization parameters.", 
            "title": "Trainer"
        }, 
        {
            "location": "/helpers/trainer/#trainop", 
            "text": "tflearn.helpers.trainer.TrainOp   (loss,  optimizer,  metric=None,  batch_size=64,  ema=0.0,  trainable_vars=None,  shuffle=True,  step_tensor=None,  name=None,  graph=None)  TrainOp represents a set of operation used for optimizing a network.  A TrainOp is meant to hold all training parameters of an optimizer. Trainer  class will then instantiate them all specifically considering all\noptimizers of the network (set names, scopes... set optimization ops...).", 
            "title": "TrainOp"
        }, 
        {
            "location": "/helpers/evaluator/", 
            "text": "Evaluator\n\n\ntflearn.helpers.evaluator.Evaluator\n  (tensors,  model=None,  session=None)\n\n\nA class used for performing predictions or evaluate a model performances.\n\n\nArguments\n\n\n\n\n\ntensors\n: list of \nTensor\n. A list of tensors to perform predictions.\n\n\nmodel\n: \nstr\n. The model weights path (Optional).\n\n\nsession\n: \nSession\n. The session to run the prediction (Optional).\n\n\n\n\nMethods\n\n\n\n \n\n\nevaluate\n  (feed_dict,  ops,  batch_size=128)\n\n\nEvaluate a list of tensors over a whole dataset. It is used to compute\na metric mean score over an entire dataset.\n\n\nArguments\n\n\n\n\n\nfeed_dict\n: \ndict\n. The feed dictionary of data.\n\n\nops\n: list of \nTensors\n. The tensors to evaluate.\n\n\nbatch_size\n: \nint\n. A batch size.\n\n\n\n\nReturns\n\n\n\nThe mean average result per tensor over the entire dataset.\n\n\n \n\n\npredict\n  (feed_dict)\n\n\nRun data through each tensor's network, and return prediction value.\n\n\nArguments\n\n\n\n\n\nfeed_dict\n: \ndict\n. Feed data dictionary, with placeholders as\nkeys, and data as values.\n\n\n\n\nReturns\n\n\n\nAn \narray\n. In case of multiple tensors to predict, array is a\nconcatanation of each tensor prediction result.", 
            "title": "Evaluator"
        }, 
        {
            "location": "/helpers/evaluator/#evaluator", 
            "text": "tflearn.helpers.evaluator.Evaluator   (tensors,  model=None,  session=None)  A class used for performing predictions or evaluate a model performances.", 
            "title": "Evaluator"
        }, 
        {
            "location": "/helpers/summarizer/", 
            "text": "summarize_variables\n\n\ntflearn.helpers.summarizer.summarize_variables\n  (train_vars=None,  summary_collection='tflearn_summ')\n\n\nArguemnts:\ntrain_vars: list of \nVariable\n. The variable weights to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.\n\n\nReturns\n\n\n\nTensor\n. Merge of all summary in 'summary_collection'\n\n\n\n\nsummarize_activations\n\n\ntflearn.helpers.summarizer.summarize_activations\n  (activations,  summary_collection='tflearn_summ')\n\n\nArguemnts:\nactivations: list of \nTensor\n. The activations to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.\n\n\nReturns\n\n\n\nTensor\n. Merge of all summary in 'summary_collection'\n\n\n\n\nsummarize_activations\n\n\ntflearn.helpers.summarizer.summarize_gradients\n  (grads,  summary_collection='tflearn_summ')\n\n\nArguemnts:\ngrads: list of \nTensor\n. The gradients to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.\n\n\nReturns\n\n\n\nTensor\n. Merge of all summary in 'summary_collection'\n\n\n\n\nsummarize\n\n\ntflearn.helpers.summarizer.summarize\n  (value,  type,  name,  summary_collection='tflearn_summ')\n\n\nA custom summarization op.\n\n\nArguemnts:\nvalue: \nTensor\n. The tensor value to monitor.\ntype: \nstr\n among 'histogram', 'scalar'. The data monitoring type.\nname: \nstr\n. A name for this summary.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.\n\n\nReturns\n\n\n\nTensor\n. Merge of all summary in 'summary_collection'.", 
            "title": "Summarizer"
        }, 
        {
            "location": "/helpers/summarizer/#summarize_variables", 
            "text": "tflearn.helpers.summarizer.summarize_variables   (train_vars=None,  summary_collection='tflearn_summ')  Arguemnts:\ntrain_vars: list of  Variable . The variable weights to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.", 
            "title": "summarize_variables"
        }, 
        {
            "location": "/helpers/summarizer/#summarize_activations", 
            "text": "tflearn.helpers.summarizer.summarize_activations   (activations,  summary_collection='tflearn_summ')  Arguemnts:\nactivations: list of  Tensor . The activations to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.", 
            "title": "summarize_activations"
        }, 
        {
            "location": "/helpers/summarizer/#summarize_activations_1", 
            "text": "tflearn.helpers.summarizer.summarize_gradients   (grads,  summary_collection='tflearn_summ')  Arguemnts:\ngrads: list of  Tensor . The gradients to monitor.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.", 
            "title": "summarize_activations"
        }, 
        {
            "location": "/helpers/summarizer/#summarize", 
            "text": "tflearn.helpers.summarizer.summarize   (value,  type,  name,  summary_collection='tflearn_summ')  A custom summarization op.  Arguemnts:\nvalue:  Tensor . The tensor value to monitor.\ntype:  str  among 'histogram', 'scalar'. The data monitoring type.\nname:  str . A name for this summary.\nsummary_collection: A collection to add this summary to and\nalso used for returning a merged summary over all its elements.\nDefault: 'tflearn_summ'.", 
            "title": "summarize"
        }, 
        {
            "location": "/helpers/regularizer/", 
            "text": "add_weights_regularizer\n\n\ntflearn.helpers.regularizer.add_weights_regularizer\n  (variable,  loss='L2',  weight_decay=0.001,  add_to_collection=None)\n\n\nAdd a weights regularizer to the provided Tensor\n\n\nArguments\n\n\n\n\n\nvariable\n: \nVariable\n. Tensor to add regularization.\n\n\nloss\n: \nstr\n. Regularization mode.\n\n\nweight_decay\n: \nfloat\n. Decay to use for regularization.\n\n\nadd_to_collection\n: \nstr\n. Add the regularization loss to the\nspecified collection. Default: tf.GraphKeys.REGULARIZATION_LOSSES.\n\n\n\n\nReturns\n\n\n\ntf.Tensor\n. The weight regularizer.", 
            "title": "Regularizer"
        }, 
        {
            "location": "/helpers/regularizer/#add_weights_regularizer", 
            "text": "tflearn.helpers.regularizer.add_weights_regularizer   (variable,  loss='L2',  weight_decay=0.001,  add_to_collection=None)  Add a weights regularizer to the provided Tensor", 
            "title": "add_weights_regularizer"
        }, 
        {
            "location": "/contributions/", 
            "text": "Contributions\n\n\nReport a bug\n\n\nTFLearn is actually at its early stage, there are probably many bugs around... We will be grateful if you would help us to find them. To report a bug, simply open an issue in the GitHub 'issues' section.\n\n\nPull request\n\n\nIf you made improvements to TFLearn or fixed a bug, feel free to send us a pull-request. Please give a brief introduction of the new feature or the bug. When adding new class or functions, make sure that you are following TFLearn docstring syntax.\n\n\nRequest a new feature\n\n\nIf you think about a new feature to improve TFLearn, let us know by opening an issue in GitHub.\n\n\nQuestions\n\n\nTo get help on how to use TFLearn or its functionalities, you can as well open an issue in GitHub.", 
            "title": "Contributions"
        }, 
        {
            "location": "/contributions/#contributions", 
            "text": "", 
            "title": "Contributions"
        }, 
        {
            "location": "/contributions/#report-a-bug", 
            "text": "TFLearn is actually at its early stage, there are probably many bugs around... We will be grateful if you would help us to find them. To report a bug, simply open an issue in the GitHub 'issues' section.", 
            "title": "Report a bug"
        }, 
        {
            "location": "/contributions/#pull-request", 
            "text": "If you made improvements to TFLearn or fixed a bug, feel free to send us a pull-request. Please give a brief introduction of the new feature or the bug. When adding new class or functions, make sure that you are following TFLearn docstring syntax.", 
            "title": "Pull request"
        }, 
        {
            "location": "/contributions/#request-a-new-feature", 
            "text": "If you think about a new feature to improve TFLearn, let us know by opening an issue in GitHub.", 
            "title": "Request a new feature"
        }, 
        {
            "location": "/contributions/#questions", 
            "text": "To get help on how to use TFLearn or its functionalities, you can as well open an issue in GitHub.", 
            "title": "Questions"
        }, 
        {
            "location": "/license/", 
            "text": "MIT License\n\n\nCopyright (c) 2016 TFLearn Contributors.\nEach contributor holds copyright over his own contributions. The project\nversioning keep tracks of such information.\n\n\nBy contributing to the TFLearn repository, the contributor releases their\ncontent to the license and copyright terms herein.\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", 
            "title": "License"
        }
    ]
}